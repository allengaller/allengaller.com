{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/images/banner-bak.jpg","path":"css/images/banner-bak.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"b48c4f7d61a5928be717d4bd654481ff1eab36ee","modified":1484147075000},{"_id":"themes/landscape/.DS_Store","hash":"9457f542cf2c3f2a50b9ecd64858fc6f50b0d0c4","modified":1484147080000},{"_id":"themes/landscape/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1484126821000},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1484126821000},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1484126821000},{"_id":"themes/landscape/README.md","hash":"c7e83cfe8f2c724fc9cac32bd71bb5faf9ceeddb","modified":1484126821000},{"_id":"themes/landscape/_config.yml","hash":"285fb948f9f50e0d2c040283251b1ce20119bfaa","modified":1484214819000},{"_id":"themes/landscape/package.json","hash":"85358dc34311c6662e841584e206a4679183943f","modified":1484126821000},{"_id":"source/_posts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1484211471000},{"_id":"source/_posts/architect-portal.md","hash":"6932aaea71078034615157134e80029d70c28bcd","modified":1484308101000},{"_id":"source/_posts/cmd_django_docker.txt","hash":"278e19844de45ed90b64d49059539be018bb3fd4","modified":1484211486000},{"_id":"source/_posts/cx-portal.md","hash":"2cd25c7e83b0f07406bfa8dfc5ea285c1e1936ce","modified":1484152314000},{"_id":"source/_posts/devops-portal.md","hash":"e51f3a902a32e2295d38850467b740fe76786f1e","modified":1484144776000},{"_id":"source/_posts/docker-cookbook.md","hash":"8caa9454e90d4ade8268c325399b17a29c48c945","modified":1484304719000},{"_id":"source/_posts/docker-core.md","hash":"09142c10d1c9c5d63b284ec14afab39b3739a5f4","modified":1484311434000},{"_id":"source/_posts/docker-k8s-core.md","hash":"c932617dd05b171229eb0cbad913f31974775902","modified":1484152331000},{"_id":"source/_posts/docker-mesos-core.md","hash":"08f6e57862e8033af8373ef1ac51da8ffdd9faa6","modified":1484152346000},{"_id":"source/_posts/docker-portal.md","hash":"1636ea5ee9554eac1f5788794bab4e8899cd187d","modified":1484151372000},{"_id":"source/_posts/fullstack-portal.md","hash":"d96e2c479c7fbfd6d38bea35f6f323d2014b38af","modified":1484152554000},{"_id":"source/_posts/hello-world.md","hash":"2821cef1e0b6723d18e7f2162653fe696c4dbdc0","modified":1484152366000},{"_id":"source/_posts/iaas-openstack-core.md","hash":"a4dfe305ed994558c7b4fc58de795922c7799462","modified":1484152388000},{"_id":"source/_posts/iaas-portal.md","hash":"5e405ec4afebf9d4a0beda52d73247535c65f739","modified":1484152398000},{"_id":"source/_posts/java-portal.md","hash":"200e3ea7381f233610ee05a7da0e829f44bd93d3","modified":1484152415000},{"_id":"source/_posts/js-nodejs-core.md","hash":"c3d8104fd5c3ba26bd0215b83a6f169248a6921c","modified":1484152422000},{"_id":"source/_posts/js-portal.md","hash":"c99c24b65ab554ef3d4bb3a145ed011f17f5e369","modified":1484152428000},{"_id":"source/_posts/linux-portal.md","hash":"4e023a556e18a248bb932ff4067513be2779b1c0","modified":1484152446000},{"_id":"source/_posts/microservice-portal.md","hash":"a73b76c6d875d6c61d419bf0a7ac68ae3ce6232f","modified":1484152456000},{"_id":"source/_posts/network-http-core.md","hash":"a5853d8ae8a690d707ee6e5e669ea3470c492940","modified":1484152471000},{"_id":"source/_posts/network-portal.md","hash":"d714cb864cd3f5e84226a1ee04f0feed4ce47736","modified":1484152482000},{"_id":"source/_posts/paas-cloudfoundry-core.md","hash":"a77e50fa1b3f67ada1bc5323779e6b3cd98b6cb7","modified":1484152524000},{"_id":"source/_posts/paas-openshift-core.md","hash":"db53a3ce03df639c195d89c45d70b0f0466d1020","modified":1484152520000},{"_id":"source/_posts/paas-portal.md","hash":"1a96b1ddfa2eb02998c00983879ee03adbe053f2","modified":1484152535000},{"_id":"source/_posts/python-django-core.md","hash":"b58bfdbcca877f4c3041e6e25fa36b7f2be82140","modified":1484214459000},{"_id":"source/_posts/python-django-install.md","hash":"7f922a7b5eb9ee80cb5cd6884eb3d87f81a0d595","modified":1484214542000},{"_id":"source/_posts/python-portal.md","hash":"0f1a90cb1de64442035b364589c1ffa2fd49ef4e","modified":1484214141000},{"_id":"source/_posts/ruby-rails-core.md","hash":"37bf54a843a2fb191bdc49ca6c2c504750db7df7","modified":1484152581000},{"_id":"source/about/index.md","hash":"bfee1378ee8b0c03381c10c44157efb661c62430","modified":1484214601000},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1484126821000},{"_id":"themes/landscape/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1484126821000},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1484126821000},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1484126821000},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1484126821000},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1484126821000},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1484126821000},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1484126821000},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1484126821000},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1484126821000},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1484126821000},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1484126821000},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1484126821000},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1484126821000},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1484126821000},{"_id":"themes/landscape/source/.DS_Store","hash":"1429b9c08aeb8c15b3499d150e011720f8ff275c","modified":1484147087000},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"9292c640bdf7c8eb6fed2e8a1800f1cc7f43722b","modified":1484145585000},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"931aaaffa0910a48199388ede576184ff15793ee","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"3ff1260ab513c523a610f1d83b20961b5d140d6b","modified":1484213973000},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"f6975a227829834c026b17ee2493d06a16202b94","modified":1484144946000},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"bfd64f2a831a6acb7f5bae852cae3098a91e1997","modified":1484145371000},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"9d7b18ae2a5479d9ae0eb053ea7043ab8a9bd642","modified":1484145235000},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1484126821000},{"_id":"themes/landscape/source/css/.DS_Store","hash":"0c4a669591bf1723e84d44bb15e7b684e25ff531","modified":1484146229000},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1484126821000},{"_id":"themes/landscape/source/css/_variables.styl","hash":"06e2f44b92c26c5d71abf01e7b43ee0dfd2010c7","modified":1484148828000},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1484126821000},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1484213953000},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"9658cb416b434dc6c3a8c2c15511eb170f363a3d","modified":1484148524000},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1484126821000},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1484126821000},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1484126821000},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"e2c9ff91ca7c221c23e41dba0d4b8dfd90d28a6c","modified":1484146333000},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1484126821000},{"_id":"themes/landscape/source/css/images/banner-bak.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1484126821000},{"_id":"public/about/index.html","hash":"2293612cde0812e473e5b433ec97444f8ca1ebd8","modified":1484306188071},{"_id":"public/python/python-django-install/index.html","hash":"fa2c1546c1af62a86fd06b1de57292bb57b71efb","modified":1484306188086},{"_id":"public/nodejs/js-nodejs-core/index.html","hash":"0c2f79dea636ed4013d8745923d92a7a03a8a60e","modified":1484306188086},{"_id":"public/devops/devops-portal/index.html","hash":"69f91399ba99fbc59dc8b252e35f09edce8760be","modified":1484306188087},{"_id":"public/docker/docker-cookbook/index.html","hash":"a9bbc3dbf5c0585bbf72fd3548e176d0674405d5","modified":1484306188087},{"_id":"public/docker/docker-core/index.html","hash":"e35a17ffd4e8d76b5c27213c8020a65f78157616","modified":1484306188087},{"_id":"public/docker/docker-k8s-core/index.html","hash":"d4d8efb1551df34ba8024dcc68c0dec69d4f1850","modified":1484306188087},{"_id":"public/docker/docker-mesos-core/index.html","hash":"de843e6e83d54a5ca4975b74f0ab595aefa6d683","modified":1484306188087},{"_id":"public/python/fullstack-portal/index.html","hash":"181cdaf90f261075f8d941248cc7f79e98d67b68","modified":1484306188087},{"_id":"public/python/python-portal/index.html","hash":"97b3dafa60246e05b1713730c4d885f074094d6c","modified":1484306188089},{"_id":"public/iaas/iaas-openstack-core/index.html","hash":"86fddfa0a4e6fe7dd827df4499046cfac9a4cefb","modified":1484306188087},{"_id":"public/iaas/iaas-portal/index.html","hash":"55e7357d6b573cf1d30f8a3b8cdcdeed99542c07","modified":1484306188088},{"_id":"public/java/java-portal/index.html","hash":"ead2d1a8e549d6e794fe66dc943f413b7d33ae95","modified":1484306188088},{"_id":"public/cx/cx-portal/index.html","hash":"72ef21fb7f887a5082b105461ec518b48c4d24be","modified":1484306188088},{"_id":"public/js/js-portal/index.html","hash":"2ea6551694cf493d5f2caacc15a2d635e098733c","modified":1484306188088},{"_id":"public/linux/linux-portal/index.html","hash":"1497711748fd606111dfde36bb2fea9acaa59246","modified":1484306188088},{"_id":"public/microservice/microservice-portal/index.html","hash":"677649386b64220509d72e26cb36ace1ceacd62b","modified":1484306188088},{"_id":"public/network/network-http-core/index.html","hash":"54c6f0994501922110a71e3f83030fa458175a9c","modified":1484306188088},{"_id":"public/network/network-portal/index.html","hash":"da7ff0519f76b920726a9f3780007735203c7c00","modified":1484306188088},{"_id":"public/paas/paas-cloudfoundry-core/index.html","hash":"1f38a2284bc74190d4c27e8466088224a01fd3d9","modified":1484306188089},{"_id":"public/paas/paas-openshift-core/index.html","hash":"0eb430b352838243365e5a2ae1061cba41b951c9","modified":1484306188089},{"_id":"public/paas/paas-portal/index.html","hash":"31fd016b0d796aec5d04a6c9ec6218bb6ff3eb8c","modified":1484306188089},{"_id":"public/python/python-django-core/index.html","hash":"aa3d5b92599be593116ca45e60dc959a92639d5b","modified":1484306188089},{"_id":"public/python/architect-portal/index.html","hash":"43bbb6beaa3b5085045fe387f935e9e8b77765ff","modified":1484214831886},{"_id":"public/ruby/ruby-rails-core/index.html","hash":"dce96caa6d5156b2d2d651c057d1b83312460073","modified":1484306188087},{"_id":"public/tmp/hello-world/index.html","hash":"d210fefe7444fa2b9847fcd9dcfa34e746bc4a05","modified":1484306188089},{"_id":"public/page/3/index.html","hash":"7122b3818d737b1bf022e4a977932fc069186cd2","modified":1484306188095},{"_id":"public/categories/python/index.html","hash":"3cc442954cacb00300b59ebddef0395971879bf9","modified":1484306188091},{"_id":"public/categories/cx/index.html","hash":"b20b3d5a6492d24b2e0eebfbaf76b185355b61fb","modified":1484306188092},{"_id":"public/categories/devops/index.html","hash":"f09a3489cfa219a5361a13f1636e98a0d251f8d8","modified":1484306188093},{"_id":"public/categories/docker/index.html","hash":"71cb4b3d5a3c2edffa70d15330076c580c94b119","modified":1484306188093},{"_id":"public/categories/tmp/index.html","hash":"759e23a25ece78ce3c1c374d15f13c14b50f8ad2","modified":1484306188093},{"_id":"public/categories/iaas/index.html","hash":"1882fb2d7f77f5453212fdd11021687a307d5bd1","modified":1484306188093},{"_id":"public/categories/java/index.html","hash":"646606d0e1bc759e134c0385a32b36143a4570e7","modified":1484306188093},{"_id":"public/categories/nodejs/index.html","hash":"8fe6a5e81310665399d47df0d8bb1b24247d223e","modified":1484306188093},{"_id":"public/categories/js/index.html","hash":"28b100a2d6965b672c8709e15903f3352a59a9fa","modified":1484306188093},{"_id":"public/categories/linux/index.html","hash":"e41274e2dbe9c55b3dcb88760c4d0bb4e79ccd8e","modified":1484306188093},{"_id":"public/categories/microservice/index.html","hash":"65660b020459d807e01ef22420664cc7e1195ca9","modified":1484306188094},{"_id":"public/categories/network/index.html","hash":"d387ee72e63c3af2adec53b68baa486d419f96da","modified":1484306188094},{"_id":"public/categories/paas/index.html","hash":"40220b72693d6a01d65ef673972a6eae27c2041e","modified":1484306188094},{"_id":"public/categories/ruby/index.html","hash":"d3c34cb351af7159220950d1a83ca8d92de89951","modified":1484306188094},{"_id":"public/archives/index.html","hash":"7d486922dba3beb9cf7f4e16d1a97f66e1b4c1fd","modified":1484306188090},{"_id":"public/archives/page/2/index.html","hash":"85e5fc308aff80e4fd98a1c9410a9210b256d158","modified":1484306188090},{"_id":"public/archives/page/3/index.html","hash":"00783496cf9dbeefcf7005c7536f74471c37bd1d","modified":1484306188090},{"_id":"public/archives/2017/index.html","hash":"064de490788d9e387b45b34a952c75a7cca89dc4","modified":1484306188090},{"_id":"public/archives/2017/page/2/index.html","hash":"4d87630b3809201637c617345fa5cb04d74ff36f","modified":1484306188090},{"_id":"public/archives/2017/page/3/index.html","hash":"ea7ebf90ff6de8e7294533b79c7404271caadfa7","modified":1484306188090},{"_id":"public/archives/2017/01/index.html","hash":"d0cb968130ce6a44c01468a9e8a85d57d69f075a","modified":1484306188090},{"_id":"public/archives/2017/01/page/2/index.html","hash":"9c6f84bd5c28d1269e795d5307390ac07e8fe3bb","modified":1484306188090},{"_id":"public/archives/2017/01/page/3/index.html","hash":"ef5cf9ebca2d770be14c17bcea266efb37124742","modified":1484306188090},{"_id":"public/tags/portal/index.html","hash":"78a961aadbc6d8719d957bf53eaabd46e1c8cb2c","modified":1484306188094},{"_id":"public/tags/portal/page/2/index.html","hash":"656d4f30678e7e3304d03f5269eb96cf07e68e22","modified":1484306188094},{"_id":"public/tags/cookbook/index.html","hash":"3d2586cf5868c897e4fc9181d78e1cd3f4163e39","modified":1484306188094},{"_id":"public/tags/core/index.html","hash":"4bde6b2df249e5b33b488101c1a5f39c78ecfe2a","modified":1484306188094},{"_id":"public/tags/openstack/index.html","hash":"6b34b7c12370d79dfb3feb00738b922871dbccb2","modified":1484306188094},{"_id":"public/tags/http/index.html","hash":"21f6d4bac9793a24b10fa887d759e1ac5d509409","modified":1484306188094},{"_id":"public/tags/cloudfoundry/index.html","hash":"13f1ff595062f00fd3d81d7927b94b82e2953866","modified":1484306188094},{"_id":"public/tags/openshift/index.html","hash":"375ab93772db1f61b5e088b204698fa754033c56","modified":1484306188094},{"_id":"public/tags/django/index.html","hash":"87eb1c4180b991a4db3d35120898c5fc16012ec6","modified":1484306188094},{"_id":"public/tags/install/index.html","hash":"6a5372617efc539626fd9e0f462036f48a497892","modified":1484306188095},{"_id":"public/tags/python/index.html","hash":"bdcaac409de8f7fbec13ab6ae1c8fde1e5074a48","modified":1484306188095},{"_id":"public/tags/docker/index.html","hash":"168be3fc8cdaa4153d5eeccd7336325b74d3c2f1","modified":1484306188095},{"_id":"public/tags/rails/index.html","hash":"15f6a2e7075931a8968e6a55f64f0679705b5775","modified":1484306188095},{"_id":"public/docker/docker-portal/index.html","hash":"d78d4a582423fba429887b2f9f92872df094f155","modified":1484306188095},{"_id":"public/index.html","hash":"5c88eec7598be9ae046bd58a1a1953f0021c89bf","modified":1484306188095},{"_id":"public/page/2/index.html","hash":"f318cd5f08bacb0015e3ab7384a01b03638c70ab","modified":1484306188095},{"_id":"public/cloud/architect/architect-portal/index.html","hash":"b077278ef13e28482038891730440640a595e44d","modified":1484306188089},{"_id":"public/categories/cloud/index.html","hash":"a92a0dae0f1651dcccf58ef0171aa6492e98c929","modified":1484306188094},{"_id":"public/categories/cloud/architect/index.html","hash":"a7d4cd3326867acd3bd4874b44c9111b5caecb06","modified":1484306188094},{"_id":"source/_posts/docker-dockerfile-core.md","hash":"ecb688e05cef1de80eb787f74e828d93247aee48","modified":1484306577000},{"_id":"public/docker/docker-dockerfile-core/index.html","hash":"3a3ce979fedb678adaa2899d112494d9bb01e2ee","modified":1484306188098},{"_id":"public/tags/core/page/2/index.html","hash":"97088ded28b812d1d3ac2a0c039dfdc7be4e8106","modified":1484306188098},{"_id":"source/_posts/docker-dockerfile-detail.md","hash":"a0e7e5e21c02381a9cd232349eed7eca7a492eaf","modified":1484306749000},{"_id":"source/_posts/docker-image-detail.md","hash":"21421ab56a9a54fe66765d998db6df3dab394563","modified":1484308150000},{"_id":"source/_posts/docker-dockerhub-detail.md","hash":"d73c876795bd2175c53d186b816dd2585f00a254","modified":1484307994000},{"_id":"source/_posts/docker-engine-detail.md","hash":"b27a664d2c97671de05b37ee1667bde0487bd05f","modified":1484310053000},{"_id":"source/_posts/docker-compose-detail.md","hash":"bb5a7d90211be29f38d1d884b1d65e95ae5842e1","modified":1484310782000},{"_id":"source/_posts/docker-machine-detail.md","hash":"9b36e632e42c327003da04c94c07440a05be938a","modified":1484310187000},{"_id":"source/_posts/docker-swarm-detail.md","hash":"3d8f82a9abe99dc02610759d5d45dd19cf03806c","modified":1484311355000},{"_id":"source/_posts/docker-compose-file-detail.md","hash":"2b421b59085d42e2aab0386cc5d9c7ab070806c5","modified":1484311079000}],"Category":[{"name":"python","_id":"cixu71ib600038psv4kzvedkn"},{"name":"cx","_id":"cixu71ibm00088psv9ewex0dx"},{"name":"devops","_id":"cixu71ic2000f8psvk5xudhiy"},{"name":"docker","_id":"cixu71icb000l8psvs6a0nvft"},{"name":"tmp","_id":"cixu71idw001m8psvaiee8fy2"},{"name":"iaas","_id":"cixu71iee001u8psvycbwyw7g"},{"name":"java","_id":"cixu71ier00278psv4j2mqwcx"},{"name":"nodejs","_id":"cixu71ieu002d8psvjxy37efe"},{"name":"js","_id":"cixu71iev002l8psvmrg53eso"},{"name":"linux","_id":"cixu71iex002q8psvcrj8y1q8"},{"name":"microservice","_id":"cixu71iey002v8psvukwktcam"},{"name":"network","_id":"cixu71iez002z8psvfyjo76s8"},{"name":"paas","_id":"cixu71if300368psv2wrxrx3d"},{"name":"ruby","_id":"cixu71ifm003g8psvp6i39xg1"},{"name":"cloud","_id":"cixvoynmb0000yasvpuq08a3r"},{"name":"architect","parent":"cixvoynmb0000yasvpuq08a3r","_id":"cixvoynn50001yasvan6kpkhj"},{"name":"cloud;","_id":"cixvqp1ga0000zhs6a9nhhybc"},{"name":"architect;","parent":"cixvqp1ga0000zhs6a9nhhybc","_id":"cixvqp1gd0003zhs6ws1js831"}],"Data":[],"Page":[{"title":"about","date":"2017-01-12T17:49:37.000Z","_content":"\n123","source":"about/index.md","raw":"---\ntitle: about\ndate: 2017-01-12 17:49:37\n---\n\n123","updated":"2017-01-12T09:50:01.000Z","path":"about/index.html","_id":"cixu71iaw00018psv8yl7ppxs","comments":1,"layout":"page","content":"<p>123</p>\n","excerpt":"","more":"<p>123</p>\n"}],"Post":[{"title":"cloud architect portal","_content":"\n# about cloud architect\n\n# resource\n\n","source":"_posts/architect-portal.md","raw":"---\ntitle: cloud architect portal\ncategories:\n- cloud\ntags:\n- portal\n- architect\n---\n\n# about cloud architect\n\n# resource\n\n","slug":"architect-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T11:48:21.000Z","_id":"cixu71iaq00008psvcb7p2zeh","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"about-cloud-architect\"><a href=\"#about-cloud-architect\" class=\"headerlink\" title=\"about cloud architect\"></a>about cloud architect</h1><h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1>","excerpt":"","more":"<h1 id=\"about-cloud-architect\"><a href=\"#about-cloud-architect\" class=\"headerlink\" title=\"about cloud architect\"></a>about cloud architect</h1><h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1>"},{"title":"cx portal","_content":"\n","source":"_posts/cx-portal.md","raw":"---\ntitle: cx portal\ncategories:\n- cx\ntags:\n- portal\n---\n\n","slug":"cx-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:31:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71iaz00028psvjqkcdzbl","content":"","excerpt":"","more":""},{"title":"devops portal","_content":"\n# about\n\n","source":"_posts/devops-portal.md","raw":"---\ntitle: devops portal\ncategories:\n- devops\ntags:\n- portal\n---\n\n# about\n\n","slug":"devops-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T14:26:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ibd00058psv0hz63d7z","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1>"},{"title":"docker cookbook","_content":"\n# docker cookbook","source":"_posts/docker-cookbook.md","raw":"---\ntitle: docker cookbook\ncategories:\n- docker\ntags:\n- cookbook\n---\n\n# docker cookbook","slug":"docker-cookbook","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T10:51:59.000Z","_id":"cixu71ibi00068psv6tox2e74","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"docker-cookbook\"><a href=\"#docker-cookbook\" class=\"headerlink\" title=\"docker cookbook\"></a>docker cookbook</h1>","excerpt":"","more":"<h1 id=\"docker-cookbook\"><a href=\"#docker-cookbook\" class=\"headerlink\" title=\"docker cookbook\"></a>docker cookbook</h1>"},{"title":"docker core","_content":"\n# about docker\n\n\n# basic concept\n\n- [dockerfile]()\n- [image]()\n\n- [dockerhub]()\n\n# basic component\n\n- [docker engine]()\n- [docker compose]()\n- [docker swarm]()\n\n# basic topic\n\n- [storage]()\n- [network]()\n- [security]()","source":"_posts/docker-core.md","raw":"---\ntitle: docker core\ncategories:\n- docker\ntags:\n- core\n---\n\n# about docker\n\n\n# basic concept\n\n- [dockerfile]()\n- [image]()\n\n- [dockerhub]()\n\n# basic component\n\n- [docker engine]()\n- [docker compose]()\n- [docker swarm]()\n\n# basic topic\n\n- [storage]()\n- [network]()\n- [security]()","slug":"docker-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T05:15:42.000Z","_id":"cixu71ibk00078psv09s4xbk0","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"about-docker\"><a href=\"#about-docker\" class=\"headerlink\" title=\"about docker\"></a>about docker</h1><h1 id=\"basic-concept\"><a href=\"#basic-concept\" class=\"headerlink\" title=\"basic concept\"></a>basic concept</h1><ul>\n<li><a href=\"\">dockerfile</a></li>\n<li><p><a href=\"\">image</a></p>\n</li>\n<li><p><a href=\"\">dockerhub</a></p>\n</li>\n</ul>\n<h1 id=\"basic-component\"><a href=\"#basic-component\" class=\"headerlink\" title=\"basic component\"></a>basic component</h1><ul>\n<li><a href=\"\">docker engine</a></li>\n<li><a href=\"\">docker compose</a></li>\n<li><a href=\"\">docker swarm</a></li>\n</ul>\n<h1 id=\"basic-topic\"><a href=\"#basic-topic\" class=\"headerlink\" title=\"basic topic\"></a>basic topic</h1><ul>\n<li><a href=\"\">storage</a></li>\n<li><a href=\"\">network</a></li>\n<li><a href=\"\">security</a></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about-docker\"><a href=\"#about-docker\" class=\"headerlink\" title=\"about docker\"></a>about docker</h1><h1 id=\"basic-concept\"><a href=\"#basic-concept\" class=\"headerlink\" title=\"basic concept\"></a>basic concept</h1><ul>\n<li><a href=\"\">dockerfile</a></li>\n<li><p><a href=\"\">image</a></p>\n</li>\n<li><p><a href=\"\">dockerhub</a></p>\n</li>\n</ul>\n<h1 id=\"basic-component\"><a href=\"#basic-component\" class=\"headerlink\" title=\"basic component\"></a>basic component</h1><ul>\n<li><a href=\"\">docker engine</a></li>\n<li><a href=\"\">docker compose</a></li>\n<li><a href=\"\">docker swarm</a></li>\n</ul>\n<h1 id=\"basic-topic\"><a href=\"#basic-topic\" class=\"headerlink\" title=\"basic topic\"></a>basic topic</h1><ul>\n<li><a href=\"\">storage</a></li>\n<li><a href=\"\">network</a></li>\n<li><a href=\"\">security</a></li>\n</ul>\n"},{"title":"k8s core","_content":"\n#  core","source":"_posts/docker-k8s-core.md","raw":"---\ntitle: k8s core\ncategories:\n- docker\ntags:\n- core\n---\n\n#  core","slug":"docker-k8s-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:32:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ibr000b8psvb0hky11f","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"mesos core","_content":"\n#  core","source":"_posts/docker-mesos-core.md","raw":"---\ntitle: mesos core\ncategories:\n- docker\ntags:\n- core\n---\n\n#  core","slug":"docker-mesos-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:32:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ibz000d8psv5tfhi7s7","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"docker portal","_content":"\n# resource\n\nofficial:\n[https://www.docker.com/](https://www.docker.com/)\n[https://blog.docker.com/](https://blog.docker.com/)\n[https://linuxcontainers.org/](https://linuxcontainers.org/)\n\nawesome:\n[https://github.com/Friz-zy/awesome-linux-containers](https://github.com/Friz-zy/awesome-linux-containers)\n\ngithub:\n[docker-library](https://github.com/docker-library)\n[dockerfile](https://github.com/tianon/dockerfiles)   \n[docker-cheat-sheet](https://github.com/wsargent/docker-cheat-sheet)\n[Chef Cookbook for Docker](https://github.com/chef-cookbooks/docker)\n\ncommunity:\n[dockerpool](http://dockerpool.com/)\n[dockerone](http://dockerone.com)\n[devops-china](http://devops-china.org)\n[ceph china](http://bbs.ceph.org.cn/)    \ncloud stack(http://www.cloudstack-china.org/)\natcontainer(http://atcontainer.com/)\ngoogle plus(https://plus.google.com/u/0/+DockerIo)\nzhihu(https://www.zhihu.com/topic/19950993)\nreddit\nstackoverflow(http://superuser.com/questions/tagged/docker)\n\norganization:\nopen container project: [link](http://www.opencontainers.org/), [doc](http://blog.docker.com/2015/06/open-container-project-foundation/)\noci:[](https://www.opencontainers.org/), [](https://github.com/opencontainers)\nabout:尽管Docker获得广大公有云厂商的大力支持，但是目前容器技术生态中已经存在许多分支与分歧，如rkt项目。为了解决容器生态中的差异化问题，为了从根本上解决生产环境中运用Docker的风险，Google，Intel，Redhat，Microsoft，EMC，IBM，Amazon，VMware，Oracle，Pivotal，Rancher，HPE，Facebook，Twitter等IT大厂于2015年6月共同宣布成立OCI（Open Container Initiative）组织。OCI组织的目标在于建立通用的容器技术标准。除了保障与延续既有容器服务的生命周期外，还通过不断推出标准的创新的容器解决方案赋能开发者。而OCI成员企业也会秉持开放，安全，弹性等核心价值观来发展容器生态。客观而言，OCI组织的出现确立了容器技术的标准，避免容器技术被单一厂商垄断。统一技术标准后，广大企业不用担心未来新兴的容器技术不兼容Docker。\nCNCF: Cloud Native Computing Foundation\n\nconf\nQConf:http://2016.qconshanghai.com/, http://qconferences.com/\nDockerCon\n    link\n        http://www.slideshare.net/Docker/presentations\n        http://www.dockercon.com/\n    2015\n        guidebook app\n        http://europe-2015.dockercon.com/\n        http://dockerconeu2015.sched.org/\n    2016\n        http://2016.dockercon.com/\n        https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/\nContainerCon\nContainerCamp\nOperability 1.0\nGoTo Conference\nSoftware Circus\n容器技术大会\n    http://atcontainer.com/\n有容云\n    http://www.bagevent.com/event/176371\n\ndocker vs x\n    docker vs virtual machine\n        link\n            http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#\n            http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution\n            http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker\n\nmooc\n    https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info\n    \nread:\n- infoq: [infoq cn](http://www.infoq.com/cn/dockers/), [infoq en](https://www.infoq.com/docker-2)\n- bot: [yidian](http://www.yidianzixun.com/home?page=channel&keyword=docker), [toutiao](http://toutiao.com/tag85482990/)\n- book\n    Docker Cookbook\n    Docker技术入门与实战:publish,[opensource](http://dockerpool.com/static/books/docker_practice/index.html)\n    Docker源码分析\n    Docker技术详解与实践 lts        \n    [docker入门实战](http://yuedu.baidu.com/ebook/d817967416fc700abb68fca1)\n    [Service discovery with Docker](http://adetante.github.io/articles/service-discovery-with-docker-1/ )\n- tut\n    [](http://www.alauda.cn/tutorial/)\n    [](http://help.daocloud.io/)        \n    [](https://coreos.com/os/docs/latest/quickstart.html   )        \n- course\n    https://training.docker.com/self-paced-training\n    http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice              \nlanguages:\n- php\n    https://github.com/schmunk42/docker-yii2-app-basic\n    https://github.com/eko/docker-symfony\n    https://github.com/harshjv/docker-laravel\n    https://github.com/tkyk/docker-compose-lamp\n    https://github.com/docker-library/php\n    compose\n    https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml\n    https://github.com/tkyk/docker-compose-lamp\n    https://github.com/larryprice/docker-compose-example\n- py\n    https://github.com/dockerfiles/django-uwsgi-nginx\n    https://github.com/mbentley/docker-django-uwsgi-nginx\n    https://github.com/dockerfiles/django-uwsgi-nginx\n    django:https://docs.docker.com/compose/django/\n    flask:dockercook 3.1\n- ruby\n    rails:https://docs.docker.com/compose/rails/\n- js\n    https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon\n- other\n    https://github.com/docker/compose/blob/master/SWARM.md\n    wordpress:https://docs.docker.com/compose/wordpress/\n\n12 factor\n    http://www.the12factorapp.com/\n    https://12factor.net/\n    https://chixq.com/articles/12-factor-app/\n\n\n        ","source":"_posts/docker-portal.md","raw":"---\ntitle: docker portal\ncategories:\n- docker\ntags:\n- portal\n---\n\n# resource\n\nofficial:\n[https://www.docker.com/](https://www.docker.com/)\n[https://blog.docker.com/](https://blog.docker.com/)\n[https://linuxcontainers.org/](https://linuxcontainers.org/)\n\nawesome:\n[https://github.com/Friz-zy/awesome-linux-containers](https://github.com/Friz-zy/awesome-linux-containers)\n\ngithub:\n[docker-library](https://github.com/docker-library)\n[dockerfile](https://github.com/tianon/dockerfiles)   \n[docker-cheat-sheet](https://github.com/wsargent/docker-cheat-sheet)\n[Chef Cookbook for Docker](https://github.com/chef-cookbooks/docker)\n\ncommunity:\n[dockerpool](http://dockerpool.com/)\n[dockerone](http://dockerone.com)\n[devops-china](http://devops-china.org)\n[ceph china](http://bbs.ceph.org.cn/)    \ncloud stack(http://www.cloudstack-china.org/)\natcontainer(http://atcontainer.com/)\ngoogle plus(https://plus.google.com/u/0/+DockerIo)\nzhihu(https://www.zhihu.com/topic/19950993)\nreddit\nstackoverflow(http://superuser.com/questions/tagged/docker)\n\norganization:\nopen container project: [link](http://www.opencontainers.org/), [doc](http://blog.docker.com/2015/06/open-container-project-foundation/)\noci:[](https://www.opencontainers.org/), [](https://github.com/opencontainers)\nabout:尽管Docker获得广大公有云厂商的大力支持，但是目前容器技术生态中已经存在许多分支与分歧，如rkt项目。为了解决容器生态中的差异化问题，为了从根本上解决生产环境中运用Docker的风险，Google，Intel，Redhat，Microsoft，EMC，IBM，Amazon，VMware，Oracle，Pivotal，Rancher，HPE，Facebook，Twitter等IT大厂于2015年6月共同宣布成立OCI（Open Container Initiative）组织。OCI组织的目标在于建立通用的容器技术标准。除了保障与延续既有容器服务的生命周期外，还通过不断推出标准的创新的容器解决方案赋能开发者。而OCI成员企业也会秉持开放，安全，弹性等核心价值观来发展容器生态。客观而言，OCI组织的出现确立了容器技术的标准，避免容器技术被单一厂商垄断。统一技术标准后，广大企业不用担心未来新兴的容器技术不兼容Docker。\nCNCF: Cloud Native Computing Foundation\n\nconf\nQConf:http://2016.qconshanghai.com/, http://qconferences.com/\nDockerCon\n    link\n        http://www.slideshare.net/Docker/presentations\n        http://www.dockercon.com/\n    2015\n        guidebook app\n        http://europe-2015.dockercon.com/\n        http://dockerconeu2015.sched.org/\n    2016\n        http://2016.dockercon.com/\n        https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/\nContainerCon\nContainerCamp\nOperability 1.0\nGoTo Conference\nSoftware Circus\n容器技术大会\n    http://atcontainer.com/\n有容云\n    http://www.bagevent.com/event/176371\n\ndocker vs x\n    docker vs virtual machine\n        link\n            http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#\n            http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution\n            http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker\n\nmooc\n    https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info\n    \nread:\n- infoq: [infoq cn](http://www.infoq.com/cn/dockers/), [infoq en](https://www.infoq.com/docker-2)\n- bot: [yidian](http://www.yidianzixun.com/home?page=channel&keyword=docker), [toutiao](http://toutiao.com/tag85482990/)\n- book\n    Docker Cookbook\n    Docker技术入门与实战:publish,[opensource](http://dockerpool.com/static/books/docker_practice/index.html)\n    Docker源码分析\n    Docker技术详解与实践 lts        \n    [docker入门实战](http://yuedu.baidu.com/ebook/d817967416fc700abb68fca1)\n    [Service discovery with Docker](http://adetante.github.io/articles/service-discovery-with-docker-1/ )\n- tut\n    [](http://www.alauda.cn/tutorial/)\n    [](http://help.daocloud.io/)        \n    [](https://coreos.com/os/docs/latest/quickstart.html   )        \n- course\n    https://training.docker.com/self-paced-training\n    http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice              \nlanguages:\n- php\n    https://github.com/schmunk42/docker-yii2-app-basic\n    https://github.com/eko/docker-symfony\n    https://github.com/harshjv/docker-laravel\n    https://github.com/tkyk/docker-compose-lamp\n    https://github.com/docker-library/php\n    compose\n    https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml\n    https://github.com/tkyk/docker-compose-lamp\n    https://github.com/larryprice/docker-compose-example\n- py\n    https://github.com/dockerfiles/django-uwsgi-nginx\n    https://github.com/mbentley/docker-django-uwsgi-nginx\n    https://github.com/dockerfiles/django-uwsgi-nginx\n    django:https://docs.docker.com/compose/django/\n    flask:dockercook 3.1\n- ruby\n    rails:https://docs.docker.com/compose/rails/\n- js\n    https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon\n- other\n    https://github.com/docker/compose/blob/master/SWARM.md\n    wordpress:https://docs.docker.com/compose/wordpress/\n\n12 factor\n    http://www.the12factorapp.com/\n    https://12factor.net/\n    https://chixq.com/articles/12-factor-app/\n\n\n        ","slug":"docker-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:16:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ic4000h8psvqk0q5mhf","content":"<h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1><p>official:<br><a href=\"https://www.docker.com/\" target=\"_blank\" rel=\"external\">https://www.docker.com/</a><br><a href=\"https://blog.docker.com/\" target=\"_blank\" rel=\"external\">https://blog.docker.com/</a><br><a href=\"https://linuxcontainers.org/\" target=\"_blank\" rel=\"external\">https://linuxcontainers.org/</a></p>\n<p>awesome:<br><a href=\"https://github.com/Friz-zy/awesome-linux-containers\" target=\"_blank\" rel=\"external\">https://github.com/Friz-zy/awesome-linux-containers</a></p>\n<p>github:<br><a href=\"https://github.com/docker-library\" target=\"_blank\" rel=\"external\">docker-library</a><br><a href=\"https://github.com/tianon/dockerfiles\" target=\"_blank\" rel=\"external\">dockerfile</a><br><a href=\"https://github.com/wsargent/docker-cheat-sheet\" target=\"_blank\" rel=\"external\">docker-cheat-sheet</a><br><a href=\"https://github.com/chef-cookbooks/docker\" target=\"_blank\" rel=\"external\">Chef Cookbook for Docker</a></p>\n<p>community:<br><a href=\"http://dockerpool.com/\" target=\"_blank\" rel=\"external\">dockerpool</a><br><a href=\"http://dockerone.com\" target=\"_blank\" rel=\"external\">dockerone</a><br><a href=\"http://devops-china.org\" target=\"_blank\" rel=\"external\">devops-china</a><br><a href=\"http://bbs.ceph.org.cn/\" target=\"_blank\" rel=\"external\">ceph china</a><br>cloud stack(<a href=\"http://www.cloudstack-china.org/\" target=\"_blank\" rel=\"external\">http://www.cloudstack-china.org/</a>)<br>atcontainer(<a href=\"http://atcontainer.com/\" target=\"_blank\" rel=\"external\">http://atcontainer.com/</a>)<br>google plus(<a href=\"https://plus.google.com/u/0/+DockerIo\" target=\"_blank\" rel=\"external\">https://plus.google.com/u/0/+DockerIo</a>)<br>zhihu(<a href=\"https://www.zhihu.com/topic/19950993\" target=\"_blank\" rel=\"external\">https://www.zhihu.com/topic/19950993</a>)<br>reddit<br>stackoverflow(<a href=\"http://superuser.com/questions/tagged/docker\" target=\"_blank\" rel=\"external\">http://superuser.com/questions/tagged/docker</a>)</p>\n<p>organization:<br>open container project: <a href=\"http://www.opencontainers.org/\" target=\"_blank\" rel=\"external\">link</a>, <a href=\"http://blog.docker.com/2015/06/open-container-project-foundation/\" target=\"_blank\" rel=\"external\">doc</a><br>oci:<a href=\"https://www.opencontainers.org/\" target=\"_blank\" rel=\"external\"></a>, <a href=\"https://github.com/opencontainers\" target=\"_blank\" rel=\"external\"></a><br>about:尽管Docker获得广大公有云厂商的大力支持，但是目前容器技术生态中已经存在许多分支与分歧，如rkt项目。为了解决容器生态中的差异化问题，为了从根本上解决生产环境中运用Docker的风险，Google，Intel，Redhat，Microsoft，EMC，IBM，Amazon，VMware，Oracle，Pivotal，Rancher，HPE，Facebook，Twitter等IT大厂于2015年6月共同宣布成立OCI（Open Container Initiative）组织。OCI组织的目标在于建立通用的容器技术标准。除了保障与延续既有容器服务的生命周期外，还通过不断推出标准的创新的容器解决方案赋能开发者。而OCI成员企业也会秉持开放，安全，弹性等核心价值观来发展容器生态。客观而言，OCI组织的出现确立了容器技术的标准，避免容器技术被单一厂商垄断。统一技术标准后，广大企业不用担心未来新兴的容器技术不兼容Docker。<br>CNCF: Cloud Native Computing Foundation</p>\n<p>conf<br>QConf:<a href=\"http://2016.qconshanghai.com/\" target=\"_blank\" rel=\"external\">http://2016.qconshanghai.com/</a>, <a href=\"http://qconferences.com/\" target=\"_blank\" rel=\"external\">http://qconferences.com/</a><br>DockerCon<br>    link<br>        <a href=\"http://www.slideshare.net/Docker/presentations\" target=\"_blank\" rel=\"external\">http://www.slideshare.net/Docker/presentations</a><br>        <a href=\"http://www.dockercon.com/\" target=\"_blank\" rel=\"external\">http://www.dockercon.com/</a><br>    2015<br>        guidebook app<br>        <a href=\"http://europe-2015.dockercon.com/\" target=\"_blank\" rel=\"external\">http://europe-2015.dockercon.com/</a><br>        <a href=\"http://dockerconeu2015.sched.org/\" target=\"_blank\" rel=\"external\">http://dockerconeu2015.sched.org/</a><br>    2016<br>        <a href=\"http://2016.dockercon.com/\" target=\"_blank\" rel=\"external\">http://2016.dockercon.com/</a><br>        <a href=\"https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/\" target=\"_blank\" rel=\"external\">https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/</a><br>ContainerCon<br>ContainerCamp<br>Operability 1.0<br>GoTo Conference<br>Software Circus<br>容器技术大会<br>    <a href=\"http://atcontainer.com/\" target=\"_blank\" rel=\"external\">http://atcontainer.com/</a><br>有容云<br>    <a href=\"http://www.bagevent.com/event/176371\" target=\"_blank\" rel=\"external\">http://www.bagevent.com/event/176371</a></p>\n<p>docker vs x<br>    docker vs virtual machine<br>        link<br>            <a href=\"http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#</a><br>            <a href=\"http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution</a><br>            <a href=\"http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker</a></p>\n<p>mooc<br>    <a href=\"https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info\" target=\"_blank\" rel=\"external\">https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info</a></p>\n<p>read:</p>\n<ul>\n<li>infoq: <a href=\"http://www.infoq.com/cn/dockers/\" target=\"_blank\" rel=\"external\">infoq cn</a>, <a href=\"https://www.infoq.com/docker-2\" target=\"_blank\" rel=\"external\">infoq en</a></li>\n<li>bot: <a href=\"http://www.yidianzixun.com/home?page=channel&amp;keyword=docker\" target=\"_blank\" rel=\"external\">yidian</a>, <a href=\"http://toutiao.com/tag85482990/\" target=\"_blank\" rel=\"external\">toutiao</a></li>\n<li>book<br>  Docker Cookbook<br>  Docker技术入门与实战:publish,<a href=\"http://dockerpool.com/static/books/docker_practice/index.html\" target=\"_blank\" rel=\"external\">opensource</a><br>  Docker源码分析<br>  Docker技术详解与实践 lts<br>  <a href=\"http://yuedu.baidu.com/ebook/d817967416fc700abb68fca1\" target=\"_blank\" rel=\"external\">docker入门实战</a><br>  <a href=\"http://adetante.github.io/articles/service-discovery-with-docker-1/\" target=\"_blank\" rel=\"external\">Service discovery with Docker</a></li>\n<li>tut<br>  <a href=\"http://www.alauda.cn/tutorial/\" target=\"_blank\" rel=\"external\"></a><br>  <a href=\"http://help.daocloud.io/\" target=\"_blank\" rel=\"external\"></a><br>  <a href=\"https://coreos.com/os/docs/latest/quickstart.html\" target=\"_blank\" rel=\"external\"></a>        </li>\n<li>course<br>  <a href=\"https://training.docker.com/self-paced-training\" target=\"_blank\" rel=\"external\">https://training.docker.com/self-paced-training</a><br>  <a href=\"http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice\" target=\"_blank\" rel=\"external\">http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice</a><br>languages:</li>\n<li>php<br>  <a href=\"https://github.com/schmunk42/docker-yii2-app-basic\" target=\"_blank\" rel=\"external\">https://github.com/schmunk42/docker-yii2-app-basic</a><br>  <a href=\"https://github.com/eko/docker-symfony\" target=\"_blank\" rel=\"external\">https://github.com/eko/docker-symfony</a><br>  <a href=\"https://github.com/harshjv/docker-laravel\" target=\"_blank\" rel=\"external\">https://github.com/harshjv/docker-laravel</a><br>  <a href=\"https://github.com/tkyk/docker-compose-lamp\" target=\"_blank\" rel=\"external\">https://github.com/tkyk/docker-compose-lamp</a><br>  <a href=\"https://github.com/docker-library/php\" target=\"_blank\" rel=\"external\">https://github.com/docker-library/php</a><br>  compose<br>  <a href=\"https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml\" target=\"_blank\" rel=\"external\">https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml</a><br>  <a href=\"https://github.com/tkyk/docker-compose-lamp\" target=\"_blank\" rel=\"external\">https://github.com/tkyk/docker-compose-lamp</a><br>  <a href=\"https://github.com/larryprice/docker-compose-example\" target=\"_blank\" rel=\"external\">https://github.com/larryprice/docker-compose-example</a></li>\n<li>py<br>  <a href=\"https://github.com/dockerfiles/django-uwsgi-nginx\" target=\"_blank\" rel=\"external\">https://github.com/dockerfiles/django-uwsgi-nginx</a><br>  <a href=\"https://github.com/mbentley/docker-django-uwsgi-nginx\" target=\"_blank\" rel=\"external\">https://github.com/mbentley/docker-django-uwsgi-nginx</a><br>  <a href=\"https://github.com/dockerfiles/django-uwsgi-nginx\" target=\"_blank\" rel=\"external\">https://github.com/dockerfiles/django-uwsgi-nginx</a><br>  django:<a href=\"https://docs.docker.com/compose/django/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/django/</a><br>  flask:dockercook 3.1</li>\n<li>ruby<br>  rails:<a href=\"https://docs.docker.com/compose/rails/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/rails/</a></li>\n<li>js<br>  <a href=\"https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon\" target=\"_blank\" rel=\"external\">https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon</a></li>\n<li>other<br>  <a href=\"https://github.com/docker/compose/blob/master/SWARM.md\" target=\"_blank\" rel=\"external\">https://github.com/docker/compose/blob/master/SWARM.md</a><br>  wordpress:<a href=\"https://docs.docker.com/compose/wordpress/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/wordpress/</a></li>\n</ul>\n<p>12 factor<br>    <a href=\"http://www.the12factorapp.com/\" target=\"_blank\" rel=\"external\">http://www.the12factorapp.com/</a><br>    <a href=\"https://12factor.net/\" target=\"_blank\" rel=\"external\">https://12factor.net/</a><br>    <a href=\"https://chixq.com/articles/12-factor-app/\" target=\"_blank\" rel=\"external\">https://chixq.com/articles/12-factor-app/</a></p>\n","excerpt":"","more":"<h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1><p>official:<br><a href=\"https://www.docker.com/\">https://www.docker.com/</a><br><a href=\"https://blog.docker.com/\">https://blog.docker.com/</a><br><a href=\"https://linuxcontainers.org/\">https://linuxcontainers.org/</a></p>\n<p>awesome:<br><a href=\"https://github.com/Friz-zy/awesome-linux-containers\">https://github.com/Friz-zy/awesome-linux-containers</a></p>\n<p>github:<br><a href=\"https://github.com/docker-library\">docker-library</a><br><a href=\"https://github.com/tianon/dockerfiles\">dockerfile</a><br><a href=\"https://github.com/wsargent/docker-cheat-sheet\">docker-cheat-sheet</a><br><a href=\"https://github.com/chef-cookbooks/docker\">Chef Cookbook for Docker</a></p>\n<p>community:<br><a href=\"http://dockerpool.com/\">dockerpool</a><br><a href=\"http://dockerone.com\">dockerone</a><br><a href=\"http://devops-china.org\">devops-china</a><br><a href=\"http://bbs.ceph.org.cn/\">ceph china</a><br>cloud stack(<a href=\"http://www.cloudstack-china.org/\">http://www.cloudstack-china.org/</a>)<br>atcontainer(<a href=\"http://atcontainer.com/\">http://atcontainer.com/</a>)<br>google plus(<a href=\"https://plus.google.com/u/0/+DockerIo\">https://plus.google.com/u/0/+DockerIo</a>)<br>zhihu(<a href=\"https://www.zhihu.com/topic/19950993\">https://www.zhihu.com/topic/19950993</a>)<br>reddit<br>stackoverflow(<a href=\"http://superuser.com/questions/tagged/docker\">http://superuser.com/questions/tagged/docker</a>)</p>\n<p>organization:<br>open container project: <a href=\"http://www.opencontainers.org/\">link</a>, <a href=\"http://blog.docker.com/2015/06/open-container-project-foundation/\">doc</a><br>oci:<a href=\"https://www.opencontainers.org/\"></a>, <a href=\"https://github.com/opencontainers\"></a><br>about:尽管Docker获得广大公有云厂商的大力支持，但是目前容器技术生态中已经存在许多分支与分歧，如rkt项目。为了解决容器生态中的差异化问题，为了从根本上解决生产环境中运用Docker的风险，Google，Intel，Redhat，Microsoft，EMC，IBM，Amazon，VMware，Oracle，Pivotal，Rancher，HPE，Facebook，Twitter等IT大厂于2015年6月共同宣布成立OCI（Open Container Initiative）组织。OCI组织的目标在于建立通用的容器技术标准。除了保障与延续既有容器服务的生命周期外，还通过不断推出标准的创新的容器解决方案赋能开发者。而OCI成员企业也会秉持开放，安全，弹性等核心价值观来发展容器生态。客观而言，OCI组织的出现确立了容器技术的标准，避免容器技术被单一厂商垄断。统一技术标准后，广大企业不用担心未来新兴的容器技术不兼容Docker。<br>CNCF: Cloud Native Computing Foundation</p>\n<p>conf<br>QConf:<a href=\"http://2016.qconshanghai.com/\">http://2016.qconshanghai.com/</a>, <a href=\"http://qconferences.com/\">http://qconferences.com/</a><br>DockerCon<br>    link<br>        <a href=\"http://www.slideshare.net/Docker/presentations\">http://www.slideshare.net/Docker/presentations</a><br>        <a href=\"http://www.dockercon.com/\">http://www.dockercon.com/</a><br>    2015<br>        guidebook app<br>        <a href=\"http://europe-2015.dockercon.com/\">http://europe-2015.dockercon.com/</a><br>        <a href=\"http://dockerconeu2015.sched.org/\">http://dockerconeu2015.sched.org/</a><br>    2016<br>        <a href=\"http://2016.dockercon.com/\">http://2016.dockercon.com/</a><br>        <a href=\"https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/\">https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/</a><br>ContainerCon<br>ContainerCamp<br>Operability 1.0<br>GoTo Conference<br>Software Circus<br>容器技术大会<br>    <a href=\"http://atcontainer.com/\">http://atcontainer.com/</a><br>有容云<br>    <a href=\"http://www.bagevent.com/event/176371\">http://www.bagevent.com/event/176371</a></p>\n<p>docker vs x<br>    docker vs virtual machine<br>        link<br>            <a href=\"http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#\">http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#</a><br>            <a href=\"http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution\">http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution</a><br>            <a href=\"http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker\">http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker</a></p>\n<p>mooc<br>    <a href=\"https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info\">https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info</a></p>\n<p>read:</p>\n<ul>\n<li>infoq: <a href=\"http://www.infoq.com/cn/dockers/\">infoq cn</a>, <a href=\"https://www.infoq.com/docker-2\">infoq en</a></li>\n<li>bot: <a href=\"http://www.yidianzixun.com/home?page=channel&amp;keyword=docker\">yidian</a>, <a href=\"http://toutiao.com/tag85482990/\">toutiao</a></li>\n<li>book<br>  Docker Cookbook<br>  Docker技术入门与实战:publish,<a href=\"http://dockerpool.com/static/books/docker_practice/index.html\">opensource</a><br>  Docker源码分析<br>  Docker技术详解与实践 lts<br>  <a href=\"http://yuedu.baidu.com/ebook/d817967416fc700abb68fca1\">docker入门实战</a><br>  <a href=\"http://adetante.github.io/articles/service-discovery-with-docker-1/\">Service discovery with Docker</a></li>\n<li>tut<br>  <a href=\"http://www.alauda.cn/tutorial/\"></a><br>  <a href=\"http://help.daocloud.io/\"></a><br>  <a href=\"https://coreos.com/os/docs/latest/quickstart.html\"></a>        </li>\n<li>course<br>  <a href=\"https://training.docker.com/self-paced-training\">https://training.docker.com/self-paced-training</a><br>  <a href=\"http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice\">http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice</a><br>languages:</li>\n<li>php<br>  <a href=\"https://github.com/schmunk42/docker-yii2-app-basic\">https://github.com/schmunk42/docker-yii2-app-basic</a><br>  <a href=\"https://github.com/eko/docker-symfony\">https://github.com/eko/docker-symfony</a><br>  <a href=\"https://github.com/harshjv/docker-laravel\">https://github.com/harshjv/docker-laravel</a><br>  <a href=\"https://github.com/tkyk/docker-compose-lamp\">https://github.com/tkyk/docker-compose-lamp</a><br>  <a href=\"https://github.com/docker-library/php\">https://github.com/docker-library/php</a><br>  compose<br>  <a href=\"https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml\">https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml</a><br>  <a href=\"https://github.com/tkyk/docker-compose-lamp\">https://github.com/tkyk/docker-compose-lamp</a><br>  <a href=\"https://github.com/larryprice/docker-compose-example\">https://github.com/larryprice/docker-compose-example</a></li>\n<li>py<br>  <a href=\"https://github.com/dockerfiles/django-uwsgi-nginx\">https://github.com/dockerfiles/django-uwsgi-nginx</a><br>  <a href=\"https://github.com/mbentley/docker-django-uwsgi-nginx\">https://github.com/mbentley/docker-django-uwsgi-nginx</a><br>  <a href=\"https://github.com/dockerfiles/django-uwsgi-nginx\">https://github.com/dockerfiles/django-uwsgi-nginx</a><br>  django:<a href=\"https://docs.docker.com/compose/django/\">https://docs.docker.com/compose/django/</a><br>  flask:dockercook 3.1</li>\n<li>ruby<br>  rails:<a href=\"https://docs.docker.com/compose/rails/\">https://docs.docker.com/compose/rails/</a></li>\n<li>js<br>  <a href=\"https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon\">https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon</a></li>\n<li>other<br>  <a href=\"https://github.com/docker/compose/blob/master/SWARM.md\">https://github.com/docker/compose/blob/master/SWARM.md</a><br>  wordpress:<a href=\"https://docs.docker.com/compose/wordpress/\">https://docs.docker.com/compose/wordpress/</a></li>\n</ul>\n<p>12 factor<br>    <a href=\"http://www.the12factorapp.com/\">http://www.the12factorapp.com/</a><br>    <a href=\"https://12factor.net/\">https://12factor.net/</a><br>    <a href=\"https://chixq.com/articles/12-factor-app/\">https://chixq.com/articles/12-factor-app/</a></p>\n"},{"title":"python portal","_content":"\n# 123","source":"_posts/fullstack-portal.md","raw":"---\ntitle: python portal\ncategories:\n- python\ntags:\n- portal\n---\n\n# 123","slug":"fullstack-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ic7000i8psv45godatp","content":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>","excerpt":"","more":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ncategories:\n- tmp\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2017-01-11T09:26:51.000Z","updated":"2017-01-11T16:32:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71icc000n8psv2q3iscr5","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n","excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\">Deployment</a></p>\n"},{"title":"openstack core","_content":"\n# core","source":"_posts/iaas-openstack-core.md","raw":"---\ntitle: openstack core\ncategories:\n- iaas\ntags:\n- core\n- openstack\n---\n\n# core","slug":"iaas-openstack-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ich000p8psvd8e5qz1q","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"iaas core","_content":"\n# iaas core","source":"_posts/iaas-portal.md","raw":"---\ntitle: iaas core\ncategories:\n- iaas\ntags:\n- portal\n---\n\n# iaas core","slug":"iaas-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71icn000u8psvxkbp9b39","content":"<h1 id=\"iaas-core\"><a href=\"#iaas-core\" class=\"headerlink\" title=\"iaas core\"></a>iaas core</h1>","excerpt":"","more":"<h1 id=\"iaas-core\"><a href=\"#iaas-core\" class=\"headerlink\" title=\"iaas core\"></a>iaas core</h1>"},{"title":"java portal","_content":"\n#  portal","source":"_posts/java-portal.md","raw":"---\ntitle: java portal\ncategories:\n- java\ntags:\n- portal\n---\n\n#  portal","slug":"java-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71icr000x8psvufdlpp8x","content":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>","excerpt":"","more":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>"},{"title":"nodejs core","_content":"\n\n        ","source":"_posts/js-nodejs-core.md","raw":"---\ntitle: nodejs core\ncategories:\n- nodejs\ntags:\n- core\n---\n\n\n        ","slug":"js-nodejs-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71id400128psvtav99pn4","content":"","excerpt":"","more":""},{"title":"js portal","_content":"\n\n        ","source":"_posts/js-portal.md","raw":"---\ntitle: js portal\ncategories:\n- js\ntags:\n- portal\n---\n\n\n        ","slug":"js-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71id800148psv7uso7ijc","content":"","excerpt":"","more":""},{"title":"linux portal","_content":"\n#  ","source":"_posts/linux-portal.md","raw":"---\ntitle: linux portal\ncategories:\n- linux\ntags:\n- portal\n---\n\n#  ","slug":"linux-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:34:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71idf00198psvjzp1fhec","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h1>","excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h1>"},{"title":"microservice portal","_content":"\n# about\n    current\n        多层架构\n            表现层，业务逻辑层，数据层\n            分层设计与优化，合理设计接口，每层可再细分，功能模块可重用\n        单体模式\n            monolith，是目前主流打包方式\n            一个单独的java war文件，rails或node中一个单独的目录\n            优势：业界熟练使用，生态健全，外围工具丰富。易于开发，测试，部署\n            开始项目最简单快捷的方式，充分利用已有代码和工具，不必担心分布式部署。\n            但是应用工程变得负责，敏捷和部署举步维艰，启动时间长，难以采用新技术。可靠性差。\n    微服务架构\n        优势\n            由多个独立运行的微小服务构成\n            使用轻量级通讯机制\n                独立构建部署\n            每个服务保持独立性\n                构建，部署，扩容，容错，数据管理\n            敏捷最大化\n                代码运行速度更高，更短的反馈周期，更简单的使用方法，快速应对变化\n            可以使用不同技术\n                每个服务可以使用独立技术栈\n                易于重构，分散式管理\n            高效团队\n                小规模团队\n                责任明晰，便捷清晰\n                围绕业务功能进行组织，非常灵活\n        不足\n            过度关注服务大小，可能过度拆分\n            分布式系统的构建与部署问题\n            分布式的数据架构\n            测试的复杂度\n            改动带来的沟通成本\n\nlink\n    main\n        http://microservices.io/patterns/microservices.html\nclusterup\n    about\n        life cycle management GUI for docker microservices\n        Real-time monitoring of Docker containers and applications\n        Manage and monitor your app pre-production. We provide app analytics\n    link\n        https://clusterup.io/\n        ","source":"_posts/microservice-portal.md","raw":"---\ntitle: microservice portal\ncategories:\n- microservice\ntags:\n- portal\n---\n\n# about\n    current\n        多层架构\n            表现层，业务逻辑层，数据层\n            分层设计与优化，合理设计接口，每层可再细分，功能模块可重用\n        单体模式\n            monolith，是目前主流打包方式\n            一个单独的java war文件，rails或node中一个单独的目录\n            优势：业界熟练使用，生态健全，外围工具丰富。易于开发，测试，部署\n            开始项目最简单快捷的方式，充分利用已有代码和工具，不必担心分布式部署。\n            但是应用工程变得负责，敏捷和部署举步维艰，启动时间长，难以采用新技术。可靠性差。\n    微服务架构\n        优势\n            由多个独立运行的微小服务构成\n            使用轻量级通讯机制\n                独立构建部署\n            每个服务保持独立性\n                构建，部署，扩容，容错，数据管理\n            敏捷最大化\n                代码运行速度更高，更短的反馈周期，更简单的使用方法，快速应对变化\n            可以使用不同技术\n                每个服务可以使用独立技术栈\n                易于重构，分散式管理\n            高效团队\n                小规模团队\n                责任明晰，便捷清晰\n                围绕业务功能进行组织，非常灵活\n        不足\n            过度关注服务大小，可能过度拆分\n            分布式系统的构建与部署问题\n            分布式的数据架构\n            测试的复杂度\n            改动带来的沟通成本\n\nlink\n    main\n        http://microservices.io/patterns/microservices.html\nclusterup\n    about\n        life cycle management GUI for docker microservices\n        Real-time monitoring of Docker containers and applications\n        Manage and monitor your app pre-production. We provide app analytics\n    link\n        https://clusterup.io/\n        ","slug":"microservice-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:34:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71idj001b8psvqbja36ft","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><pre><code>current\n    多层架构\n        表现层，业务逻辑层，数据层\n        分层设计与优化，合理设计接口，每层可再细分，功能模块可重用\n    单体模式\n        monolith，是目前主流打包方式\n        一个单独的java war文件，rails或node中一个单独的目录\n        优势：业界熟练使用，生态健全，外围工具丰富。易于开发，测试，部署\n        开始项目最简单快捷的方式，充分利用已有代码和工具，不必担心分布式部署。\n        但是应用工程变得负责，敏捷和部署举步维艰，启动时间长，难以采用新技术。可靠性差。\n微服务架构\n    优势\n        由多个独立运行的微小服务构成\n        使用轻量级通讯机制\n            独立构建部署\n        每个服务保持独立性\n            构建，部署，扩容，容错，数据管理\n        敏捷最大化\n            代码运行速度更高，更短的反馈周期，更简单的使用方法，快速应对变化\n        可以使用不同技术\n            每个服务可以使用独立技术栈\n            易于重构，分散式管理\n        高效团队\n            小规模团队\n            责任明晰，便捷清晰\n            围绕业务功能进行组织，非常灵活\n    不足\n        过度关注服务大小，可能过度拆分\n        分布式系统的构建与部署问题\n        分布式的数据架构\n        测试的复杂度\n        改动带来的沟通成本\n</code></pre><p>link<br>    main<br>        <a href=\"http://microservices.io/patterns/microservices.html\" target=\"_blank\" rel=\"external\">http://microservices.io/patterns/microservices.html</a><br>clusterup<br>    about<br>        life cycle management GUI for docker microservices<br>        Real-time monitoring of Docker containers and applications<br>        Manage and monitor your app pre-production. We provide app analytics<br>    link<br>        <a href=\"https://clusterup.io/\" target=\"_blank\" rel=\"external\">https://clusterup.io/</a></p>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><pre><code>current\n    多层架构\n        表现层，业务逻辑层，数据层\n        分层设计与优化，合理设计接口，每层可再细分，功能模块可重用\n    单体模式\n        monolith，是目前主流打包方式\n        一个单独的java war文件，rails或node中一个单独的目录\n        优势：业界熟练使用，生态健全，外围工具丰富。易于开发，测试，部署\n        开始项目最简单快捷的方式，充分利用已有代码和工具，不必担心分布式部署。\n        但是应用工程变得负责，敏捷和部署举步维艰，启动时间长，难以采用新技术。可靠性差。\n微服务架构\n    优势\n        由多个独立运行的微小服务构成\n        使用轻量级通讯机制\n            独立构建部署\n        每个服务保持独立性\n            构建，部署，扩容，容错，数据管理\n        敏捷最大化\n            代码运行速度更高，更短的反馈周期，更简单的使用方法，快速应对变化\n        可以使用不同技术\n            每个服务可以使用独立技术栈\n            易于重构，分散式管理\n        高效团队\n            小规模团队\n            责任明晰，便捷清晰\n            围绕业务功能进行组织，非常灵活\n    不足\n        过度关注服务大小，可能过度拆分\n        分布式系统的构建与部署问题\n        分布式的数据架构\n        测试的复杂度\n        改动带来的沟通成本\n</code></pre><p>link<br>    main<br>        <a href=\"http://microservices.io/patterns/microservices.html\">http://microservices.io/patterns/microservices.html</a><br>clusterup<br>    about<br>        life cycle management GUI for docker microservices<br>        Real-time monitoring of Docker containers and applications<br>        Manage and monitor your app pre-production. We provide app analytics<br>    link<br>        <a href=\"https://clusterup.io/\">https://clusterup.io/</a></p>\n"},{"title":"http core","_content":"\n#  core","source":"_posts/network-http-core.md","raw":"---\ntitle: http core\ncategories:\n- network\ntags:\n- core\n- http\n---\n\n#  core","slug":"network-http-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:34:31.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ido001g8psvh4qib2wo","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"network portal","_content":"\n# ","source":"_posts/network-portal.md","raw":"---\ntitle: network portal\ncategories:\n- network\ntags:\n- portal\n---\n\n# ","slug":"network-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:34:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ids001i8psvzo7y61cd","content":"<p># </p>\n","excerpt":"","more":"<p># </p>\n"},{"title":"cloudfoundry core","_content":"\n# ","source":"_posts/paas-cloudfoundry-core.md","raw":"---\ntitle: cloudfoundry core\ncategories:\n- paas\ntags:\n- core\n- cloudfoundry\n---\n\n# ","slug":"paas-cloudfoundry-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71idx001n8psvc5kda3ef","content":"<p># </p>\n","excerpt":"","more":"<p># </p>\n"},{"title":"openshift core","_content":"\n# ","source":"_posts/paas-openshift-core.md","raw":"---\ntitle: openshift core\ncategories:\n- paas\ntags:\n- core\n- openshift\n---\n\n# ","slug":"paas-openshift-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ie4001p8psvhy2j8r8f","content":"<p># </p>\n","excerpt":"","more":"<p># </p>\n"},{"title":"paas portal","_content":"\n","source":"_posts/paas-portal.md","raw":"---\ntitle: paas portal\ncategories:\n- paas\ntags:\n- portal\n---\n\n","slug":"paas-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ie9001t8psvbs69z8j7","content":"","excerpt":"","more":""},{"title":"django core","_content":"\n# about\n\n    Full stack web frameworks.The most popular web framework in Python.\n\n    Django makes it easier to build better Web apps more quickly and with less code.\n    \n    Django is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. It’s free and open source.\n\n    Ridiculously fast: Django was designed to help developers take applications from concept to completion as quickly as possible.\n\n    Reassuringly secure: Django takes security seriously and helps developers avoid many common security mistakes.\n\n    Exceedingly scalable: Some of the busiest sites on the Web leverage Django’s ability to quickly and flexibly scale.\n\n# link\n\n    - official: https://www.djangoproject.com/\n    - tut: https://docs.djangoproject.com/en/1.10/intro/tutorial01/\n    - awesome: https://github.com/rosarior/awesome-django\n    - community: http://django-china.cn/\n\n# install\n\n    - [install on mac (bare metal)]()\n    - [install on mac (docker)]()\n\n# read\n\n    - djangobook: http://docs.30c.org/djangobook2/; http://djangobook.py3k.cn/2.0/\n\n# mooc\n    \n    - http://www.imooc.com/learn/790\n\n    \n\n","source":"_posts/python-django-core.md","raw":"---\ntitle: django core\ncategories:\n- python\ntags:\n- core\n- django\n---\n\n# about\n\n    Full stack web frameworks.The most popular web framework in Python.\n\n    Django makes it easier to build better Web apps more quickly and with less code.\n    \n    Django is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. It’s free and open source.\n\n    Ridiculously fast: Django was designed to help developers take applications from concept to completion as quickly as possible.\n\n    Reassuringly secure: Django takes security seriously and helps developers avoid many common security mistakes.\n\n    Exceedingly scalable: Some of the busiest sites on the Web leverage Django’s ability to quickly and flexibly scale.\n\n# link\n\n    - official: https://www.djangoproject.com/\n    - tut: https://docs.djangoproject.com/en/1.10/intro/tutorial01/\n    - awesome: https://github.com/rosarior/awesome-django\n    - community: http://django-china.cn/\n\n# install\n\n    - [install on mac (bare metal)]()\n    - [install on mac (docker)]()\n\n# read\n\n    - djangobook: http://docs.30c.org/djangobook2/; http://djangobook.py3k.cn/2.0/\n\n# mooc\n    \n    - http://www.imooc.com/learn/790\n\n    \n\n","slug":"python-django-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-12T09:47:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ief001w8psvaldctusq","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><pre><code>Full stack web frameworks.The most popular web framework in Python.\n\nDjango makes it easier to build better Web apps more quickly and with less code.\n\nDjango is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. It’s free and open source.\n\nRidiculously fast: Django was designed to help developers take applications from concept to completion as quickly as possible.\n\nReassuringly secure: Django takes security seriously and helps developers avoid many common security mistakes.\n\nExceedingly scalable: Some of the busiest sites on the Web leverage Django’s ability to quickly and flexibly scale.\n</code></pre><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>- official: https://www.djangoproject.com/\n- tut: https://docs.djangoproject.com/en/1.10/intro/tutorial01/\n- awesome: https://github.com/rosarior/awesome-django\n- community: http://django-china.cn/\n</code></pre><h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><pre><code>- [install on mac (bare metal)]()\n- [install on mac (docker)]()\n</code></pre><h1 id=\"read\"><a href=\"#read\" class=\"headerlink\" title=\"read\"></a>read</h1><pre><code>- djangobook: http://docs.30c.org/djangobook2/; http://djangobook.py3k.cn/2.0/\n</code></pre><h1 id=\"mooc\"><a href=\"#mooc\" class=\"headerlink\" title=\"mooc\"></a>mooc</h1><pre><code>- http://www.imooc.com/learn/790\n</code></pre>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><pre><code>Full stack web frameworks.The most popular web framework in Python.\n\nDjango makes it easier to build better Web apps more quickly and with less code.\n\nDjango is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. It’s free and open source.\n\nRidiculously fast: Django was designed to help developers take applications from concept to completion as quickly as possible.\n\nReassuringly secure: Django takes security seriously and helps developers avoid many common security mistakes.\n\nExceedingly scalable: Some of the busiest sites on the Web leverage Django’s ability to quickly and flexibly scale.\n</code></pre><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>- official: https://www.djangoproject.com/\n- tut: https://docs.djangoproject.com/en/1.10/intro/tutorial01/\n- awesome: https://github.com/rosarior/awesome-django\n- community: http://django-china.cn/\n</code></pre><h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><pre><code>- [install on mac (bare metal)]()\n- [install on mac (docker)]()\n</code></pre><h1 id=\"read\"><a href=\"#read\" class=\"headerlink\" title=\"read\"></a>read</h1><pre><code>- djangobook: http://docs.30c.org/djangobook2/; http://djangobook.py3k.cn/2.0/\n</code></pre><h1 id=\"mooc\"><a href=\"#mooc\" class=\"headerlink\" title=\"mooc\"></a>mooc</h1><pre><code>- http://www.imooc.com/learn/790\n</code></pre>"},{"title":"install django on mac","update":"2017-01-12T09:43:23.000Z","_content":"\n# install on mac (bare metal)\n\n# install on mac (docker)\n- download & install docker for mac;\n    - link: https://docs.docker.com/compose/django/;\n    - Define the project components;\n        1. create folder;\n        2. create Dockerfile;\n            ```\n             FROM python:2.7\n             ENV PYTHONUNBUFFERED 1\n             RUN mkdir /code\n             WORKDIR /code\n             ADD requirements.txt /code/\n             RUN pip install -r requirements.txt\n             ADD . /code/\n            ```\n        3. create requirements.txt;\n            ```\n             Django\n             psycopg2\n            ```\n        4. create docker-compose.yml\n            ```\n             version: '2'\n             services:\n               db:\n                 image: postgres\n               web:\n                 build: .\n                 command: python manage.py runserver 0.0.0.0:8000\n                 volumes:\n                   - .:/code\n                 ports:\n                   - \"8000:8000\"\n                 depends_on:\n                   - db\n            ```\n    - Create a Django project;\n        1. goto root dir;\n        2. docker-compose run web django-admin.py startproject composeexample .\n        3. ls -l; sudo chown -R $USER:$USER .;\n    - Connect the database;\n        1. edit composeexample/settings.py;\n        ```\n        DATABASES = {\n             'default': {\n                 'ENGINE': 'django.db.backends.postgresql',\n                 'NAME': 'postgres',\n                 'USER': 'postgres',\n                 'HOST': 'db',\n                 'PORT': 5432,\n             }\n         }\n        ```\n        2. $ docker-compose up","source":"_posts/python-django-install.md","raw":"---\ntitle: install django on mac\nupdate: 2017-01-12 17:43:23\ncategories:\n- python\ntags: \n- install\n- python\n- django\n- docker\n---\n\n# install on mac (bare metal)\n\n# install on mac (docker)\n- download & install docker for mac;\n    - link: https://docs.docker.com/compose/django/;\n    - Define the project components;\n        1. create folder;\n        2. create Dockerfile;\n            ```\n             FROM python:2.7\n             ENV PYTHONUNBUFFERED 1\n             RUN mkdir /code\n             WORKDIR /code\n             ADD requirements.txt /code/\n             RUN pip install -r requirements.txt\n             ADD . /code/\n            ```\n        3. create requirements.txt;\n            ```\n             Django\n             psycopg2\n            ```\n        4. create docker-compose.yml\n            ```\n             version: '2'\n             services:\n               db:\n                 image: postgres\n               web:\n                 build: .\n                 command: python manage.py runserver 0.0.0.0:8000\n                 volumes:\n                   - .:/code\n                 ports:\n                   - \"8000:8000\"\n                 depends_on:\n                   - db\n            ```\n    - Create a Django project;\n        1. goto root dir;\n        2. docker-compose run web django-admin.py startproject composeexample .\n        3. ls -l; sudo chown -R $USER:$USER .;\n    - Connect the database;\n        1. edit composeexample/settings.py;\n        ```\n        DATABASES = {\n             'default': {\n                 'ENGINE': 'django.db.backends.postgresql',\n                 'NAME': 'postgres',\n                 'USER': 'postgres',\n                 'HOST': 'db',\n                 'PORT': 5432,\n             }\n         }\n        ```\n        2. $ docker-compose up","slug":"python-django-install","published":1,"date":"2017-01-12T09:43:23.000Z","updated":"2017-01-12T09:49:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71iej001z8psv9qad9c5w","content":"<h1 id=\"install-on-mac-bare-metal\"><a href=\"#install-on-mac-bare-metal\" class=\"headerlink\" title=\"install on mac (bare metal)\"></a>install on mac (bare metal)</h1><h1 id=\"install-on-mac-docker\"><a href=\"#install-on-mac-docker\" class=\"headerlink\" title=\"install on mac (docker)\"></a>install on mac (docker)</h1><ul>\n<li><p>download &amp; install docker for mac;</p>\n<ul>\n<li>link: <a href=\"https://docs.docker.com/compose/django/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/django/</a>;</li>\n<li><p>Define the project components;</p>\n<ol>\n<li>create folder;</li>\n<li><p>create Dockerfile;</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">FROM python:2.7</div><div class=\"line\">ENV PYTHONUNBUFFERED 1</div><div class=\"line\">RUN mkdir /code</div><div class=\"line\">WORKDIR /code</div><div class=\"line\">ADD requirements.txt /code/</div><div class=\"line\">RUN pip install -r requirements.txt</div><div class=\"line\">ADD . /code/</div></pre></td></tr></table></figure>\n</li>\n<li><p>create requirements.txt;</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Django</div><div class=\"line\">psycopg2</div></pre></td></tr></table></figure>\n</li>\n<li><p>create docker-compose.yml</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">version: &apos;2&apos;</div><div class=\"line\">services:</div><div class=\"line\">  db:</div><div class=\"line\">    image: postgres</div><div class=\"line\">  web:</div><div class=\"line\">    build: .</div><div class=\"line\">    command: python manage.py runserver 0.0.0.0:8000</div><div class=\"line\">    volumes:</div><div class=\"line\">      - .:/code</div><div class=\"line\">    ports:</div><div class=\"line\">      - &quot;8000:8000&quot;</div><div class=\"line\">    depends_on:</div><div class=\"line\">      - db</div></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>Create a Django project;</p>\n<ol>\n<li>goto root dir;</li>\n<li>docker-compose run web django-admin.py startproject composeexample .</li>\n<li>ls -l; sudo chown -R $USER:$USER .;</li>\n</ol>\n</li>\n<li><p>Connect the database;</p>\n<ol>\n<li><p>edit composeexample/settings.py;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">DATABASES = &#123;</div><div class=\"line\">     &apos;default&apos;: &#123;</div><div class=\"line\">         &apos;ENGINE&apos;: &apos;django.db.backends.postgresql&apos;,</div><div class=\"line\">         &apos;NAME&apos;: &apos;postgres&apos;,</div><div class=\"line\">         &apos;USER&apos;: &apos;postgres&apos;,</div><div class=\"line\">         &apos;HOST&apos;: &apos;db&apos;,</div><div class=\"line\">         &apos;PORT&apos;: 5432,</div><div class=\"line\">     &#125;</div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>$ docker-compose up</p>\n</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"install-on-mac-bare-metal\"><a href=\"#install-on-mac-bare-metal\" class=\"headerlink\" title=\"install on mac (bare metal)\"></a>install on mac (bare metal)</h1><h1 id=\"install-on-mac-docker\"><a href=\"#install-on-mac-docker\" class=\"headerlink\" title=\"install on mac (docker)\"></a>install on mac (docker)</h1><ul>\n<li><p>download &amp; install docker for mac;</p>\n<ul>\n<li>link: <a href=\"https://docs.docker.com/compose/django/\">https://docs.docker.com/compose/django/</a>;</li>\n<li><p>Define the project components;</p>\n<ol>\n<li>create folder;</li>\n<li><p>create Dockerfile;</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">FROM python:2.7</div><div class=\"line\">ENV PYTHONUNBUFFERED 1</div><div class=\"line\">RUN mkdir /code</div><div class=\"line\">WORKDIR /code</div><div class=\"line\">ADD requirements.txt /code/</div><div class=\"line\">RUN pip install -r requirements.txt</div><div class=\"line\">ADD . /code/</div></pre></td></tr></table></figure>\n</li>\n<li><p>create requirements.txt;</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Django</div><div class=\"line\">psycopg2</div></pre></td></tr></table></figure>\n</li>\n<li><p>create docker-compose.yml</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">version: &apos;2&apos;</div><div class=\"line\">services:</div><div class=\"line\">  db:</div><div class=\"line\">    image: postgres</div><div class=\"line\">  web:</div><div class=\"line\">    build: .</div><div class=\"line\">    command: python manage.py runserver 0.0.0.0:8000</div><div class=\"line\">    volumes:</div><div class=\"line\">      - .:/code</div><div class=\"line\">    ports:</div><div class=\"line\">      - &quot;8000:8000&quot;</div><div class=\"line\">    depends_on:</div><div class=\"line\">      - db</div></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>Create a Django project;</p>\n<ol>\n<li>goto root dir;</li>\n<li>docker-compose run web django-admin.py startproject composeexample .</li>\n<li>ls -l; sudo chown -R $USER:$USER .;</li>\n</ol>\n</li>\n<li><p>Connect the database;</p>\n<ol>\n<li><p>edit composeexample/settings.py;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">DATABASES = &#123;</div><div class=\"line\">     &apos;default&apos;: &#123;</div><div class=\"line\">         &apos;ENGINE&apos;: &apos;django.db.backends.postgresql&apos;,</div><div class=\"line\">         &apos;NAME&apos;: &apos;postgres&apos;,</div><div class=\"line\">         &apos;USER&apos;: &apos;postgres&apos;,</div><div class=\"line\">         &apos;HOST&apos;: &apos;db&apos;,</div><div class=\"line\">         &apos;PORT&apos;: 5432,</div><div class=\"line\">     &#125;</div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>$ docker-compose up</p>\n</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"python portal","_content":"\n# about\n\n# link\n\n    - official: \n    - pep: http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/python_style_rules/（至少过一遍，否则视野会局限，可以不看Python书但需要熟读官方手册）\n    - awesome\n    https://github.com/vinta/awesome-python\n    https://github.com/Junnplus/awesome-python-books\n","source":"_posts/python-portal.md","raw":"---\ntitle: python portal\ncategories:\n- python\ntags:\n- portal\n---\n\n# about\n\n# link\n\n    - official: \n    - pep: http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/python_style_rules/（至少过一遍，否则视野会局限，可以不看Python书但需要熟读官方手册）\n    - awesome\n    https://github.com/vinta/awesome-python\n    https://github.com/Junnplus/awesome-python-books\n","slug":"python-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-12T09:42:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71ien00238psvut5ll6i9","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>- official: \n- pep: http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/python_style_rules/（至少过一遍，否则视野会局限，可以不看Python书但需要熟读官方手册）\n- awesome\nhttps://github.com/vinta/awesome-python\nhttps://github.com/Junnplus/awesome-python-books\n</code></pre>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>- official: \n- pep: http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/python_style_rules/（至少过一遍，否则视野会局限，可以不看Python书但需要熟读官方手册）\n- awesome\nhttps://github.com/vinta/awesome-python\nhttps://github.com/Junnplus/awesome-python-books\n</code></pre>"},{"title":"ruby on rails core","_content":"\n# 123","source":"_posts/ruby-rails-core.md","raw":"---\ntitle: ruby on rails core\ncategories:\n- ruby\ntags:\n- core\n- rails\n---\n\n# 123","slug":"ruby-rails-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:36:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cixu71iep00268psv4bq2iftu","content":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>","excerpt":"","more":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>"},{"title":"docker image","_content":"\n# about docker image\n\n- standard: [Docker Image Specification](https://github.com/docker/docker/blob/master/image/spec/v1.md)\n\n- layer\n\n        r & w layer-container\n        add nginx-image2\n        add nginx-image1\n        ubuntu-base image\n        kernel-bootfs\n\n- duplication while writing 写时复制机制\n\n# docker image command\n        \n- docker pull\n\n- docker run\n\n- docker images: check out\n    \n        docker images ububtu\n\n- docker inspect\n\n        docker inspect ubuntu\n\n- docker search: AUTOMATED-automatic build\n\n- docker rmi: delete image\n\n        docker rmi c03k349dfjn2\n    \n    -f if some container depends on this image:\n\n        docker rmi -f ubuntu\n    \n    delete all:\n        \n        docker rm $(docker ps -a -q)\n\n- docker commit: one way to create local image, the other way is dockerfile\n    commit changes to user image\n    \n        sudo docker run -t -i ubuntu\n        apt-get install sqlite3\n        echo 'test docker commit' >> hellodocker\n        exit\n        sudo docker commit -m=\"message\" --author=\"ag\" CONTAINERID ag/sqlite3:v1\n        sudo docker run -t -i ag/sqlite3:v1\n        cat hellodocker\n        sqlite3 -version\n\n- docker build: build image with dockerfile\n    \n    -rm=false: do not delete the tmp image while building\n\n    -t: set namespace, repo name, tag\n\n        sudo docker build -t ag/test:v1\n\n- docker tag\n\n        sudo docker tag ag/test:v1 ag/test:v2\n        (v1 and v2 will have the same image id)\n    \n    build with github:\n    \n        sudo docker build -t ag/test:v1 git://github.com/ag/dockerfile.git\n\n- docker save\n\n- docker load\n\n- docker diff\n    \n        docker diff container","source":"_posts/docker-image-detail.md","raw":"---\ntitle: docker image\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about docker image\n\n- standard: [Docker Image Specification](https://github.com/docker/docker/blob/master/image/spec/v1.md)\n\n- layer\n\n        r & w layer-container\n        add nginx-image2\n        add nginx-image1\n        ubuntu-base image\n        kernel-bootfs\n\n- duplication while writing 写时复制机制\n\n# docker image command\n        \n- docker pull\n\n- docker run\n\n- docker images: check out\n    \n        docker images ububtu\n\n- docker inspect\n\n        docker inspect ubuntu\n\n- docker search: AUTOMATED-automatic build\n\n- docker rmi: delete image\n\n        docker rmi c03k349dfjn2\n    \n    -f if some container depends on this image:\n\n        docker rmi -f ubuntu\n    \n    delete all:\n        \n        docker rm $(docker ps -a -q)\n\n- docker commit: one way to create local image, the other way is dockerfile\n    commit changes to user image\n    \n        sudo docker run -t -i ubuntu\n        apt-get install sqlite3\n        echo 'test docker commit' >> hellodocker\n        exit\n        sudo docker commit -m=\"message\" --author=\"ag\" CONTAINERID ag/sqlite3:v1\n        sudo docker run -t -i ag/sqlite3:v1\n        cat hellodocker\n        sqlite3 -version\n\n- docker build: build image with dockerfile\n    \n    -rm=false: do not delete the tmp image while building\n\n    -t: set namespace, repo name, tag\n\n        sudo docker build -t ag/test:v1\n\n- docker tag\n\n        sudo docker tag ag/test:v1 ag/test:v2\n        (v1 and v2 will have the same image id)\n    \n    build with github:\n    \n        sudo docker build -t ag/test:v1 git://github.com/ag/dockerfile.git\n\n- docker save\n\n- docker load\n\n- docker diff\n    \n        docker diff container","slug":"docker-image-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T11:50:32.000Z","_id":"cixvpwb530008y9svnulrqaze","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"about-docker-image\"><a href=\"#about-docker-image\" class=\"headerlink\" title=\"about docker image\"></a>about docker image</h1><ul>\n<li><p>standard: <a href=\"https://github.com/docker/docker/blob/master/image/spec/v1.md\" target=\"_blank\" rel=\"external\">Docker Image Specification</a></p>\n</li>\n<li><p>layer</p>\n<pre><code>r &amp; w layer-container\nadd nginx-image2\nadd nginx-image1\nubuntu-base image\nkernel-bootfs\n</code></pre></li>\n<li><p>duplication while writing 写时复制机制</p>\n</li>\n</ul>\n<h1 id=\"docker-image-command\"><a href=\"#docker-image-command\" class=\"headerlink\" title=\"docker image command\"></a>docker image command</h1><ul>\n<li><p>docker pull</p>\n</li>\n<li><p>docker run</p>\n</li>\n<li><p>docker images: check out</p>\n<pre><code>docker images ububtu\n</code></pre></li>\n<li><p>docker inspect</p>\n<pre><code>docker inspect ubuntu\n</code></pre></li>\n<li><p>docker search: AUTOMATED-automatic build</p>\n</li>\n<li><p>docker rmi: delete image</p>\n<pre><code>docker rmi c03k349dfjn2\n</code></pre><p>  -f if some container depends on this image:</p>\n<pre><code>docker rmi -f ubuntu\n</code></pre><p>  delete all:</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre></li>\n<li><p>docker commit: one way to create local image, the other way is dockerfile<br>  commit changes to user image</p>\n<pre><code>sudo docker run -t -i ubuntu\napt-get install sqlite3\necho &apos;test docker commit&apos; &gt;&gt; hellodocker\nexit\nsudo docker commit -m=&quot;message&quot; --author=&quot;ag&quot; CONTAINERID ag/sqlite3:v1\nsudo docker run -t -i ag/sqlite3:v1\ncat hellodocker\nsqlite3 -version\n</code></pre></li>\n<li><p>docker build: build image with dockerfile</p>\n<p>  -rm=false: do not delete the tmp image while building</p>\n<p>  -t: set namespace, repo name, tag</p>\n<pre><code>sudo docker build -t ag/test:v1\n</code></pre></li>\n<li><p>docker tag</p>\n<pre><code>sudo docker tag ag/test:v1 ag/test:v2\n(v1 and v2 will have the same image id)\n</code></pre><p>  build with github:</p>\n<pre><code>sudo docker build -t ag/test:v1 git://github.com/ag/dockerfile.git\n</code></pre></li>\n<li><p>docker save</p>\n</li>\n<li><p>docker load</p>\n</li>\n<li><p>docker diff</p>\n<pre><code>docker diff container\n</code></pre></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about-docker-image\"><a href=\"#about-docker-image\" class=\"headerlink\" title=\"about docker image\"></a>about docker image</h1><ul>\n<li><p>standard: <a href=\"https://github.com/docker/docker/blob/master/image/spec/v1.md\">Docker Image Specification</a></p>\n</li>\n<li><p>layer</p>\n<pre><code>r &amp; w layer-container\nadd nginx-image2\nadd nginx-image1\nubuntu-base image\nkernel-bootfs\n</code></pre></li>\n<li><p>duplication while writing 写时复制机制</p>\n</li>\n</ul>\n<h1 id=\"docker-image-command\"><a href=\"#docker-image-command\" class=\"headerlink\" title=\"docker image command\"></a>docker image command</h1><ul>\n<li><p>docker pull</p>\n</li>\n<li><p>docker run</p>\n</li>\n<li><p>docker images: check out</p>\n<pre><code>docker images ububtu\n</code></pre></li>\n<li><p>docker inspect</p>\n<pre><code>docker inspect ubuntu\n</code></pre></li>\n<li><p>docker search: AUTOMATED-automatic build</p>\n</li>\n<li><p>docker rmi: delete image</p>\n<pre><code>docker rmi c03k349dfjn2\n</code></pre><p>  -f if some container depends on this image:</p>\n<pre><code>docker rmi -f ubuntu\n</code></pre><p>  delete all:</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre></li>\n<li><p>docker commit: one way to create local image, the other way is dockerfile<br>  commit changes to user image</p>\n<pre><code>sudo docker run -t -i ubuntu\napt-get install sqlite3\necho &apos;test docker commit&apos; &gt;&gt; hellodocker\nexit\nsudo docker commit -m=&quot;message&quot; --author=&quot;ag&quot; CONTAINERID ag/sqlite3:v1\nsudo docker run -t -i ag/sqlite3:v1\ncat hellodocker\nsqlite3 -version\n</code></pre></li>\n<li><p>docker build: build image with dockerfile</p>\n<p>  -rm=false: do not delete the tmp image while building</p>\n<p>  -t: set namespace, repo name, tag</p>\n<pre><code>sudo docker build -t ag/test:v1\n</code></pre></li>\n<li><p>docker tag</p>\n<pre><code>sudo docker tag ag/test:v1 ag/test:v2\n(v1 and v2 will have the same image id)\n</code></pre><p>  build with github:</p>\n<pre><code>sudo docker build -t ag/test:v1 git://github.com/ag/dockerfile.git\n</code></pre></li>\n<li><p>docker save</p>\n</li>\n<li><p>docker load</p>\n</li>\n<li><p>docker diff</p>\n<pre><code>docker diff container\n</code></pre></li>\n</ul>\n"},{"title":"dockerfile","_content":"\n# about dockerfile\n\n\n# dockerfile command\n\n- point to a Dockerfile anywhere in your file system\n    \n        docker build -f /path/to/a/Dockerfile .\n\n- specify a repository and tag at which to save the new image if the build succeeds\n    \n        docker build -t shykes/myapp .\n\n# dockerfile keyword\n\n- FROM: base image\n\n- MAINTAINER\n\n        MAINTAINER ag \"allengaller@gmail.com\"\n\n- USER: set user\n\n        USER root\n\n- RUN: run system cmd\n\n        RUN apt-get update\n        RUN [\"apt-get\", \"update\"]\n        RUN apt-get install -y nginx\n        RUN touch test.txt && echo \"abc\" >> abc.txt\n\n- EXPOSE: expose port\n\n- ADD\n\n    The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the container at the path <dest>.\n    \n    pattern: ADD <src>... <dest>; ADD [\"<src>\",... \"<dest>\"]\n    add folder: ADD /webapp /opt/webapp\n    add file: ADD abc.txt /opt/\n    add network file: ADD https://www.baidu.com/img/bd_logo1.png /opt/\n\n- ENV: set env variable\n\n        ENV WEBAPP_PORT = 9090\n\n- WORKDIR: set working directory\n    \n    The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.The WORKDIR instruction can resolve environment variables previously set using ENV. You can only use environment variables explicitly set in the Dockerfile. For example:\n\n        ENV DIRPATH /path\n        WORKDIR $DIRPATH/$DIRNAME\n        RUN pwd\n\n    The output of the final pwd command in this Dockerfile would be /path/$DIRNAME.It can be used multiple times in the one Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:\n\n        WORKDIR /a\n        WORKDIR b\n        WORKDIR c\n        RUN pwd\n\n    The output of the final pwd command in this Dockerfile would be /a/b/c.\n    \n        WORKDIR /opt/\n\n- ENTRYPOINT: set boot command, append parameter to boot cmd\n    \n    An ENTRYPOINT allows you to configure a container that will run as an executable.For example, the following will start nginx with its default content, listening on port 80:\n            \n        docker run -i -t --rm -p 80:80 nginx\n    \n        ENTRYPOINT [\"ls\"]\n        ENTRYPOINT [\"ls\"]\n        CMD [\"-l\", \"-a\"]\n\n- CMD: set boot parameter\n    \n        CMD [\"ls\", \"-a\", \"-l\"]\n        CMD ls -l -a\n\n- VOLUME: set volume\n    \n        VOLUME [\"/data\", \"/var/www\"]\n\n- ONBUILD: trigger for child image\n    \n        ONBUILD ADD . /app/src\n        ONBUILD RUN echo \"on build excuted\" >> onbuild.txt\n\n- ARG\n\n- STOPSIGNAL\n\n# best practice [link](https://docs.docker.com/engine/articles/dockerfile_best-practices/)\n\n- Containers should be ephemeral\n\n    The container produced by the image your Dockerfile defines should be as ephemeral as possible.By “ephemeral,” we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration.\n\n- Use a .dockerignore file\n\n    In most cases, it’s best to put each Dockerfile in an empty directory. Then, add to that directory only the files needed for building the Dockerfile. To increase the build’s performance, you can exclude files and directories by adding a .dockerignore file to that directory as well. This file supports exclusion patterns similar to .gitignore files. For information on creating one, see the .dockerignore file.\n    \n- Avoid installing unnecessary packages\n\n    In order to reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be “nice to have.” For example, you don’t need to include a text editor in a database image.\n\n- Run only one process per container\n\n    In almost all cases, you should only run a single process in a single container. Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. If that service depends on another service, make use of container linking.\n\n- Minimize the number of layers\n\n    You need to find the balance between readability (and thus long-term maintainability) of the Dockerfile and minimizing the number of layers it uses. Be strategic and cautious about the number of layers you use.\n\n- Sort multi-line arguments\n\n    Here’s an example from the buildpack-deps image:\n\n    RUN apt-get update && apt-get install -y \\\n      bzr \\\n      cvs \\\n      git \\\n      mercurial \\\n      subversion\n\n- Build cache\n\n# .dockerignore\n\n    */temp*\n    */*/temp*\n    temp?\n","source":"_posts/docker-dockerfile-detail.md","raw":"---\ntitle: dockerfile\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about dockerfile\n\n\n# dockerfile command\n\n- point to a Dockerfile anywhere in your file system\n    \n        docker build -f /path/to/a/Dockerfile .\n\n- specify a repository and tag at which to save the new image if the build succeeds\n    \n        docker build -t shykes/myapp .\n\n# dockerfile keyword\n\n- FROM: base image\n\n- MAINTAINER\n\n        MAINTAINER ag \"allengaller@gmail.com\"\n\n- USER: set user\n\n        USER root\n\n- RUN: run system cmd\n\n        RUN apt-get update\n        RUN [\"apt-get\", \"update\"]\n        RUN apt-get install -y nginx\n        RUN touch test.txt && echo \"abc\" >> abc.txt\n\n- EXPOSE: expose port\n\n- ADD\n\n    The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the container at the path <dest>.\n    \n    pattern: ADD <src>... <dest>; ADD [\"<src>\",... \"<dest>\"]\n    add folder: ADD /webapp /opt/webapp\n    add file: ADD abc.txt /opt/\n    add network file: ADD https://www.baidu.com/img/bd_logo1.png /opt/\n\n- ENV: set env variable\n\n        ENV WEBAPP_PORT = 9090\n\n- WORKDIR: set working directory\n    \n    The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.The WORKDIR instruction can resolve environment variables previously set using ENV. You can only use environment variables explicitly set in the Dockerfile. For example:\n\n        ENV DIRPATH /path\n        WORKDIR $DIRPATH/$DIRNAME\n        RUN pwd\n\n    The output of the final pwd command in this Dockerfile would be /path/$DIRNAME.It can be used multiple times in the one Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:\n\n        WORKDIR /a\n        WORKDIR b\n        WORKDIR c\n        RUN pwd\n\n    The output of the final pwd command in this Dockerfile would be /a/b/c.\n    \n        WORKDIR /opt/\n\n- ENTRYPOINT: set boot command, append parameter to boot cmd\n    \n    An ENTRYPOINT allows you to configure a container that will run as an executable.For example, the following will start nginx with its default content, listening on port 80:\n            \n        docker run -i -t --rm -p 80:80 nginx\n    \n        ENTRYPOINT [\"ls\"]\n        ENTRYPOINT [\"ls\"]\n        CMD [\"-l\", \"-a\"]\n\n- CMD: set boot parameter\n    \n        CMD [\"ls\", \"-a\", \"-l\"]\n        CMD ls -l -a\n\n- VOLUME: set volume\n    \n        VOLUME [\"/data\", \"/var/www\"]\n\n- ONBUILD: trigger for child image\n    \n        ONBUILD ADD . /app/src\n        ONBUILD RUN echo \"on build excuted\" >> onbuild.txt\n\n- ARG\n\n- STOPSIGNAL\n\n# best practice [link](https://docs.docker.com/engine/articles/dockerfile_best-practices/)\n\n- Containers should be ephemeral\n\n    The container produced by the image your Dockerfile defines should be as ephemeral as possible.By “ephemeral,” we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration.\n\n- Use a .dockerignore file\n\n    In most cases, it’s best to put each Dockerfile in an empty directory. Then, add to that directory only the files needed for building the Dockerfile. To increase the build’s performance, you can exclude files and directories by adding a .dockerignore file to that directory as well. This file supports exclusion patterns similar to .gitignore files. For information on creating one, see the .dockerignore file.\n    \n- Avoid installing unnecessary packages\n\n    In order to reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be “nice to have.” For example, you don’t need to include a text editor in a database image.\n\n- Run only one process per container\n\n    In almost all cases, you should only run a single process in a single container. Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. If that service depends on another service, make use of container linking.\n\n- Minimize the number of layers\n\n    You need to find the balance between readability (and thus long-term maintainability) of the Dockerfile and minimizing the number of layers it uses. Be strategic and cautious about the number of layers you use.\n\n- Sort multi-line arguments\n\n    Here’s an example from the buildpack-deps image:\n\n    RUN apt-get update && apt-get install -y \\\n      bzr \\\n      cvs \\\n      git \\\n      mercurial \\\n      subversion\n\n- Build cache\n\n# .dockerignore\n\n    */temp*\n    */*/temp*\n    temp?\n","slug":"docker-dockerfile-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T11:46:41.000Z","_id":"cixvpwgnz000by9svilna5rsc","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"about-dockerfile\"><a href=\"#about-dockerfile\" class=\"headerlink\" title=\"about dockerfile\"></a>about dockerfile</h1><h1 id=\"dockerfile-command\"><a href=\"#dockerfile-command\" class=\"headerlink\" title=\"dockerfile command\"></a>dockerfile command</h1><ul>\n<li><p>point to a Dockerfile anywhere in your file system</p>\n<pre><code>docker build -f /path/to/a/Dockerfile .\n</code></pre></li>\n<li><p>specify a repository and tag at which to save the new image if the build succeeds</p>\n<pre><code>docker build -t shykes/myapp .\n</code></pre></li>\n</ul>\n<h1 id=\"dockerfile-keyword\"><a href=\"#dockerfile-keyword\" class=\"headerlink\" title=\"dockerfile keyword\"></a>dockerfile keyword</h1><ul>\n<li><p>FROM: base image</p>\n</li>\n<li><p>MAINTAINER</p>\n<pre><code>MAINTAINER ag &quot;allengaller@gmail.com&quot;\n</code></pre></li>\n<li><p>USER: set user</p>\n<pre><code>USER root\n</code></pre></li>\n<li><p>RUN: run system cmd</p>\n<pre><code>RUN apt-get update\nRUN [&quot;apt-get&quot;, &quot;update&quot;]\nRUN apt-get install -y nginx\nRUN touch test.txt &amp;&amp; echo &quot;abc&quot; &gt;&gt; abc.txt\n</code></pre></li>\n<li><p>EXPOSE: expose port</p>\n</li>\n<li><p>ADD</p>\n<p>  The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the container at the path <dest>.</dest></src></p>\n<p>  pattern: ADD <src>… <dest>; ADD [“<src>“,… “<dest>“]<br>  add folder: ADD /webapp /opt/webapp<br>  add file: ADD abc.txt /opt/<br>  add network file: ADD <a href=\"https://www.baidu.com/img/bd_logo1.png\" target=\"_blank\" rel=\"external\">https://www.baidu.com/img/bd_logo1.png</a> /opt/</dest></src></dest></src></p>\n</li>\n<li><p>ENV: set env variable</p>\n<pre><code>ENV WEBAPP_PORT = 9090\n</code></pre></li>\n<li><p>WORKDIR: set working directory</p>\n<p>  The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.The WORKDIR instruction can resolve environment variables previously set using ENV. You can only use environment variables explicitly set in the Dockerfile. For example:</p>\n<pre><code>ENV DIRPATH /path\nWORKDIR $DIRPATH/$DIRNAME\nRUN pwd\n</code></pre><p>  The output of the final pwd command in this Dockerfile would be /path/$DIRNAME.It can be used multiple times in the one Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:</p>\n<pre><code>WORKDIR /a\nWORKDIR b\nWORKDIR c\nRUN pwd\n</code></pre><p>  The output of the final pwd command in this Dockerfile would be /a/b/c.</p>\n<pre><code>WORKDIR /opt/\n</code></pre></li>\n<li><p>ENTRYPOINT: set boot command, append parameter to boot cmd</p>\n<p>  An ENTRYPOINT allows you to configure a container that will run as an executable.For example, the following will start nginx with its default content, listening on port 80:</p>\n<pre><code>docker run -i -t --rm -p 80:80 nginx\n\nENTRYPOINT [&quot;ls&quot;]\nENTRYPOINT [&quot;ls&quot;]\nCMD [&quot;-l&quot;, &quot;-a&quot;]\n</code></pre></li>\n<li><p>CMD: set boot parameter</p>\n<pre><code>CMD [&quot;ls&quot;, &quot;-a&quot;, &quot;-l&quot;]\nCMD ls -l -a\n</code></pre></li>\n<li><p>VOLUME: set volume</p>\n<pre><code>VOLUME [&quot;/data&quot;, &quot;/var/www&quot;]\n</code></pre></li>\n<li><p>ONBUILD: trigger for child image</p>\n<pre><code>ONBUILD ADD . /app/src\nONBUILD RUN echo &quot;on build excuted&quot; &gt;&gt; onbuild.txt\n</code></pre></li>\n<li><p>ARG</p>\n</li>\n<li><p>STOPSIGNAL</p>\n</li>\n</ul>\n<h1 id=\"best-practice-link\"><a href=\"#best-practice-link\" class=\"headerlink\" title=\"best practice link\"></a>best practice <a href=\"https://docs.docker.com/engine/articles/dockerfile_best-practices/\" target=\"_blank\" rel=\"external\">link</a></h1><ul>\n<li><p>Containers should be ephemeral</p>\n<p>  The container produced by the image your Dockerfile defines should be as ephemeral as possible.By “ephemeral,” we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration.</p>\n</li>\n<li><p>Use a .dockerignore file</p>\n<p>  In most cases, it’s best to put each Dockerfile in an empty directory. Then, add to that directory only the files needed for building the Dockerfile. To increase the build’s performance, you can exclude files and directories by adding a .dockerignore file to that directory as well. This file supports exclusion patterns similar to .gitignore files. For information on creating one, see the .dockerignore file.</p>\n</li>\n<li><p>Avoid installing unnecessary packages</p>\n<p>  In order to reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be “nice to have.” For example, you don’t need to include a text editor in a database image.</p>\n</li>\n<li><p>Run only one process per container</p>\n<p>  In almost all cases, you should only run a single process in a single container. Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. If that service depends on another service, make use of container linking.</p>\n</li>\n<li><p>Minimize the number of layers</p>\n<p>  You need to find the balance between readability (and thus long-term maintainability) of the Dockerfile and minimizing the number of layers it uses. Be strategic and cautious about the number of layers you use.</p>\n</li>\n<li><p>Sort multi-line arguments</p>\n<p>  Here’s an example from the buildpack-deps image:</p>\n<p>  RUN apt-get update &amp;&amp; apt-get install -y \\</p>\n<pre><code>bzr \\\ncvs \\\ngit \\\nmercurial \\\nsubversion\n</code></pre></li>\n<li><p>Build cache</p>\n</li>\n</ul>\n<h1 id=\"dockerignore\"><a href=\"#dockerignore\" class=\"headerlink\" title=\".dockerignore\"></a>.dockerignore</h1><pre><code>*/temp*\n*/*/temp*\ntemp?\n</code></pre>","excerpt":"","more":"<h1 id=\"about-dockerfile\"><a href=\"#about-dockerfile\" class=\"headerlink\" title=\"about dockerfile\"></a>about dockerfile</h1><h1 id=\"dockerfile-command\"><a href=\"#dockerfile-command\" class=\"headerlink\" title=\"dockerfile command\"></a>dockerfile command</h1><ul>\n<li><p>point to a Dockerfile anywhere in your file system</p>\n<pre><code>docker build -f /path/to/a/Dockerfile .\n</code></pre></li>\n<li><p>specify a repository and tag at which to save the new image if the build succeeds</p>\n<pre><code>docker build -t shykes/myapp .\n</code></pre></li>\n</ul>\n<h1 id=\"dockerfile-keyword\"><a href=\"#dockerfile-keyword\" class=\"headerlink\" title=\"dockerfile keyword\"></a>dockerfile keyword</h1><ul>\n<li><p>FROM: base image</p>\n</li>\n<li><p>MAINTAINER</p>\n<pre><code>MAINTAINER ag &quot;allengaller@gmail.com&quot;\n</code></pre></li>\n<li><p>USER: set user</p>\n<pre><code>USER root\n</code></pre></li>\n<li><p>RUN: run system cmd</p>\n<pre><code>RUN apt-get update\nRUN [&quot;apt-get&quot;, &quot;update&quot;]\nRUN apt-get install -y nginx\nRUN touch test.txt &amp;&amp; echo &quot;abc&quot; &gt;&gt; abc.txt\n</code></pre></li>\n<li><p>EXPOSE: expose port</p>\n</li>\n<li><p>ADD</p>\n<p>  The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the container at the path <dest>.</p>\n<p>  pattern: ADD <src>… <dest>; ADD [“<src>“,… “<dest>“]<br>  add folder: ADD /webapp /opt/webapp<br>  add file: ADD abc.txt /opt/<br>  add network file: ADD <a href=\"https://www.baidu.com/img/bd_logo1.png\">https://www.baidu.com/img/bd_logo1.png</a> /opt/</p>\n</li>\n<li><p>ENV: set env variable</p>\n<pre><code>ENV WEBAPP_PORT = 9090\n</code></pre></li>\n<li><p>WORKDIR: set working directory</p>\n<p>  The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.The WORKDIR instruction can resolve environment variables previously set using ENV. You can only use environment variables explicitly set in the Dockerfile. For example:</p>\n<pre><code>ENV DIRPATH /path\nWORKDIR $DIRPATH/$DIRNAME\nRUN pwd\n</code></pre><p>  The output of the final pwd command in this Dockerfile would be /path/$DIRNAME.It can be used multiple times in the one Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:</p>\n<pre><code>WORKDIR /a\nWORKDIR b\nWORKDIR c\nRUN pwd\n</code></pre><p>  The output of the final pwd command in this Dockerfile would be /a/b/c.</p>\n<pre><code>WORKDIR /opt/\n</code></pre></li>\n<li><p>ENTRYPOINT: set boot command, append parameter to boot cmd</p>\n<p>  An ENTRYPOINT allows you to configure a container that will run as an executable.For example, the following will start nginx with its default content, listening on port 80:</p>\n<pre><code>docker run -i -t --rm -p 80:80 nginx\n\nENTRYPOINT [&quot;ls&quot;]\nENTRYPOINT [&quot;ls&quot;]\nCMD [&quot;-l&quot;, &quot;-a&quot;]\n</code></pre></li>\n<li><p>CMD: set boot parameter</p>\n<pre><code>CMD [&quot;ls&quot;, &quot;-a&quot;, &quot;-l&quot;]\nCMD ls -l -a\n</code></pre></li>\n<li><p>VOLUME: set volume</p>\n<pre><code>VOLUME [&quot;/data&quot;, &quot;/var/www&quot;]\n</code></pre></li>\n<li><p>ONBUILD: trigger for child image</p>\n<pre><code>ONBUILD ADD . /app/src\nONBUILD RUN echo &quot;on build excuted&quot; &gt;&gt; onbuild.txt\n</code></pre></li>\n<li><p>ARG</p>\n</li>\n<li><p>STOPSIGNAL</p>\n</li>\n</ul>\n<h1 id=\"best-practice-link\"><a href=\"#best-practice-link\" class=\"headerlink\" title=\"best practice link\"></a>best practice <a href=\"https://docs.docker.com/engine/articles/dockerfile_best-practices/\">link</a></h1><ul>\n<li><p>Containers should be ephemeral</p>\n<p>  The container produced by the image your Dockerfile defines should be as ephemeral as possible.By “ephemeral,” we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration.</p>\n</li>\n<li><p>Use a .dockerignore file</p>\n<p>  In most cases, it’s best to put each Dockerfile in an empty directory. Then, add to that directory only the files needed for building the Dockerfile. To increase the build’s performance, you can exclude files and directories by adding a .dockerignore file to that directory as well. This file supports exclusion patterns similar to .gitignore files. For information on creating one, see the .dockerignore file.</p>\n</li>\n<li><p>Avoid installing unnecessary packages</p>\n<p>  In order to reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be “nice to have.” For example, you don’t need to include a text editor in a database image.</p>\n</li>\n<li><p>Run only one process per container</p>\n<p>  In almost all cases, you should only run a single process in a single container. Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. If that service depends on another service, make use of container linking.</p>\n</li>\n<li><p>Minimize the number of layers</p>\n<p>  You need to find the balance between readability (and thus long-term maintainability) of the Dockerfile and minimizing the number of layers it uses. Be strategic and cautious about the number of layers you use.</p>\n</li>\n<li><p>Sort multi-line arguments</p>\n<p>  Here’s an example from the buildpack-deps image:</p>\n<p>  RUN apt-get update &amp;&amp; apt-get install -y \\</p>\n<pre><code>bzr \\\ncvs \\\ngit \\\nmercurial \\\nsubversion\n</code></pre></li>\n<li><p>Build cache</p>\n</li>\n</ul>\n<h1 id=\"dockerignore\"><a href=\"#dockerignore\" class=\"headerlink\" title=\".dockerignore\"></a>.dockerignore</h1><pre><code>*/temp*\n*/*/temp*\ntemp?\n</code></pre>"},{"title":"dockerhub","_content":"\n# dockerhub\n\n## about dockerhub [link](https://hub.docker.com)\n\n- types:\n\n        official image\n        user image\n\n## command\n\n- docker login\n\n        comfig: cat ~/.dockercfg\n\n- build: Automated Build/Trusted Build\n    \n- registry\n\n        docker pull registry\n        docker run -p 5000:5000 -d -i -t registry\n        docker commit 3ie9djk 127.0.0.1:5000/my_image:v1\n            [registry_host: registry_port\\image_name:image_tag]\n        docker push 127.0.0.1:5000/my_image:v1","source":"_posts/docker-dockerhub-detail.md","raw":"---\ntitle: dockerhub\ncategories:\n- docker\ntags:\n- detail\n---\n\n# dockerhub\n\n## about dockerhub [link](https://hub.docker.com)\n\n- types:\n\n        official image\n        user image\n\n## command\n\n- docker login\n\n        comfig: cat ~/.dockercfg\n\n- build: Automated Build/Trusted Build\n    \n- registry\n\n        docker pull registry\n        docker run -p 5000:5000 -d -i -t registry\n        docker commit 3ie9djk 127.0.0.1:5000/my_image:v1\n            [registry_host: registry_port\\image_name:image_tag]\n        docker push 127.0.0.1:5000/my_image:v1","slug":"docker-dockerhub-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T11:46:34.000Z","_id":"cixvqn1fx0003vfs64p89e0dn","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"dockerhub\"><a href=\"#dockerhub\" class=\"headerlink\" title=\"dockerhub\"></a>dockerhub</h1><h2 id=\"about-dockerhub-link\"><a href=\"#about-dockerhub-link\" class=\"headerlink\" title=\"about dockerhub link\"></a>about dockerhub <a href=\"https://hub.docker.com\" target=\"_blank\" rel=\"external\">link</a></h2><ul>\n<li><p>types:</p>\n<pre><code>official image\nuser image\n</code></pre></li>\n</ul>\n<h2 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h2><ul>\n<li><p>docker login</p>\n<pre><code>comfig: cat ~/.dockercfg\n</code></pre></li>\n<li><p>build: Automated Build/Trusted Build</p>\n</li>\n<li><p>registry</p>\n<pre><code>docker pull registry\ndocker run -p 5000:5000 -d -i -t registry\ndocker commit 3ie9djk 127.0.0.1:5000/my_image:v1\n    [registry_host: registry_port\\image_name:image_tag]\ndocker push 127.0.0.1:5000/my_image:v1\n</code></pre></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"dockerhub\"><a href=\"#dockerhub\" class=\"headerlink\" title=\"dockerhub\"></a>dockerhub</h1><h2 id=\"about-dockerhub-link\"><a href=\"#about-dockerhub-link\" class=\"headerlink\" title=\"about dockerhub link\"></a>about dockerhub <a href=\"https://hub.docker.com\">link</a></h2><ul>\n<li><p>types:</p>\n<pre><code>official image\nuser image\n</code></pre></li>\n</ul>\n<h2 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h2><ul>\n<li><p>docker login</p>\n<pre><code>comfig: cat ~/.dockercfg\n</code></pre></li>\n<li><p>build: Automated Build/Trusted Build</p>\n</li>\n<li><p>registry</p>\n<pre><code>docker pull registry\ndocker run -p 5000:5000 -d -i -t registry\ndocker commit 3ie9djk 127.0.0.1:5000/my_image:v1\n    [registry_host: registry_port\\image_name:image_tag]\ndocker push 127.0.0.1:5000/my_image:v1\n</code></pre></li>\n</ul>\n"},{"title":"docker engine","_content":"\n## about\n\n## docker engine command\n\n- tips\n\n    Delete all containers:\n        \n        docker rm $(docker ps -a -q)\n\n    Delete all images:\n        \n        docker rmi $(docker images -q)\n\n- env\n\n    - info\n    \n    - version\n\n- life-cycle\n\n    - create:  (ini: stop)\n\n            --restart: check for exit code then restart container; always or on-failure; on-failure:5 restart 5 times max\n\n            sudo docker run --restart=always --name docker_restart -d ubuntu /bin/sh -c \"while true;do echo hello world;sleep 1;done\"\n\n    - exec: exec cmd insid container\n\n            sudo docker exec -d daemon_dave touch /etc/new_config_file\n            sudo docker exec -t -i daemon_dave /bin/bash\n\n    - kill: send SIGKILL signal to container process\n    \n    - pause\n\n    - restart\n\n    - rm: cannot remove a running container; docker stop or kill first or docker rm -f bad_ubuntu\n        \n        -q: list only container ids;\n        delete all container at once:\n            \n            docker rm `docker ps -a -q`\n\n    - run: [reference](https://docs.docker.com/engine/reference/run/);(ini: run); \n\n        equals: docker create & docker start\n\n        2 types of container\n        - interactive\n            -i: STDIN\n            -t: open terminal\n            exit?: docker stop or kill;exit\n\n                sudo docker run -i -t --name=inspect_shell ubuntu /bin/bash\n                inspect_shell: container name\n                base image: ubuntu\n                command: /bin/bash\n                file system: image+writable layer\n                network: virtual network interface bridge to host & set a IP\n        \n        - daemon: -d\n            exit?: docker stop or kill\n            \n                sudo docker run --name daemon_while -d ubuntu /bin/sh -c \"while true; do echo hello world; sleep 1; done\"\n            \n                return token\n            \n                docker ps\n\n    - start: start existing container\n            \n            sudo docker start inspect_shell or cid\n\n    - stop: works for both interactive and daemon container;send SIGTERM signal to container process\n\n            sudo docker stop daemon_while\n            sudo docker stop s39c938dj34489d\n        \n    - unpause\n\n- registry\n\n    - login\n    \n    - logout\n    \n    - pull\n    \n    - push\n    \n    - search\n\n- image\n\n    - build\n    \n    - images\n    \n    - import:             \n\n            cat my_container.rar | sudo docker import - imported:container\n            repository: imported, tag: container\n            docker import url res:tag\n\n    - load\n    \n    - rmi\n    \n    - save\n    \n    - tag\n    \n    - commit\n\n- container\n\n    - attach: attach terminal to interactive container\n    \n    - export\n\n            sudo docker run -i -t --nam=inspect_import ubuntu /bin/bash\n            #... do something\n            sudo docker export inspect_import > my_container.tar\n\n    - inspect: check out the configuration\n\n            sudo docker inspect daemon_dave\n\n        -f or --format:\n\n            sudo docker inspect --format='{{ .State.Running }}' daemon_dave\n    \n    - port\n    \n    - ps: checkout existing container\n\n        -a: all\n            Exited(0): exit\n        -l: latest container\n        -n=x: latest x container\n\n    - rename\n    \n    - stats\n    \n    - top: check out UID PID PPID...\n        \n            sudo docker run -d --name=\"daemon_top\" ubuntu /bin/bash -c 'while true;do sleep 1;done'\n        \n        2 process:\n        \n            sudo docker top daemon_top\n\n    - wait\n    \n    - cp\n    \n    - diff\n\n- sys log\n\n    - events\n    \n    - history\n    \n    - logs\n\n        -f: realtime\n        --tail=x: last x line\n                \n            sudo docker logs -f --tail=5 -t daemon_logs\n\n- other\n\n    - docker daemon: [link](https://docs.docker.com/engine/reference/commandline/daemon/), A self-sufficient runtime for linux containers.\n            \n        The Docker daemon can listen for Docker Remote API requests via three different types of Socket: unix, tcp, and fd.\n        By default, a unix domain socket (or IPC socket) is created at /var/run/docker.sock, requiring either root permission, or docker group membership.","source":"_posts/docker-engine-detail.md","raw":"---\ntitle: docker engine\ncategories:\n- docker\ntags:\n- detail\n---\n\n## about\n\n## docker engine command\n\n- tips\n\n    Delete all containers:\n        \n        docker rm $(docker ps -a -q)\n\n    Delete all images:\n        \n        docker rmi $(docker images -q)\n\n- env\n\n    - info\n    \n    - version\n\n- life-cycle\n\n    - create:  (ini: stop)\n\n            --restart: check for exit code then restart container; always or on-failure; on-failure:5 restart 5 times max\n\n            sudo docker run --restart=always --name docker_restart -d ubuntu /bin/sh -c \"while true;do echo hello world;sleep 1;done\"\n\n    - exec: exec cmd insid container\n\n            sudo docker exec -d daemon_dave touch /etc/new_config_file\n            sudo docker exec -t -i daemon_dave /bin/bash\n\n    - kill: send SIGKILL signal to container process\n    \n    - pause\n\n    - restart\n\n    - rm: cannot remove a running container; docker stop or kill first or docker rm -f bad_ubuntu\n        \n        -q: list only container ids;\n        delete all container at once:\n            \n            docker rm `docker ps -a -q`\n\n    - run: [reference](https://docs.docker.com/engine/reference/run/);(ini: run); \n\n        equals: docker create & docker start\n\n        2 types of container\n        - interactive\n            -i: STDIN\n            -t: open terminal\n            exit?: docker stop or kill;exit\n\n                sudo docker run -i -t --name=inspect_shell ubuntu /bin/bash\n                inspect_shell: container name\n                base image: ubuntu\n                command: /bin/bash\n                file system: image+writable layer\n                network: virtual network interface bridge to host & set a IP\n        \n        - daemon: -d\n            exit?: docker stop or kill\n            \n                sudo docker run --name daemon_while -d ubuntu /bin/sh -c \"while true; do echo hello world; sleep 1; done\"\n            \n                return token\n            \n                docker ps\n\n    - start: start existing container\n            \n            sudo docker start inspect_shell or cid\n\n    - stop: works for both interactive and daemon container;send SIGTERM signal to container process\n\n            sudo docker stop daemon_while\n            sudo docker stop s39c938dj34489d\n        \n    - unpause\n\n- registry\n\n    - login\n    \n    - logout\n    \n    - pull\n    \n    - push\n    \n    - search\n\n- image\n\n    - build\n    \n    - images\n    \n    - import:             \n\n            cat my_container.rar | sudo docker import - imported:container\n            repository: imported, tag: container\n            docker import url res:tag\n\n    - load\n    \n    - rmi\n    \n    - save\n    \n    - tag\n    \n    - commit\n\n- container\n\n    - attach: attach terminal to interactive container\n    \n    - export\n\n            sudo docker run -i -t --nam=inspect_import ubuntu /bin/bash\n            #... do something\n            sudo docker export inspect_import > my_container.tar\n\n    - inspect: check out the configuration\n\n            sudo docker inspect daemon_dave\n\n        -f or --format:\n\n            sudo docker inspect --format='{{ .State.Running }}' daemon_dave\n    \n    - port\n    \n    - ps: checkout existing container\n\n        -a: all\n            Exited(0): exit\n        -l: latest container\n        -n=x: latest x container\n\n    - rename\n    \n    - stats\n    \n    - top: check out UID PID PPID...\n        \n            sudo docker run -d --name=\"daemon_top\" ubuntu /bin/bash -c 'while true;do sleep 1;done'\n        \n        2 process:\n        \n            sudo docker top daemon_top\n\n    - wait\n    \n    - cp\n    \n    - diff\n\n- sys log\n\n    - events\n    \n    - history\n    \n    - logs\n\n        -f: realtime\n        --tail=x: last x line\n                \n            sudo docker logs -f --tail=5 -t daemon_logs\n\n- other\n\n    - docker daemon: [link](https://docs.docker.com/engine/reference/commandline/daemon/), A self-sufficient runtime for linux containers.\n            \n        The Docker daemon can listen for Docker Remote API requests via three different types of Socket: unix, tcp, and fd.\n        By default, a unix domain socket (or IPC socket) is created at /var/run/docker.sock, requiring either root permission, or docker group membership.","slug":"docker-engine-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T12:20:53.000Z","_id":"cixvqvsvz00033as65wwvx2kk","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h2><h2 id=\"docker-engine-command\"><a href=\"#docker-engine-command\" class=\"headerlink\" title=\"docker engine command\"></a>docker engine command</h2><ul>\n<li><p>tips</p>\n<p>  Delete all containers:</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre><p>  Delete all images:</p>\n<pre><code>docker rmi $(docker images -q)\n</code></pre></li>\n<li><p>env</p>\n<ul>\n<li><p>info</p>\n</li>\n<li><p>version</p>\n</li>\n</ul>\n</li>\n<li><p>life-cycle</p>\n<ul>\n<li><p>create:  (ini: stop)</p>\n<pre><code>--restart: check for exit code then restart container; always or on-failure; on-failure:5 restart 5 times max\n\nsudo docker run --restart=always --name docker_restart -d ubuntu /bin/sh -c &quot;while true;do echo hello world;sleep 1;done&quot;\n</code></pre></li>\n<li><p>exec: exec cmd insid container</p>\n<pre><code>sudo docker exec -d daemon_dave touch /etc/new_config_file\nsudo docker exec -t -i daemon_dave /bin/bash\n</code></pre></li>\n<li><p>kill: send SIGKILL signal to container process</p>\n</li>\n<li><p>pause</p>\n</li>\n<li><p>restart</p>\n</li>\n<li><p>rm: cannot remove a running container; docker stop or kill first or docker rm -f bad_ubuntu</p>\n<p>  -q: list only container ids;<br>  delete all container at once:</p>\n<pre><code>docker rm `docker ps -a -q`\n</code></pre></li>\n<li><p>run: <a href=\"https://docs.docker.com/engine/reference/run/\" target=\"_blank\" rel=\"external\">reference</a>;(ini: run); </p>\n<p>  equals: docker create &amp; docker start</p>\n<p>  2 types of container</p>\n<ul>\n<li><p>interactive<br>  -i: STDIN<br>  -t: open terminal<br>  exit?: docker stop or kill;exit</p>\n<pre><code>sudo docker run -i -t --name=inspect_shell ubuntu /bin/bash\ninspect_shell: container name\nbase image: ubuntu\ncommand: /bin/bash\nfile system: image+writable layer\nnetwork: virtual network interface bridge to host &amp; set a IP\n</code></pre></li>\n<li><p>daemon: -d<br>  exit?: docker stop or kill</p>\n<pre><code>sudo docker run --name daemon_while -d ubuntu /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;\n\nreturn token\n\ndocker ps\n</code></pre></li>\n</ul>\n</li>\n<li><p>start: start existing container</p>\n<pre><code>sudo docker start inspect_shell or cid\n</code></pre></li>\n<li><p>stop: works for both interactive and daemon container;send SIGTERM signal to container process</p>\n<pre><code>sudo docker stop daemon_while\nsudo docker stop s39c938dj34489d\n</code></pre></li>\n<li><p>unpause</p>\n</li>\n</ul>\n</li>\n<li><p>registry</p>\n<ul>\n<li><p>login</p>\n</li>\n<li><p>logout</p>\n</li>\n<li><p>pull</p>\n</li>\n<li><p>push</p>\n</li>\n<li><p>search</p>\n</li>\n</ul>\n</li>\n<li><p>image</p>\n<ul>\n<li><p>build</p>\n</li>\n<li><p>images</p>\n</li>\n<li><p>import:             </p>\n<pre><code>cat my_container.rar | sudo docker import - imported:container\nrepository: imported, tag: container\ndocker import url res:tag\n</code></pre></li>\n<li><p>load</p>\n</li>\n<li><p>rmi</p>\n</li>\n<li><p>save</p>\n</li>\n<li><p>tag</p>\n</li>\n<li><p>commit</p>\n</li>\n</ul>\n</li>\n<li><p>container</p>\n<ul>\n<li><p>attach: attach terminal to interactive container</p>\n</li>\n<li><p>export</p>\n<pre><code>sudo docker run -i -t --nam=inspect_import ubuntu /bin/bash\n#... do something\nsudo docker export inspect_import &gt; my_container.tar\n</code></pre></li>\n<li><p>inspect: check out the configuration</p>\n<pre><code>sudo docker inspect daemon_dave\n</code></pre><p>  -f or –format:</p>\n<pre><code>sudo docker inspect --format=&apos;{{ .State.Running }}&apos; daemon_dave\n</code></pre></li>\n<li><p>port</p>\n</li>\n<li><p>ps: checkout existing container</p>\n<p>  -a: all</p>\n<pre><code>Exited(0): exit\n</code></pre><p>  -l: latest container<br>  -n=x: latest x container</p>\n</li>\n<li><p>rename</p>\n</li>\n<li><p>stats</p>\n</li>\n<li><p>top: check out UID PID PPID…</p>\n<pre><code>sudo docker run -d --name=&quot;daemon_top&quot; ubuntu /bin/bash -c &apos;while true;do sleep 1;done&apos;\n</code></pre><p>  2 process:</p>\n<pre><code>sudo docker top daemon_top\n</code></pre></li>\n<li><p>wait</p>\n</li>\n<li><p>cp</p>\n</li>\n<li><p>diff</p>\n</li>\n</ul>\n</li>\n<li><p>sys log</p>\n<ul>\n<li><p>events</p>\n</li>\n<li><p>history</p>\n</li>\n<li><p>logs</p>\n<p>  -f: realtime<br>  –tail=x: last x line</p>\n<pre><code>sudo docker logs -f --tail=5 -t daemon_logs\n</code></pre></li>\n</ul>\n</li>\n<li><p>other</p>\n<ul>\n<li><p>docker daemon: <a href=\"https://docs.docker.com/engine/reference/commandline/daemon/\" target=\"_blank\" rel=\"external\">link</a>, A self-sufficient runtime for linux containers.</p>\n<p>  The Docker daemon can listen for Docker Remote API requests via three different types of Socket: unix, tcp, and fd.<br>  By default, a unix domain socket (or IPC socket) is created at /var/run/docker.sock, requiring either root permission, or docker group membership.</p>\n</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h2 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h2><h2 id=\"docker-engine-command\"><a href=\"#docker-engine-command\" class=\"headerlink\" title=\"docker engine command\"></a>docker engine command</h2><ul>\n<li><p>tips</p>\n<p>  Delete all containers:</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre><p>  Delete all images:</p>\n<pre><code>docker rmi $(docker images -q)\n</code></pre></li>\n<li><p>env</p>\n<ul>\n<li><p>info</p>\n</li>\n<li><p>version</p>\n</li>\n</ul>\n</li>\n<li><p>life-cycle</p>\n<ul>\n<li><p>create:  (ini: stop)</p>\n<pre><code>--restart: check for exit code then restart container; always or on-failure; on-failure:5 restart 5 times max\n\nsudo docker run --restart=always --name docker_restart -d ubuntu /bin/sh -c &quot;while true;do echo hello world;sleep 1;done&quot;\n</code></pre></li>\n<li><p>exec: exec cmd insid container</p>\n<pre><code>sudo docker exec -d daemon_dave touch /etc/new_config_file\nsudo docker exec -t -i daemon_dave /bin/bash\n</code></pre></li>\n<li><p>kill: send SIGKILL signal to container process</p>\n</li>\n<li><p>pause</p>\n</li>\n<li><p>restart</p>\n</li>\n<li><p>rm: cannot remove a running container; docker stop or kill first or docker rm -f bad_ubuntu</p>\n<p>  -q: list only container ids;<br>  delete all container at once:</p>\n<pre><code>docker rm `docker ps -a -q`\n</code></pre></li>\n<li><p>run: <a href=\"https://docs.docker.com/engine/reference/run/\">reference</a>;(ini: run); </p>\n<p>  equals: docker create &amp; docker start</p>\n<p>  2 types of container</p>\n<ul>\n<li><p>interactive<br>  -i: STDIN<br>  -t: open terminal<br>  exit?: docker stop or kill;exit</p>\n<pre><code>sudo docker run -i -t --name=inspect_shell ubuntu /bin/bash\ninspect_shell: container name\nbase image: ubuntu\ncommand: /bin/bash\nfile system: image+writable layer\nnetwork: virtual network interface bridge to host &amp; set a IP\n</code></pre></li>\n<li><p>daemon: -d<br>  exit?: docker stop or kill</p>\n<pre><code>sudo docker run --name daemon_while -d ubuntu /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;\n\nreturn token\n\ndocker ps\n</code></pre></li>\n</ul>\n</li>\n<li><p>start: start existing container</p>\n<pre><code>sudo docker start inspect_shell or cid\n</code></pre></li>\n<li><p>stop: works for both interactive and daemon container;send SIGTERM signal to container process</p>\n<pre><code>sudo docker stop daemon_while\nsudo docker stop s39c938dj34489d\n</code></pre></li>\n<li><p>unpause</p>\n</li>\n</ul>\n</li>\n<li><p>registry</p>\n<ul>\n<li><p>login</p>\n</li>\n<li><p>logout</p>\n</li>\n<li><p>pull</p>\n</li>\n<li><p>push</p>\n</li>\n<li><p>search</p>\n</li>\n</ul>\n</li>\n<li><p>image</p>\n<ul>\n<li><p>build</p>\n</li>\n<li><p>images</p>\n</li>\n<li><p>import:             </p>\n<pre><code>cat my_container.rar | sudo docker import - imported:container\nrepository: imported, tag: container\ndocker import url res:tag\n</code></pre></li>\n<li><p>load</p>\n</li>\n<li><p>rmi</p>\n</li>\n<li><p>save</p>\n</li>\n<li><p>tag</p>\n</li>\n<li><p>commit</p>\n</li>\n</ul>\n</li>\n<li><p>container</p>\n<ul>\n<li><p>attach: attach terminal to interactive container</p>\n</li>\n<li><p>export</p>\n<pre><code>sudo docker run -i -t --nam=inspect_import ubuntu /bin/bash\n#... do something\nsudo docker export inspect_import &gt; my_container.tar\n</code></pre></li>\n<li><p>inspect: check out the configuration</p>\n<pre><code>sudo docker inspect daemon_dave\n</code></pre><p>  -f or –format:</p>\n<pre><code>sudo docker inspect --format=&apos;{{ .State.Running }}&apos; daemon_dave\n</code></pre></li>\n<li><p>port</p>\n</li>\n<li><p>ps: checkout existing container</p>\n<p>  -a: all</p>\n<pre><code>Exited(0): exit\n</code></pre><p>  -l: latest container<br>  -n=x: latest x container</p>\n</li>\n<li><p>rename</p>\n</li>\n<li><p>stats</p>\n</li>\n<li><p>top: check out UID PID PPID…</p>\n<pre><code>sudo docker run -d --name=&quot;daemon_top&quot; ubuntu /bin/bash -c &apos;while true;do sleep 1;done&apos;\n</code></pre><p>  2 process:</p>\n<pre><code>sudo docker top daemon_top\n</code></pre></li>\n<li><p>wait</p>\n</li>\n<li><p>cp</p>\n</li>\n<li><p>diff</p>\n</li>\n</ul>\n</li>\n<li><p>sys log</p>\n<ul>\n<li><p>events</p>\n</li>\n<li><p>history</p>\n</li>\n<li><p>logs</p>\n<p>  -f: realtime<br>  –tail=x: last x line</p>\n<pre><code>sudo docker logs -f --tail=5 -t daemon_logs\n</code></pre></li>\n</ul>\n</li>\n<li><p>other</p>\n<ul>\n<li><p>docker daemon: <a href=\"https://docs.docker.com/engine/reference/commandline/daemon/\">link</a>, A self-sufficient runtime for linux containers.</p>\n<p>  The Docker daemon can listen for Docker Remote API requests via three different types of Socket: unix, tcp, and fd.<br>  By default, a unix domain socket (or IPC socket) is created at /var/run/docker.sock, requiring either root permission, or docker group membership.</p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"docker compose","_content":"\n# about docker compose\n\n[link](https://docs.docker.com/compose/)\norchestration 官方编排工具, 用于将一个多容器应用编排成一个单一应用\nFig工具的替代品: [fig](http://www.fig.sh/)可以快速搭建开发环境,通过YAML文件管理多个容器;\nFit cmd: add fig.yml; fig up\n\n# install\n\n[link](http://docs.docker.com/compose/install/)\n            \n        docker-compose --version\n\n    64bits Linux or MacOS X:\n\n            curl -L https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\n            chmod +x /usr/local/bin/docker-compose\n    \n    win and other:\n\n            sudo pip install -U docker-compose\n# command\n\n- docker-compose up -d\n\n- docker exec\n    \n    docker exec -it example_web_1 bash\n\n- docker-compose stop && docker-compose rm --force\n\n- docker-compose build\n    Build or rebuild services\n\n- docker-compose help\n\n- docker-compose kill\n    Kill containers 通过发送 SIGKILL 信号来强制停止服务容器\n    支持通过参数来指定发送的信号\n        docker-compose kill -s SIGINT\n\n- docker-compose logs\n    View output from containers\n\n- docker-compose port\n    Print the public port for a port binding\n\n- docker-compose ps\n    List containers\n\n- docker-compose pull\n    Pulls service images\n\n- docker-compose rm\n    Remove stopped containers\n\n- docker-compose run\n    Run a one-off command 在一个服务上执行一个命令\n    docker-compose run ubuntu ping docker.com\n        将会启动一个 ubuntu 服务，执行 ping docker.com 命令\n    默认情况下，所有关联的服务将会自动被启动，除非这些服务已经在运行中。\n    该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照期望创建。\n    两个不同点：\n        给定命令将会覆盖原有的自动运行命令；\n        不会自动创建端口，以避免冲突。\n    如果不希望自动启动关联的容器，可以使用 --no-deps 选项\n        docker-compose run --no-deps web python manage.py shell\n        将不会启动 web 容器所关联的其它容器\n- docker-compose scale\n    Set number of containers for a service 设置同一个服务运行的容器个数\n    Set number of containers for a service\n    service=num\n    docker-compose scale web=2 worker=3\n\n- docker-compose start\n    Start services\n\n- docker-compose stop\n    Stop services\n\n- docker-compose restart\n    Restart services\n        env variable\n            COMPOSE_PROJECT_NAME\n                设置通过 Compose 启动的每一个容器前添加的项目名称，默认是当前工作目录的名字。\n            COMPOSE_FILE\n                设置要使用的 docker-compose.yml 的路径。默认路径是当前工作目录。\n            DOCKER_HOST\n                设置 Docker daemon 的地址。默认使用 unix:///var/run/docker.sock，与 Docker 客户端采用的默认值一致。\n            DOCKER_TLS_VERIFY\n                如果设置不为空，则与 Docker daemon 交互通过 TLS 进行。\n            DOCKER_CERT_PATH\n                配置 TLS 通信所需要的验证（ca.pem、cert.pem 和 key.pem）文件的路径，默认是 ~/.docker 。\n\n- docker-compose up\n    Create and start containers\n    $ docker-compose up -d\n\n- docker-compose logs\n\n- docker-compose version\n    Show the Docker-Compose version information\n\n- docker-compose unpause\n    Unpause services\n\n- docker-compose migrate-to-labels\n    Recreate containers to add labels\n   ","source":"_posts/docker-compose-detail.md","raw":"---\ntitle: docker compose\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about docker compose\n\n[link](https://docs.docker.com/compose/)\norchestration 官方编排工具, 用于将一个多容器应用编排成一个单一应用\nFig工具的替代品: [fig](http://www.fig.sh/)可以快速搭建开发环境,通过YAML文件管理多个容器;\nFit cmd: add fig.yml; fig up\n\n# install\n\n[link](http://docs.docker.com/compose/install/)\n            \n        docker-compose --version\n\n    64bits Linux or MacOS X:\n\n            curl -L https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\n            chmod +x /usr/local/bin/docker-compose\n    \n    win and other:\n\n            sudo pip install -U docker-compose\n# command\n\n- docker-compose up -d\n\n- docker exec\n    \n    docker exec -it example_web_1 bash\n\n- docker-compose stop && docker-compose rm --force\n\n- docker-compose build\n    Build or rebuild services\n\n- docker-compose help\n\n- docker-compose kill\n    Kill containers 通过发送 SIGKILL 信号来强制停止服务容器\n    支持通过参数来指定发送的信号\n        docker-compose kill -s SIGINT\n\n- docker-compose logs\n    View output from containers\n\n- docker-compose port\n    Print the public port for a port binding\n\n- docker-compose ps\n    List containers\n\n- docker-compose pull\n    Pulls service images\n\n- docker-compose rm\n    Remove stopped containers\n\n- docker-compose run\n    Run a one-off command 在一个服务上执行一个命令\n    docker-compose run ubuntu ping docker.com\n        将会启动一个 ubuntu 服务，执行 ping docker.com 命令\n    默认情况下，所有关联的服务将会自动被启动，除非这些服务已经在运行中。\n    该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照期望创建。\n    两个不同点：\n        给定命令将会覆盖原有的自动运行命令；\n        不会自动创建端口，以避免冲突。\n    如果不希望自动启动关联的容器，可以使用 --no-deps 选项\n        docker-compose run --no-deps web python manage.py shell\n        将不会启动 web 容器所关联的其它容器\n- docker-compose scale\n    Set number of containers for a service 设置同一个服务运行的容器个数\n    Set number of containers for a service\n    service=num\n    docker-compose scale web=2 worker=3\n\n- docker-compose start\n    Start services\n\n- docker-compose stop\n    Stop services\n\n- docker-compose restart\n    Restart services\n        env variable\n            COMPOSE_PROJECT_NAME\n                设置通过 Compose 启动的每一个容器前添加的项目名称，默认是当前工作目录的名字。\n            COMPOSE_FILE\n                设置要使用的 docker-compose.yml 的路径。默认路径是当前工作目录。\n            DOCKER_HOST\n                设置 Docker daemon 的地址。默认使用 unix:///var/run/docker.sock，与 Docker 客户端采用的默认值一致。\n            DOCKER_TLS_VERIFY\n                如果设置不为空，则与 Docker daemon 交互通过 TLS 进行。\n            DOCKER_CERT_PATH\n                配置 TLS 通信所需要的验证（ca.pem、cert.pem 和 key.pem）文件的路径，默认是 ~/.docker 。\n\n- docker-compose up\n    Create and start containers\n    $ docker-compose up -d\n\n- docker-compose logs\n\n- docker-compose version\n    Show the Docker-Compose version information\n\n- docker-compose unpause\n    Unpause services\n\n- docker-compose migrate-to-labels\n    Recreate containers to add labels\n   ","slug":"docker-compose-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T12:33:02.000Z","_id":"cixvrxaob0003eys6peooymvm","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"about-docker-compose\"><a href=\"#about-docker-compose\" class=\"headerlink\" title=\"about docker compose\"></a>about docker compose</h1><p><a href=\"https://docs.docker.com/compose/\" target=\"_blank\" rel=\"external\">link</a><br>orchestration 官方编排工具, 用于将一个多容器应用编排成一个单一应用<br>Fig工具的替代品: <a href=\"http://www.fig.sh/\" target=\"_blank\" rel=\"external\">fig</a>可以快速搭建开发环境,通过YAML文件管理多个容器;<br>Fit cmd: add fig.yml; fig up</p>\n<h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><p><a href=\"http://docs.docker.com/compose/install/\" target=\"_blank\" rel=\"external\">link</a></p>\n<pre><code>    docker-compose --version\n\n64bits Linux or MacOS X:\n\n        curl -L https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose\n        chmod +x /usr/local/bin/docker-compose\n\nwin and other:\n\n        sudo pip install -U docker-compose\n</code></pre><h1 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h1><ul>\n<li><p>docker-compose up -d</p>\n</li>\n<li><p>docker exec</p>\n<p>  docker exec -it example_web_1 bash</p>\n</li>\n<li><p>docker-compose stop &amp;&amp; docker-compose rm –force</p>\n</li>\n<li><p>docker-compose build<br>  Build or rebuild services</p>\n</li>\n<li><p>docker-compose help</p>\n</li>\n<li><p>docker-compose kill<br>  Kill containers 通过发送 SIGKILL 信号来强制停止服务容器<br>  支持通过参数来指定发送的信号</p>\n<pre><code>docker-compose kill -s SIGINT\n</code></pre></li>\n<li><p>docker-compose logs<br>  View output from containers</p>\n</li>\n<li><p>docker-compose port<br>  Print the public port for a port binding</p>\n</li>\n<li><p>docker-compose ps<br>  List containers</p>\n</li>\n<li><p>docker-compose pull<br>  Pulls service images</p>\n</li>\n<li><p>docker-compose rm<br>  Remove stopped containers</p>\n</li>\n<li><p>docker-compose run<br>  Run a one-off command 在一个服务上执行一个命令<br>  docker-compose run ubuntu ping docker.com</p>\n<pre><code>将会启动一个 ubuntu 服务，执行 ping docker.com 命令\n</code></pre><p>  默认情况下，所有关联的服务将会自动被启动，除非这些服务已经在运行中。<br>  该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照期望创建。<br>  两个不同点：</p>\n<pre><code>给定命令将会覆盖原有的自动运行命令；\n不会自动创建端口，以避免冲突。\n</code></pre><p>  如果不希望自动启动关联的容器，可以使用 –no-deps 选项</p>\n<pre><code>docker-compose run --no-deps web python manage.py shell\n将不会启动 web 容器所关联的其它容器\n</code></pre></li>\n<li><p>docker-compose scale<br>  Set number of containers for a service 设置同一个服务运行的容器个数<br>  Set number of containers for a service<br>  service=num<br>  docker-compose scale web=2 worker=3</p>\n</li>\n<li><p>docker-compose start<br>  Start services</p>\n</li>\n<li><p>docker-compose stop<br>  Stop services</p>\n</li>\n<li><p>docker-compose restart<br>  Restart services</p>\n<pre><code>env variable\n    COMPOSE_PROJECT_NAME\n        设置通过 Compose 启动的每一个容器前添加的项目名称，默认是当前工作目录的名字。\n    COMPOSE_FILE\n        设置要使用的 docker-compose.yml 的路径。默认路径是当前工作目录。\n    DOCKER_HOST\n        设置 Docker daemon 的地址。默认使用 unix:///var/run/docker.sock，与 Docker 客户端采用的默认值一致。\n    DOCKER_TLS_VERIFY\n        如果设置不为空，则与 Docker daemon 交互通过 TLS 进行。\n    DOCKER_CERT_PATH\n        配置 TLS 通信所需要的验证（ca.pem、cert.pem 和 key.pem）文件的路径，默认是 ~/.docker 。\n</code></pre></li>\n<li><p>docker-compose up<br>  Create and start containers<br>  $ docker-compose up -d</p>\n</li>\n<li><p>docker-compose logs</p>\n</li>\n<li><p>docker-compose version<br>  Show the Docker-Compose version information</p>\n</li>\n<li><p>docker-compose unpause<br>  Unpause services</p>\n</li>\n<li><p>docker-compose migrate-to-labels<br>  Recreate containers to add labels</p>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about-docker-compose\"><a href=\"#about-docker-compose\" class=\"headerlink\" title=\"about docker compose\"></a>about docker compose</h1><p><a href=\"https://docs.docker.com/compose/\">link</a><br>orchestration 官方编排工具, 用于将一个多容器应用编排成一个单一应用<br>Fig工具的替代品: <a href=\"http://www.fig.sh/\">fig</a>可以快速搭建开发环境,通过YAML文件管理多个容器;<br>Fit cmd: add fig.yml; fig up</p>\n<h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><p><a href=\"http://docs.docker.com/compose/install/\">link</a></p>\n<pre><code>    docker-compose --version\n\n64bits Linux or MacOS X:\n\n        curl -L https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose\n        chmod +x /usr/local/bin/docker-compose\n\nwin and other:\n\n        sudo pip install -U docker-compose\n</code></pre><h1 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h1><ul>\n<li><p>docker-compose up -d</p>\n</li>\n<li><p>docker exec</p>\n<p>  docker exec -it example_web_1 bash</p>\n</li>\n<li><p>docker-compose stop &amp;&amp; docker-compose rm –force</p>\n</li>\n<li><p>docker-compose build<br>  Build or rebuild services</p>\n</li>\n<li><p>docker-compose help</p>\n</li>\n<li><p>docker-compose kill<br>  Kill containers 通过发送 SIGKILL 信号来强制停止服务容器<br>  支持通过参数来指定发送的信号</p>\n<pre><code>docker-compose kill -s SIGINT\n</code></pre></li>\n<li><p>docker-compose logs<br>  View output from containers</p>\n</li>\n<li><p>docker-compose port<br>  Print the public port for a port binding</p>\n</li>\n<li><p>docker-compose ps<br>  List containers</p>\n</li>\n<li><p>docker-compose pull<br>  Pulls service images</p>\n</li>\n<li><p>docker-compose rm<br>  Remove stopped containers</p>\n</li>\n<li><p>docker-compose run<br>  Run a one-off command 在一个服务上执行一个命令<br>  docker-compose run ubuntu ping docker.com</p>\n<pre><code>将会启动一个 ubuntu 服务，执行 ping docker.com 命令\n</code></pre><p>  默认情况下，所有关联的服务将会自动被启动，除非这些服务已经在运行中。<br>  该命令类似启动容器后运行指定的命令，相关卷、链接等等都将会按照期望创建。<br>  两个不同点：</p>\n<pre><code>给定命令将会覆盖原有的自动运行命令；\n不会自动创建端口，以避免冲突。\n</code></pre><p>  如果不希望自动启动关联的容器，可以使用 –no-deps 选项</p>\n<pre><code>docker-compose run --no-deps web python manage.py shell\n将不会启动 web 容器所关联的其它容器\n</code></pre></li>\n<li><p>docker-compose scale<br>  Set number of containers for a service 设置同一个服务运行的容器个数<br>  Set number of containers for a service<br>  service=num<br>  docker-compose scale web=2 worker=3</p>\n</li>\n<li><p>docker-compose start<br>  Start services</p>\n</li>\n<li><p>docker-compose stop<br>  Stop services</p>\n</li>\n<li><p>docker-compose restart<br>  Restart services</p>\n<pre><code>env variable\n    COMPOSE_PROJECT_NAME\n        设置通过 Compose 启动的每一个容器前添加的项目名称，默认是当前工作目录的名字。\n    COMPOSE_FILE\n        设置要使用的 docker-compose.yml 的路径。默认路径是当前工作目录。\n    DOCKER_HOST\n        设置 Docker daemon 的地址。默认使用 unix:///var/run/docker.sock，与 Docker 客户端采用的默认值一致。\n    DOCKER_TLS_VERIFY\n        如果设置不为空，则与 Docker daemon 交互通过 TLS 进行。\n    DOCKER_CERT_PATH\n        配置 TLS 通信所需要的验证（ca.pem、cert.pem 和 key.pem）文件的路径，默认是 ~/.docker 。\n</code></pre></li>\n<li><p>docker-compose up<br>  Create and start containers<br>  $ docker-compose up -d</p>\n</li>\n<li><p>docker-compose logs</p>\n</li>\n<li><p>docker-compose version<br>  Show the Docker-Compose version information</p>\n</li>\n<li><p>docker-compose unpause<br>  Unpause services</p>\n</li>\n<li><p>docker-compose migrate-to-labels<br>  Recreate containers to add labels</p>\n</li>\n</ul>\n"},{"title":"docker swarm","_content":"\n# about \n\n# command\n\n- docker-machine ls\n\n- docker-machine create -d virtualbox local\n\n- $(docker-machine env local) \n\n- docker run swarm create\n\n        $  docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://63e7a1adb607ce4db056a29b1f5d30cf swarm-master \n\n        $(docker-machine env --swarm swarm-master)\n\n- docker-machine ls\n","source":"_posts/docker-swarm-detail.md","raw":"---\ntitle: docker swarm\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about \n\n# command\n\n- docker-machine ls\n\n- docker-machine create -d virtualbox local\n\n- $(docker-machine env local) \n\n- docker run swarm create\n\n        $  docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://63e7a1adb607ce4db056a29b1f5d30cf swarm-master \n\n        $(docker-machine env --swarm swarm-master)\n\n- docker-machine ls\n","slug":"docker-swarm-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T12:42:35.000Z","_id":"cixvrxxxh0009eys6nx9yz5i7","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h1><ul>\n<li><p>docker-machine ls</p>\n</li>\n<li><p>docker-machine create -d virtualbox local</p>\n</li>\n<li><p>$(docker-machine env local) </p>\n</li>\n<li><p>docker run swarm create</p>\n<pre><code>$  docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://63e7a1adb607ce4db056a29b1f5d30cf swarm-master \n\n$(docker-machine env --swarm swarm-master)\n</code></pre></li>\n<li><p>docker-machine ls</p>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h1><ul>\n<li><p>docker-machine ls</p>\n</li>\n<li><p>docker-machine create -d virtualbox local</p>\n</li>\n<li><p>$(docker-machine env local) </p>\n</li>\n<li><p>docker run swarm create</p>\n<pre><code>$  docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://63e7a1adb607ce4db056a29b1f5d30cf swarm-master \n\n$(docker-machine env --swarm swarm-master)\n</code></pre></li>\n<li><p>docker-machine ls</p>\n</li>\n</ul>\n"},{"title":"docker machine","_content":"\n# about docker machine\n","source":"_posts/docker-machine-detail.md","raw":"---\ntitle: docker machine\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about docker machine\n","slug":"docker-machine-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T12:23:07.000Z","_id":"cixvryeqr000feys6gy5sh8t5","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"about-docker-machine\"><a href=\"#about-docker-machine\" class=\"headerlink\" title=\"about docker machine\"></a>about docker machine</h1>","excerpt":"","more":"<h1 id=\"about-docker-machine\"><a href=\"#about-docker-machine\" class=\"headerlink\" title=\"about docker machine\"></a>about docker machine</h1>"},{"title":"docker compose","_content":"\n# about\n\n    The compose file is a YAML file where all the top level keys are the name of a service, \n    and the values are the service definition. \n    The default path for a compose file is ./docker-compose.yml.\n    \n    ```\n        containers:\n        web:\n         build: .\n         command: python app.py\n         ports:\n         - \"5000:5000\"\n         volumes:\n         - .:/code\n         links:\n         - redis\n         environment:\n         - PYTHONUNBUFFERED=1\n        redis:\n         image: redis:latest\n         command: redis-server --appendonly yes\n     ```\n\n     ```\n        wiki2:\n        image: 'nickstenning/mediawiki'\n        ports:\n            - \"8880:80\"\n        links:\n            - db:database\n        volumes:\n            - /data/wiki2:/data\n\n        db:\n        image: \"mysql\"\n        expose:\n            - \"3306\"\n        environment:\n            - MYSQL_ROOT_PASSWORD=defaultpass\n\n    上面的YAML文件定义了两个容器应用，第一个容器运行Python应用，并通过当前目录的Dockerfile文件构建。\n    第二个容器是从Docker Hub注册中心的Redis官方仓库中构建。links指令用来定义依赖，意思是Python应用依赖于Redis应用。\n    定义完成后，通过下面的命令来启动应用：\n\n    docker-compose up\n\n    links指令关注的是Python和Redis容器之间的依赖关系，Redis容器是最先开始构建，紧随其后的是Python容器。\n\n# Variable substitution\n            \nBoth $VARIABLE and ${VARIABLE} syntax are supported. \nExtended shell-style features, such as ${VARIABLE-default} and ${VARIABLE/foo/bar}, are not supported.\n            db:\n  image: \"postgres:${POSTGRES_VERSION}\"\n            web:\n  build: .\n  command: \"$$VAR_NOT_INTERPOLATED_BY_COMPOSE\"\n        \n# install\n\n    curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose --version | awk 'NR==1{print $NF}')/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose\n        doc\n            docker-compose.yml reference\n                https://docs.docker.com/compose/yml/\n        keywords\n            image\n                指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉去这个镜像\n                image: ubuntu\n            build\n                指定 Dockerfile 所在文件夹的路径\n                Compose 将会利用它自动构建这个镜像，然后使用这个镜像\n                build: /path/to/build/dir\n            dockerfile\n            command\n                覆盖容器启动后默认执行的命令。\n                command: bundle exec thin -p 3000\n            links\n                链接到其它服务中的容器\n                使用服务名称（同时作为别名）或服务名称：服务别名 （SERVICE:ALIAS） 格式都可以\n                    links:\n - db\n - db:database\n - redis\n                使用的别名将会自动在服务容器中的 /etc/hosts 里创建,相应的环境变量也将被创建\n                    172.17.2.186  db\n172.17.2.186  database\n172.17.2.187  redis\n            external_links\n                链接到 docker-compose.yml 外部的容器\n                甚至 并非 Compose 管理的容器。参数格式跟 links 类似\n                external_links:\n - redis_1\n - project_db_1:mysql\n - project_db_1:postgresql\n            extra_hosts\n            ports\n                暴露端口信息\n                使用宿主：容器 （HOST:CONTAINER）格式或者仅仅指定容器的端口（宿主将会随机选择端口）都可以\n                ports:\n - \"3000\"\n - \"8000:8000\"\n - \"49100:22\"\n - \"127.0.0.1:8001:8001\"\n            expose\n                暴露端口，但不映射到宿主机，只被连接的服务访问\n                仅可以指定内部端口为参数\n                expose:\n - \"3000\"\n - \"8000\"\n            volumes\n                卷挂载路径设置\n                可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）\n                volumes:\n - /var/lib/mysql\n - cache/:/tmp/cache\n - ~/configs:/etc/configs/:ro\n            volumes_from\n                从另一个服务或容器挂载它的所有卷\n                volumes_from:\n - service_name\n - container_name\n            environment\n                设置环境变量。你可以使用数组或字典两种格式。\n                只给定名称的变量会自动获取它在 Compose 主机上的值，可以用来防止泄露不必要的数据\n                environment:\n  RACK_ENV: development\n  SESSION_SECRET:\n\nenvironment:\n  - RACK_ENV=development\n  - SESSION_SECRET\n            env_file\n                从文件中获取环境变量，可以为单独的文件路径或列表。\n                如果通过 docker-compose -f FILE 指定了模板文件，则 env_file 中路径会基于模板文件路径。\n                如果有变量名称与 environment 指令冲突，则以后者为准。\n                env_file: .env\n\nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/secrets.env\n                环境变量文件中每一行必须符合格式，支持 # 开头的注释行\n                # common.env: Set Rails/Rack environment\nRACK_ENV=development\n            extends\n                基于已有的服务进行扩展\n                例如我们已经有了一个 webapp 服务，模板文件为 common.yml\n                # common.yml\nwebapp:\n  build: ./webapp\n  environment:\n    - DEBUG=false\n    - SEND_EMAILS=false\n                编写一个新的 development.yml 文件，使用 common.yml 中的 webapp 服务进行扩展\n                # development.yml\nweb:\n  extends:\n    file: common.yml\n    service: webapp\n  ports:\n    - \"8000:8000\"\n  links:\n    - db\n  environment:\n    - DEBUG=true\ndb:\n  image: postgres\n                后者会自动继承 common.yml 中的 webapp 服务及相关环节变量\n            labels\n            container_name\n            log driver\n            net\n                设置网络模式\n                使用和 docker client 的 --net 参数一样的值\n                net: \"bridge\"\nnet: \"none\"\nnet: \"container:[name or id]\"\nnet: \"host\"\n            pid\n                跟主机系统共享进程命名空间\n                打开该选项的容器可以相互通过进程 ID 来访问和操作\n                pid: \"host\"\n            dns\n                配置 DNS 服务器\n                可以是一个值，也可以是一个列表\n                dns: 8.8.8.8\ndns:\n  - 8.8.8.8\n  - 9.9.9.9\n            cap_add, cap_drop\n                添加或放弃容器的 Linux 能力（Capabiliity）\n                cap_add:\n  - ALL\n\ncap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n            dns_search\n                配置 DNS 搜索域\n                可以是一个值，也可以是一个列表\n                dns_search: example.com\ndns_search:\n  - domain1.example.com\n  - domain2.example.com\n            devices\n            security_opt\n            working_dir, entrypoint, user, hostname, domainname, \nmac_address, mem_limit, memswap_limit, privileged, \nrestart, stdin_open, tty, cpu_shares, cpuset, \nread_only, volume_driver\n                这些都是和 docker run 支持的选项类似\n                cpu_shares: 73\n\nworking_dir: /code\nentrypoint: /code/entrypoint.sh\nuser: postgresql\n\nhostname: foo\ndomainname: foo.com\n\nmem_limit: 1000000000\nprivileged: true\n\nrestart: always\n\nstdin_open: true\ntty: true\n        keyword\n            build\n                Path to a directory containing a Dockerfile.\n                build: /path/to/build/dir\n            cap_add, cap_drop\n                Add or drop container capabilities. See man 7 capabilities for a full list.\n                cap_add:\n  - ALL\n\ncap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n            command\n                Override the default command.\n                command: bundle exec thin -p 3000\n            cgroup_parent\n                Specify an optional parent cgroup for the container.\n                cgroup_parent: m-executor-abcd\n            container_name\n                Specify a custom container name, rather than a generated default name.\n                container_name: my-web-container\n            devices\n                List of device mappings. Uses the same format as the --device docker client create option.\n                devices:\n  - \"/dev/ttyUSB0:/dev/ttyUSB0\"\n            dns\n                Custom DNS servers. Can be a single value or a list.\n                dns: 8.8.8.8\ndns:\n  - 8.8.8.8\n  - 9.9.9.9\n            dns_search\n                Custom DNS search domains. Can be a single value or a list.\n                dns_search: example.com\ndns_search:\n  - dc1.example.com\n  - dc2.example.com\n            dockerfile\n                Alternate Dockerfile.\nCompose will use an alternate file to build with.\n                dockerfile: Dockerfile-alternate\n            env_file\n                Add environment variables from a file. Can be a single value or a list.\nIf you have specified a Compose file with docker-compose -f FILE, \npaths in env_file are relative to the directory that file is in.\nEnvironment variables specified in environment override these values.\n                env_file: .env\n\nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/secrets.env\n                Compose expects each line in an env file to be in VAR=VAL format.\n Lines beginning with # (i.e. comments) are ignored, as are blank lines.\n\n# Set Rails/Rack environment\nRACK_ENV=development\n            environment\n                Add environment variables. You can use either an array or a dictionary.\n                Any boolean values; true, false, yes no, need to be enclosed in quotes\n to ensure they are not converted to True or False by the YML parser.\n                Environment variables with only a key are resolved to their values on the machine Compose is running on, \nwhich can be helpful for secret or host-specific values.\n                environment:\n  RACK_ENV: development\n  SHOW: 'true'\n  SESSION_SECRET:\n\nenvironment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET\n            expose\n                Expose ports without publishing them to the host machine - \nthey’ll only be accessible to linked services. Only the internal port can be specified.\n                expose:\n - \"3000\"\n - \"8000\"\n            extends\n                Extend another service, in the current file or another, optionally overriding configuration.\nYou can use extends on any service together with other configuration keys.\n The extends value must be a dictionary defined with a required service and an optional file key.\n                extends:\n  file: common.yml\n  service: webapp\n            external_links\n                Link to containers started outside this docker-compose.yml or even outside of Compose,\n especially for containers that provide shared or common services. \nexternal_links follow semantics similar to links when specifying both the container name and the link alias (CONTAINER:ALIAS).\n                external_links:\n - redis_1\n - project_db_1:mysql\n - project_db_1:postgresql\n            extra_hosts\n                Add hostname mappings. Use the same values as the docker client --add-host parameter.\n                extra_hosts:\n - \"somehost:162.242.195.82\"\n - \"otherhost:50.31.209.229\"\n                An entry with the ip address and hostname will be created in /etc/hosts inside containers for this service, e.g:\n\n162.242.195.82  somehost\n50.31.209.229   otherhost\n            image\n                Tag or partial image ID. Can be local or remote - \nCompose will attempt to pull if it doesn’t exist locally.\n                image: ubuntu\nimage: orchardup/postgresql\nimage: a4bc65fd\n            labels\n                Add metadata to containers using Docker labels. You can use either an array or a dictionary.\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n                labels:\n  com.example.description: \"Accounting webapp\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n\nlabels:\n  - \"com.example.description=Accounting webapp\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n            links\n                Link to containers in another service. \nEither specify both the service name and the link alias (SERVICE:ALIAS), \nor just the service name (which will also be used for the alias).\n                links:\n - db\n - db:database\n - redis\n                An entry with the alias’ name will be created in /etc/hosts \ninside containers for this service, e.g:\n\n172.17.2.186  db\n172.17.2.186  database\n172.17.2.187  redis\n            log_driver\n                Specify a logging driver for the service’s containers, as with the --log-driver option for docker run\n                The default value is json-file.\nNote: Only the json-file driver makes the logs available directly from docker-compose up and docker-compose logs. \nUsing any other driver will not print any logs.\n                log_driver: \"json-file\"\nlog_driver: \"syslog\"\nlog_driver: \"none\"\n            log_opt\n                Specify logging options with log_opt for the logging driver, as with the --log-opt option for docker run.\n                log_driver: \"syslog\"\nlog_opt:\n  syslog-address: \"tcp://192.168.0.42:123\"\n            net\n                Networking mode. Use the same values as the docker client --net parameter.\n                net: \"bridge\"\nnet: \"none\"\nnet: \"container:[name or id]\"\nnet: \"host\"\n            pid\n                pid: \"host\"\n                Sets the PID mode to the host PID mode. \nThis turns on sharing between container and the host oprating system the PID address space.\n Containers launched with this flag will be able to access and manipulate other containers\n in the bare-metal machine’s namespace and vise-versa.\n            ports\n                Expose ports. Either specify both ports (HOST:CONTAINER), \nor just the container port (a random host port will be chosen).\n                Note: When mapping ports in the HOST:CONTAINER format, \nyou may experience erroneous results when using a container port lower than 60, \nbecause YAML will parse numbers in the format xx:yy as sexagesimal (base 60). \nFor this reason, we recommend always explicitly specifying your port mappings as strings.\n                ports:\n - \"3000\"\n - \"3000-3005\"\n - \"8000:8000\"\n - \"9090-9091:8080-8081\"\n - \"49100:22\"\n - \"127.0.0.1:8001:8001\"\n - \"127.0.0.1:5000-5010:5000-5010\"\n            security_opt\n                Override the default labeling scheme for each container.\n                security_opt:\n    - label:user:USER\n    - label:role:ROLE\n            ulimits\n                Override the default ulimits for a container. \nYou can either specify a single limit as an integer or soft/hard limits as a mapping.\n                ulimits:\n    nproc: 65535\n    nofile:\n      soft: 20000\n      hard: 40000\n            volumes, volume_driver\n                Mount paths as volumes, optionally specifying a path on the host machine \n(HOST:CONTAINER), or an access mode (HOST:CONTAINER:ro).\n                volumes:\n - /var/lib/mysql\n - ./cache:/tmp/cache\n - ~/configs:/etc/configs/:ro\n                You can mount a relative path on the host, which will expand relative to the director\ny of the Compose configuration file being used. Relative paths should always begin with . or ...\n                If you use a volume name (instead of a volume path), you may also specify a volume_driver.\nvolume_driver: mydriver\nNote: No path expansion will be done if you have also specified a volume_driver.\n            volumes_from\n                Mount all of the volumes from another service or container, \noptionally specifying read-only access(ro) or read-write(rw).\n                volumes_from:\n - service_name\n - container_name\n - service_name:rw\n            cpu_shares, cpuset, domainname, entrypoint, hostname, \nipc, mac_address, mem_limit, memswap_limit, privileged, \nread_only, restart, stdin_open, tty, user, working_dir\n                Each of these is a single value, analogous to its docker run counterpart.\n                cpu_shares: 73\ncpuset: 0,1\n\nentrypoint: /code/entrypoint.sh\nuser: postgresql\nworking_dir: /code\n\ndomainname: foo.com\nhostname: foo\nipc: host\nmac_address: 02:42:ac:11:65:43\n\nmem_limit: 1000000000\nmemswap_limit: 2000000000\nprivileged: true\n\nrestart: always\n\nread_only: true\nstdin_open: true\ntty: true","source":"_posts/docker-compose-file-detail.md","raw":"---\ntitle: docker compose\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about\n\n    The compose file is a YAML file where all the top level keys are the name of a service, \n    and the values are the service definition. \n    The default path for a compose file is ./docker-compose.yml.\n    \n    ```\n        containers:\n        web:\n         build: .\n         command: python app.py\n         ports:\n         - \"5000:5000\"\n         volumes:\n         - .:/code\n         links:\n         - redis\n         environment:\n         - PYTHONUNBUFFERED=1\n        redis:\n         image: redis:latest\n         command: redis-server --appendonly yes\n     ```\n\n     ```\n        wiki2:\n        image: 'nickstenning/mediawiki'\n        ports:\n            - \"8880:80\"\n        links:\n            - db:database\n        volumes:\n            - /data/wiki2:/data\n\n        db:\n        image: \"mysql\"\n        expose:\n            - \"3306\"\n        environment:\n            - MYSQL_ROOT_PASSWORD=defaultpass\n\n    上面的YAML文件定义了两个容器应用，第一个容器运行Python应用，并通过当前目录的Dockerfile文件构建。\n    第二个容器是从Docker Hub注册中心的Redis官方仓库中构建。links指令用来定义依赖，意思是Python应用依赖于Redis应用。\n    定义完成后，通过下面的命令来启动应用：\n\n    docker-compose up\n\n    links指令关注的是Python和Redis容器之间的依赖关系，Redis容器是最先开始构建，紧随其后的是Python容器。\n\n# Variable substitution\n            \nBoth $VARIABLE and ${VARIABLE} syntax are supported. \nExtended shell-style features, such as ${VARIABLE-default} and ${VARIABLE/foo/bar}, are not supported.\n            db:\n  image: \"postgres:${POSTGRES_VERSION}\"\n            web:\n  build: .\n  command: \"$$VAR_NOT_INTERPOLATED_BY_COMPOSE\"\n        \n# install\n\n    curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose --version | awk 'NR==1{print $NF}')/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose\n        doc\n            docker-compose.yml reference\n                https://docs.docker.com/compose/yml/\n        keywords\n            image\n                指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉去这个镜像\n                image: ubuntu\n            build\n                指定 Dockerfile 所在文件夹的路径\n                Compose 将会利用它自动构建这个镜像，然后使用这个镜像\n                build: /path/to/build/dir\n            dockerfile\n            command\n                覆盖容器启动后默认执行的命令。\n                command: bundle exec thin -p 3000\n            links\n                链接到其它服务中的容器\n                使用服务名称（同时作为别名）或服务名称：服务别名 （SERVICE:ALIAS） 格式都可以\n                    links:\n - db\n - db:database\n - redis\n                使用的别名将会自动在服务容器中的 /etc/hosts 里创建,相应的环境变量也将被创建\n                    172.17.2.186  db\n172.17.2.186  database\n172.17.2.187  redis\n            external_links\n                链接到 docker-compose.yml 外部的容器\n                甚至 并非 Compose 管理的容器。参数格式跟 links 类似\n                external_links:\n - redis_1\n - project_db_1:mysql\n - project_db_1:postgresql\n            extra_hosts\n            ports\n                暴露端口信息\n                使用宿主：容器 （HOST:CONTAINER）格式或者仅仅指定容器的端口（宿主将会随机选择端口）都可以\n                ports:\n - \"3000\"\n - \"8000:8000\"\n - \"49100:22\"\n - \"127.0.0.1:8001:8001\"\n            expose\n                暴露端口，但不映射到宿主机，只被连接的服务访问\n                仅可以指定内部端口为参数\n                expose:\n - \"3000\"\n - \"8000\"\n            volumes\n                卷挂载路径设置\n                可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）\n                volumes:\n - /var/lib/mysql\n - cache/:/tmp/cache\n - ~/configs:/etc/configs/:ro\n            volumes_from\n                从另一个服务或容器挂载它的所有卷\n                volumes_from:\n - service_name\n - container_name\n            environment\n                设置环境变量。你可以使用数组或字典两种格式。\n                只给定名称的变量会自动获取它在 Compose 主机上的值，可以用来防止泄露不必要的数据\n                environment:\n  RACK_ENV: development\n  SESSION_SECRET:\n\nenvironment:\n  - RACK_ENV=development\n  - SESSION_SECRET\n            env_file\n                从文件中获取环境变量，可以为单独的文件路径或列表。\n                如果通过 docker-compose -f FILE 指定了模板文件，则 env_file 中路径会基于模板文件路径。\n                如果有变量名称与 environment 指令冲突，则以后者为准。\n                env_file: .env\n\nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/secrets.env\n                环境变量文件中每一行必须符合格式，支持 # 开头的注释行\n                # common.env: Set Rails/Rack environment\nRACK_ENV=development\n            extends\n                基于已有的服务进行扩展\n                例如我们已经有了一个 webapp 服务，模板文件为 common.yml\n                # common.yml\nwebapp:\n  build: ./webapp\n  environment:\n    - DEBUG=false\n    - SEND_EMAILS=false\n                编写一个新的 development.yml 文件，使用 common.yml 中的 webapp 服务进行扩展\n                # development.yml\nweb:\n  extends:\n    file: common.yml\n    service: webapp\n  ports:\n    - \"8000:8000\"\n  links:\n    - db\n  environment:\n    - DEBUG=true\ndb:\n  image: postgres\n                后者会自动继承 common.yml 中的 webapp 服务及相关环节变量\n            labels\n            container_name\n            log driver\n            net\n                设置网络模式\n                使用和 docker client 的 --net 参数一样的值\n                net: \"bridge\"\nnet: \"none\"\nnet: \"container:[name or id]\"\nnet: \"host\"\n            pid\n                跟主机系统共享进程命名空间\n                打开该选项的容器可以相互通过进程 ID 来访问和操作\n                pid: \"host\"\n            dns\n                配置 DNS 服务器\n                可以是一个值，也可以是一个列表\n                dns: 8.8.8.8\ndns:\n  - 8.8.8.8\n  - 9.9.9.9\n            cap_add, cap_drop\n                添加或放弃容器的 Linux 能力（Capabiliity）\n                cap_add:\n  - ALL\n\ncap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n            dns_search\n                配置 DNS 搜索域\n                可以是一个值，也可以是一个列表\n                dns_search: example.com\ndns_search:\n  - domain1.example.com\n  - domain2.example.com\n            devices\n            security_opt\n            working_dir, entrypoint, user, hostname, domainname, \nmac_address, mem_limit, memswap_limit, privileged, \nrestart, stdin_open, tty, cpu_shares, cpuset, \nread_only, volume_driver\n                这些都是和 docker run 支持的选项类似\n                cpu_shares: 73\n\nworking_dir: /code\nentrypoint: /code/entrypoint.sh\nuser: postgresql\n\nhostname: foo\ndomainname: foo.com\n\nmem_limit: 1000000000\nprivileged: true\n\nrestart: always\n\nstdin_open: true\ntty: true\n        keyword\n            build\n                Path to a directory containing a Dockerfile.\n                build: /path/to/build/dir\n            cap_add, cap_drop\n                Add or drop container capabilities. See man 7 capabilities for a full list.\n                cap_add:\n  - ALL\n\ncap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n            command\n                Override the default command.\n                command: bundle exec thin -p 3000\n            cgroup_parent\n                Specify an optional parent cgroup for the container.\n                cgroup_parent: m-executor-abcd\n            container_name\n                Specify a custom container name, rather than a generated default name.\n                container_name: my-web-container\n            devices\n                List of device mappings. Uses the same format as the --device docker client create option.\n                devices:\n  - \"/dev/ttyUSB0:/dev/ttyUSB0\"\n            dns\n                Custom DNS servers. Can be a single value or a list.\n                dns: 8.8.8.8\ndns:\n  - 8.8.8.8\n  - 9.9.9.9\n            dns_search\n                Custom DNS search domains. Can be a single value or a list.\n                dns_search: example.com\ndns_search:\n  - dc1.example.com\n  - dc2.example.com\n            dockerfile\n                Alternate Dockerfile.\nCompose will use an alternate file to build with.\n                dockerfile: Dockerfile-alternate\n            env_file\n                Add environment variables from a file. Can be a single value or a list.\nIf you have specified a Compose file with docker-compose -f FILE, \npaths in env_file are relative to the directory that file is in.\nEnvironment variables specified in environment override these values.\n                env_file: .env\n\nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/secrets.env\n                Compose expects each line in an env file to be in VAR=VAL format.\n Lines beginning with # (i.e. comments) are ignored, as are blank lines.\n\n# Set Rails/Rack environment\nRACK_ENV=development\n            environment\n                Add environment variables. You can use either an array or a dictionary.\n                Any boolean values; true, false, yes no, need to be enclosed in quotes\n to ensure they are not converted to True or False by the YML parser.\n                Environment variables with only a key are resolved to their values on the machine Compose is running on, \nwhich can be helpful for secret or host-specific values.\n                environment:\n  RACK_ENV: development\n  SHOW: 'true'\n  SESSION_SECRET:\n\nenvironment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET\n            expose\n                Expose ports without publishing them to the host machine - \nthey’ll only be accessible to linked services. Only the internal port can be specified.\n                expose:\n - \"3000\"\n - \"8000\"\n            extends\n                Extend another service, in the current file or another, optionally overriding configuration.\nYou can use extends on any service together with other configuration keys.\n The extends value must be a dictionary defined with a required service and an optional file key.\n                extends:\n  file: common.yml\n  service: webapp\n            external_links\n                Link to containers started outside this docker-compose.yml or even outside of Compose,\n especially for containers that provide shared or common services. \nexternal_links follow semantics similar to links when specifying both the container name and the link alias (CONTAINER:ALIAS).\n                external_links:\n - redis_1\n - project_db_1:mysql\n - project_db_1:postgresql\n            extra_hosts\n                Add hostname mappings. Use the same values as the docker client --add-host parameter.\n                extra_hosts:\n - \"somehost:162.242.195.82\"\n - \"otherhost:50.31.209.229\"\n                An entry with the ip address and hostname will be created in /etc/hosts inside containers for this service, e.g:\n\n162.242.195.82  somehost\n50.31.209.229   otherhost\n            image\n                Tag or partial image ID. Can be local or remote - \nCompose will attempt to pull if it doesn’t exist locally.\n                image: ubuntu\nimage: orchardup/postgresql\nimage: a4bc65fd\n            labels\n                Add metadata to containers using Docker labels. You can use either an array or a dictionary.\nIt’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n                labels:\n  com.example.description: \"Accounting webapp\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n\nlabels:\n  - \"com.example.description=Accounting webapp\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n            links\n                Link to containers in another service. \nEither specify both the service name and the link alias (SERVICE:ALIAS), \nor just the service name (which will also be used for the alias).\n                links:\n - db\n - db:database\n - redis\n                An entry with the alias’ name will be created in /etc/hosts \ninside containers for this service, e.g:\n\n172.17.2.186  db\n172.17.2.186  database\n172.17.2.187  redis\n            log_driver\n                Specify a logging driver for the service’s containers, as with the --log-driver option for docker run\n                The default value is json-file.\nNote: Only the json-file driver makes the logs available directly from docker-compose up and docker-compose logs. \nUsing any other driver will not print any logs.\n                log_driver: \"json-file\"\nlog_driver: \"syslog\"\nlog_driver: \"none\"\n            log_opt\n                Specify logging options with log_opt for the logging driver, as with the --log-opt option for docker run.\n                log_driver: \"syslog\"\nlog_opt:\n  syslog-address: \"tcp://192.168.0.42:123\"\n            net\n                Networking mode. Use the same values as the docker client --net parameter.\n                net: \"bridge\"\nnet: \"none\"\nnet: \"container:[name or id]\"\nnet: \"host\"\n            pid\n                pid: \"host\"\n                Sets the PID mode to the host PID mode. \nThis turns on sharing between container and the host oprating system the PID address space.\n Containers launched with this flag will be able to access and manipulate other containers\n in the bare-metal machine’s namespace and vise-versa.\n            ports\n                Expose ports. Either specify both ports (HOST:CONTAINER), \nor just the container port (a random host port will be chosen).\n                Note: When mapping ports in the HOST:CONTAINER format, \nyou may experience erroneous results when using a container port lower than 60, \nbecause YAML will parse numbers in the format xx:yy as sexagesimal (base 60). \nFor this reason, we recommend always explicitly specifying your port mappings as strings.\n                ports:\n - \"3000\"\n - \"3000-3005\"\n - \"8000:8000\"\n - \"9090-9091:8080-8081\"\n - \"49100:22\"\n - \"127.0.0.1:8001:8001\"\n - \"127.0.0.1:5000-5010:5000-5010\"\n            security_opt\n                Override the default labeling scheme for each container.\n                security_opt:\n    - label:user:USER\n    - label:role:ROLE\n            ulimits\n                Override the default ulimits for a container. \nYou can either specify a single limit as an integer or soft/hard limits as a mapping.\n                ulimits:\n    nproc: 65535\n    nofile:\n      soft: 20000\n      hard: 40000\n            volumes, volume_driver\n                Mount paths as volumes, optionally specifying a path on the host machine \n(HOST:CONTAINER), or an access mode (HOST:CONTAINER:ro).\n                volumes:\n - /var/lib/mysql\n - ./cache:/tmp/cache\n - ~/configs:/etc/configs/:ro\n                You can mount a relative path on the host, which will expand relative to the director\ny of the Compose configuration file being used. Relative paths should always begin with . or ...\n                If you use a volume name (instead of a volume path), you may also specify a volume_driver.\nvolume_driver: mydriver\nNote: No path expansion will be done if you have also specified a volume_driver.\n            volumes_from\n                Mount all of the volumes from another service or container, \noptionally specifying read-only access(ro) or read-write(rw).\n                volumes_from:\n - service_name\n - container_name\n - service_name:rw\n            cpu_shares, cpuset, domainname, entrypoint, hostname, \nipc, mac_address, mem_limit, memswap_limit, privileged, \nread_only, restart, stdin_open, tty, user, working_dir\n                Each of these is a single value, analogous to its docker run counterpart.\n                cpu_shares: 73\ncpuset: 0,1\n\nentrypoint: /code/entrypoint.sh\nuser: postgresql\nworking_dir: /code\n\ndomainname: foo.com\nhostname: foo\nipc: host\nmac_address: 02:42:ac:11:65:43\n\nmem_limit: 1000000000\nmemswap_limit: 2000000000\nprivileged: true\n\nrestart: always\n\nread_only: true\nstdin_open: true\ntty: true","slug":"docker-compose-file-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T12:37:59.000Z","_id":"cixvsa4yr0003nus6iizqdhj1","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><pre><code>The compose file is a YAML file where all the top level keys are the name of a service, \nand the values are the service definition. \nThe default path for a compose file is ./docker-compose.yml.\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">containers:</div><div class=\"line\">web:</div><div class=\"line\"> build: .</div><div class=\"line\"> command: python app.py</div><div class=\"line\"> ports:</div><div class=\"line\"> - &quot;5000:5000&quot;</div><div class=\"line\"> volumes:</div><div class=\"line\"> - .:/code</div><div class=\"line\"> links:</div><div class=\"line\"> - redis</div><div class=\"line\"> environment:</div><div class=\"line\"> - PYTHONUNBUFFERED=1</div><div class=\"line\">redis:</div><div class=\"line\"> image: redis:latest</div><div class=\"line\"> command: redis-server --appendonly yes</div></pre></td></tr></table></figure>\n\n ```\n    wiki2:\n    image: &apos;nickstenning/mediawiki&apos;\n    ports:\n        - &quot;8880:80&quot;\n    links:\n        - db:database\n    volumes:\n        - /data/wiki2:/data\n\n    db:\n    image: &quot;mysql&quot;\n    expose:\n        - &quot;3306&quot;\n    environment:\n        - MYSQL_ROOT_PASSWORD=defaultpass\n\n上面的YAML文件定义了两个容器应用，第一个容器运行Python应用，并通过当前目录的Dockerfile文件构建。\n第二个容器是从Docker Hub注册中心的Redis官方仓库中构建。links指令用来定义依赖，意思是Python应用依赖于Redis应用。\n定义完成后，通过下面的命令来启动应用：\n\ndocker-compose up\n\nlinks指令关注的是Python和Redis容器之间的依赖关系，Redis容器是最先开始构建，紧随其后的是Python容器。\n</code></pre><h1 id=\"Variable-substitution\"><a href=\"#Variable-substitution\" class=\"headerlink\" title=\"Variable substitution\"></a>Variable substitution</h1><p>Both $VARIABLE and ${VARIABLE} syntax are supported.<br>Extended shell-style features, such as ${VARIABLE-default} and ${VARIABLE/foo/bar}, are not supported.<br>            db:<br>  image: “postgres:${POSTGRES_VERSION}”<br>            web:<br>  build: .<br>  command: “$$VAR_NOT_INTERPOLATED_BY_COMPOSE”</p>\n<h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><pre><code>curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose --version | awk &apos;NR==1{print $NF}&apos;)/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose\n    doc\n        docker-compose.yml reference\n            https://docs.docker.com/compose/yml/\n    keywords\n        image\n            指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉去这个镜像\n            image: ubuntu\n        build\n            指定 Dockerfile 所在文件夹的路径\n            Compose 将会利用它自动构建这个镜像，然后使用这个镜像\n            build: /path/to/build/dir\n        dockerfile\n        command\n            覆盖容器启动后默认执行的命令。\n            command: bundle exec thin -p 3000\n        links\n            链接到其它服务中的容器\n            使用服务名称（同时作为别名）或服务名称：服务别名 （SERVICE:ALIAS） 格式都可以\n                links:\n</code></pre><ul>\n<li>db</li>\n<li>db:database</li>\n<li>redis<pre><code>使用的别名将会自动在服务容器中的 /etc/hosts 里创建,相应的环境变量也将被创建\n    172.17.2.186  db\n</code></pre>172.17.2.186  database<br>172.17.2.187  redis<pre><code>external_links\n    链接到 docker-compose.yml 外部的容器\n    甚至 并非 Compose 管理的容器。参数格式跟 links 类似\n    external_links:\n</code></pre></li>\n<li>redis_1</li>\n<li>project_db_1:mysql</li>\n<li>project_db_1:postgresql<pre><code>extra_hosts\nports\n    暴露端口信息\n    使用宿主：容器 （HOST:CONTAINER）格式或者仅仅指定容器的端口（宿主将会随机选择端口）都可以\n    ports:\n</code></pre></li>\n<li>“3000”</li>\n<li>“8000:8000”</li>\n<li>“49100:22”</li>\n<li>“127.0.0.1:8001:8001”<pre><code>expose\n    暴露端口，但不映射到宿主机，只被连接的服务访问\n    仅可以指定内部端口为参数\n    expose:\n</code></pre></li>\n<li>“3000”</li>\n<li>“8000”<pre><code>volumes\n    卷挂载路径设置\n    可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）\n    volumes:\n</code></pre></li>\n<li>/var/lib/mysql</li>\n<li>cache/:/tmp/cache</li>\n<li>~/configs:/etc/configs/:ro<pre><code>volumes_from\n    从另一个服务或容器挂载它的所有卷\n    volumes_from:\n</code></pre></li>\n<li>service_name</li>\n<li>container_name<pre><code>environment\n    设置环境变量。你可以使用数组或字典两种格式。\n    只给定名称的变量会自动获取它在 Compose 主机上的值，可以用来防止泄露不必要的数据\n    environment:\n</code></pre>RACK_ENV: development<br>SESSION_SECRET:</li>\n</ul>\n<p>environment:</p>\n<ul>\n<li>RACK_ENV=development</li>\n<li>SESSION_SECRET<pre><code>env_file\n    从文件中获取环境变量，可以为单独的文件路径或列表。\n    如果通过 docker-compose -f FILE 指定了模板文件，则 env_file 中路径会基于模板文件路径。\n    如果有变量名称与 environment 指令冲突，则以后者为准。\n    env_file: .env\n</code></pre></li>\n</ul>\n<p>env_file:</p>\n<ul>\n<li>./common.env</li>\n<li>./apps/web.env</li>\n<li>/opt/secrets.env<pre><code>环境变量文件中每一行必须符合格式，支持 # 开头的注释行\n# common.env: Set Rails/Rack environment\n</code></pre>RACK_ENV=development<pre><code>extends\n    基于已有的服务进行扩展\n    例如我们已经有了一个 webapp 服务，模板文件为 common.yml\n    # common.yml\n</code></pre>webapp:<br>build: ./webapp<br>environment:<ul>\n<li>DEBUG=false</li>\n<li>SEND_EMAILS=false<pre><code>编写一个新的 development.yml 文件，使用 common.yml 中的 webapp 服务进行扩展\n# development.yml\n</code></pre>web:<br>extends:<br>file: common.yml<br>service: webapp<br>ports:</li>\n<li>“8000:8000”<br>links:</li>\n<li>db<br>environment:</li>\n<li>DEBUG=true<br>db:<br>image: postgres<pre><code>    后者会自动继承 common.yml 中的 webapp 服务及相关环节变量\nlabels\ncontainer_name\nlog driver\nnet\n    设置网络模式\n    使用和 docker client 的 --net 参数一样的值\n    net: &quot;bridge&quot;\n</code></pre>net: “none”<br>net: “container:[name or id]”<br>net: “host”<pre><code>pid\n    跟主机系统共享进程命名空间\n    打开该选项的容器可以相互通过进程 ID 来访问和操作\n    pid: &quot;host&quot;\ndns\n    配置 DNS 服务器\n    可以是一个值，也可以是一个列表\n    dns: 8.8.8.8\n</code></pre>dns:</li>\n</ul>\n</li>\n<li>8.8.8.8</li>\n<li>9.9.9.9<pre><code>cap_add, cap_drop\n    添加或放弃容器的 Linux 能力（Capabiliity）\n    cap_add:\n</code></pre></li>\n<li>ALL</li>\n</ul>\n<p>cap_drop:</p>\n<ul>\n<li>NET_ADMIN</li>\n<li>SYS_ADMIN<pre><code>dns_search\n    配置 DNS 搜索域\n    可以是一个值，也可以是一个列表\n    dns_search: example.com\n</code></pre>dns_search:</li>\n<li>domain1.example.com</li>\n<li>domain2.example.com<pre><code>devices\nsecurity_opt\nworking_dir, entrypoint, user, hostname, domainname, \n</code></pre>mac_address, mem_limit, memswap_limit, privileged,<br>restart, stdin_open, tty, cpu_shares, cpuset,<br>read_only, volume_driver<pre><code>这些都是和 docker run 支持的选项类似\ncpu_shares: 73\n</code></pre></li>\n</ul>\n<p>working_dir: /code<br>entrypoint: /code/entrypoint.sh<br>user: postgresql</p>\n<p>hostname: foo<br>domainname: foo.com</p>\n<p>mem_limit: 1000000000<br>privileged: true</p>\n<p>restart: always</p>\n<p>stdin_open: true<br>tty: true<br>        keyword<br>            build<br>                Path to a directory containing a Dockerfile.<br>                build: /path/to/build/dir<br>            cap_add, cap_drop<br>                Add or drop container capabilities. See man 7 capabilities for a full list.<br>                cap_add:</p>\n<ul>\n<li>ALL</li>\n</ul>\n<p>cap_drop:</p>\n<ul>\n<li>NET_ADMIN</li>\n<li>SYS_ADMIN<pre><code>command\n    Override the default command.\n    command: bundle exec thin -p 3000\ncgroup_parent\n    Specify an optional parent cgroup for the container.\n    cgroup_parent: m-executor-abcd\ncontainer_name\n    Specify a custom container name, rather than a generated default name.\n    container_name: my-web-container\ndevices\n    List of device mappings. Uses the same format as the --device docker client create option.\n    devices:\n</code></pre></li>\n<li>“/dev/ttyUSB0:/dev/ttyUSB0”<pre><code>dns\n    Custom DNS servers. Can be a single value or a list.\n    dns: 8.8.8.8\n</code></pre>dns:</li>\n<li>8.8.8.8</li>\n<li>9.9.9.9<pre><code>dns_search\n    Custom DNS search domains. Can be a single value or a list.\n    dns_search: example.com\n</code></pre>dns_search:</li>\n<li>dc1.example.com</li>\n<li>dc2.example.com<pre><code>dockerfile\n    Alternate Dockerfile.\n</code></pre>Compose will use an alternate file to build with.<pre><code>    dockerfile: Dockerfile-alternate\nenv_file\n    Add environment variables from a file. Can be a single value or a list.\n</code></pre>If you have specified a Compose file with docker-compose -f FILE,<br>paths in env_file are relative to the directory that file is in.<br>Environment variables specified in environment override these values.<pre><code>env_file: .env\n</code></pre></li>\n</ul>\n<p>env_file:</p>\n<ul>\n<li>./common.env</li>\n<li>./apps/web.env</li>\n<li>/opt/secrets.env<pre><code>Compose expects each line in an env file to be in VAR=VAL format.\n</code></pre>Lines beginning with # (i.e. comments) are ignored, as are blank lines.</li>\n</ul>\n<h1 id=\"Set-Rails-Rack-environment\"><a href=\"#Set-Rails-Rack-environment\" class=\"headerlink\" title=\"Set Rails/Rack environment\"></a>Set Rails/Rack environment</h1><p>RACK_ENV=development<br>            environment<br>                Add environment variables. You can use either an array or a dictionary.<br>                Any boolean values; true, false, yes no, need to be enclosed in quotes<br> to ensure they are not converted to True or False by the YML parser.<br>                Environment variables with only a key are resolved to their values on the machine Compose is running on,<br>which can be helpful for secret or host-specific values.<br>                environment:<br>  RACK_ENV: development<br>  SHOW: ‘true’<br>  SESSION_SECRET:</p>\n<p>environment:</p>\n<ul>\n<li>RACK_ENV=development</li>\n<li>SHOW=true</li>\n<li>SESSION_SECRET<pre><code>expose\n    Expose ports without publishing them to the host machine - \n</code></pre>they’ll only be accessible to linked services. Only the internal port can be specified.<pre><code>expose:\n</code></pre><ul>\n<li>“3000”</li>\n<li>“8000”<pre><code>extends\n    Extend another service, in the current file or another, optionally overriding configuration.\n</code></pre>You can use extends on any service together with other configuration keys.<br>The extends value must be a dictionary defined with a required service and an optional file key.<pre><code>extends:\n</code></pre>file: common.yml<br>service: webapp<pre><code>external_links\n    Link to containers started outside this docker-compose.yml or even outside of Compose,\n</code></pre>especially for containers that provide shared or common services.<br>external_links follow semantics similar to links when specifying both the container name and the link alias (CONTAINER:ALIAS).<pre><code>external_links:\n</code></pre></li>\n<li>redis_1</li>\n<li>project_db_1:mysql</li>\n<li>project_db_1:postgresql<pre><code>extra_hosts\n    Add hostname mappings. Use the same values as the docker client --add-host parameter.\n    extra_hosts:\n</code></pre></li>\n<li>“somehost:162.242.195.82”</li>\n<li>“otherhost:50.31.209.229”<pre><code>An entry with the ip address and hostname will be created in /etc/hosts inside containers for this service, e.g:\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<p>162.242.195.82  somehost<br>50.31.209.229   otherhost<br>            image<br>                Tag or partial image ID. Can be local or remote -<br>Compose will attempt to pull if it doesn’t exist locally.<br>                image: ubuntu<br>image: orchardup/postgresql<br>image: a4bc65fd<br>            labels<br>                Add metadata to containers using Docker labels. You can use either an array or a dictionary.<br>It’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.<br>                labels:<br>  com.example.description: “Accounting webapp”<br>  com.example.department: “Finance”<br>  com.example.label-with-empty-value: “”</p>\n<p>labels:</p>\n<ul>\n<li>“com.example.description=Accounting webapp”</li>\n<li>“com.example.department=Finance”</li>\n<li>“com.example.label-with-empty-value”<pre><code>links\n    Link to containers in another service. \n</code></pre>Either specify both the service name and the link alias (SERVICE:ALIAS),<br>or just the service name (which will also be used for the alias).<pre><code>links:\n</code></pre><ul>\n<li>db</li>\n<li>db:database</li>\n<li>redis<pre><code>An entry with the alias’ name will be created in /etc/hosts \n</code></pre>inside containers for this service, e.g:</li>\n</ul>\n</li>\n</ul>\n<p>172.17.2.186  db<br>172.17.2.186  database<br>172.17.2.187  redis<br>            log_driver<br>                Specify a logging driver for the service’s containers, as with the –log-driver option for docker run<br>                The default value is json-file.<br>Note: Only the json-file driver makes the logs available directly from docker-compose up and docker-compose logs.<br>Using any other driver will not print any logs.<br>                log_driver: “json-file”<br>log_driver: “syslog”<br>log_driver: “none”<br>            log_opt<br>                Specify logging options with log_opt for the logging driver, as with the –log-opt option for docker run.<br>                log_driver: “syslog”<br>log_opt:<br>  syslog-address: “tcp://192.168.0.42:123”<br>            net<br>                Networking mode. Use the same values as the docker client –net parameter.<br>                net: “bridge”<br>net: “none”<br>net: “container:[name or id]”<br>net: “host”<br>            pid<br>                pid: “host”<br>                Sets the PID mode to the host PID mode.<br>This turns on sharing between container and the host oprating system the PID address space.<br> Containers launched with this flag will be able to access and manipulate other containers<br> in the bare-metal machine’s namespace and vise-versa.<br>            ports<br>                Expose ports. Either specify both ports (HOST:CONTAINER),<br>or just the container port (a random host port will be chosen).<br>                Note: When mapping ports in the HOST:CONTAINER format,<br>you may experience erroneous results when using a container port lower than 60,<br>because YAML will parse numbers in the format xx:yy as sexagesimal (base 60).<br>For this reason, we recommend always explicitly specifying your port mappings as strings.<br>                ports:</p>\n<ul>\n<li>“3000”</li>\n<li>“3000-3005”</li>\n<li>“8000:8000”</li>\n<li>“9090-9091:8080-8081”</li>\n<li>“49100:22”</li>\n<li>“127.0.0.1:8001:8001”</li>\n<li>“127.0.0.1:5000-5010:5000-5010”<pre><code>security_opt\n    Override the default labeling scheme for each container.\n    security_opt:\n</code></pre><ul>\n<li>label:user:USER</li>\n<li>label:role:ROLE<pre><code>ulimits\n    Override the default ulimits for a container. \n</code></pre>You can either specify a single limit as an integer or soft/hard limits as a mapping.<pre><code>ulimits:\n</code></pre>nproc: 65535<br>nofile:<br>soft: 20000<br>hard: 40000<pre><code>volumes, volume_driver\n    Mount paths as volumes, optionally specifying a path on the host machine \n</code></pre>(HOST:CONTAINER), or an access mode (HOST:CONTAINER:ro).<pre><code>volumes:\n</code></pre></li>\n</ul>\n</li>\n<li>/var/lib/mysql</li>\n<li>./cache:/tmp/cache</li>\n<li>~/configs:/etc/configs/:ro<pre><code>You can mount a relative path on the host, which will expand relative to the director\n</code></pre>y of the Compose configuration file being used. Relative paths should always begin with . or …<pre><code>If you use a volume name (instead of a volume path), you may also specify a volume_driver.\n</code></pre>volume_driver: mydriver<br>Note: No path expansion will be done if you have also specified a volume_driver.<pre><code>volumes_from\n    Mount all of the volumes from another service or container, \n</code></pre>optionally specifying read-only access(ro) or read-write(rw).<pre><code>volumes_from:\n</code></pre></li>\n<li>service_name</li>\n<li>container_name</li>\n<li>service_name:rw<pre><code>cpu_shares, cpuset, domainname, entrypoint, hostname, \n</code></pre>ipc, mac_address, mem_limit, memswap_limit, privileged,<br>read_only, restart, stdin_open, tty, user, working_dir<pre><code>Each of these is a single value, analogous to its docker run counterpart.\ncpu_shares: 73\n</code></pre>cpuset: 0,1</li>\n</ul>\n<p>entrypoint: /code/entrypoint.sh<br>user: postgresql<br>working_dir: /code</p>\n<p>domainname: foo.com<br>hostname: foo<br>ipc: host<br>mac_address: 02:42:ac:11:65:43</p>\n<p>mem_limit: 1000000000<br>memswap_limit: 2000000000<br>privileged: true</p>\n<p>restart: always</p>\n<p>read_only: true<br>stdin_open: true<br>tty: true</p>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><pre><code>The compose file is a YAML file where all the top level keys are the name of a service, \nand the values are the service definition. \nThe default path for a compose file is ./docker-compose.yml.\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">containers:</div><div class=\"line\">web:</div><div class=\"line\"> build: .</div><div class=\"line\"> command: python app.py</div><div class=\"line\"> ports:</div><div class=\"line\"> - &quot;5000:5000&quot;</div><div class=\"line\"> volumes:</div><div class=\"line\"> - .:/code</div><div class=\"line\"> links:</div><div class=\"line\"> - redis</div><div class=\"line\"> environment:</div><div class=\"line\"> - PYTHONUNBUFFERED=1</div><div class=\"line\">redis:</div><div class=\"line\"> image: redis:latest</div><div class=\"line\"> command: redis-server --appendonly yes</div></pre></td></tr></table></figure>\n\n ```\n    wiki2:\n    image: &apos;nickstenning/mediawiki&apos;\n    ports:\n        - &quot;8880:80&quot;\n    links:\n        - db:database\n    volumes:\n        - /data/wiki2:/data\n\n    db:\n    image: &quot;mysql&quot;\n    expose:\n        - &quot;3306&quot;\n    environment:\n        - MYSQL_ROOT_PASSWORD=defaultpass\n\n上面的YAML文件定义了两个容器应用，第一个容器运行Python应用，并通过当前目录的Dockerfile文件构建。\n第二个容器是从Docker Hub注册中心的Redis官方仓库中构建。links指令用来定义依赖，意思是Python应用依赖于Redis应用。\n定义完成后，通过下面的命令来启动应用：\n\ndocker-compose up\n\nlinks指令关注的是Python和Redis容器之间的依赖关系，Redis容器是最先开始构建，紧随其后的是Python容器。\n</code></pre><h1 id=\"Variable-substitution\"><a href=\"#Variable-substitution\" class=\"headerlink\" title=\"Variable substitution\"></a>Variable substitution</h1><p>Both $VARIABLE and ${VARIABLE} syntax are supported.<br>Extended shell-style features, such as ${VARIABLE-default} and ${VARIABLE/foo/bar}, are not supported.<br>            db:<br>  image: “postgres:${POSTGRES_VERSION}”<br>            web:<br>  build: .<br>  command: “$$VAR_NOT_INTERPOLATED_BY_COMPOSE”</p>\n<h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><pre><code>curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose --version | awk &apos;NR==1{print $NF}&apos;)/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose\n    doc\n        docker-compose.yml reference\n            https://docs.docker.com/compose/yml/\n    keywords\n        image\n            指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉去这个镜像\n            image: ubuntu\n        build\n            指定 Dockerfile 所在文件夹的路径\n            Compose 将会利用它自动构建这个镜像，然后使用这个镜像\n            build: /path/to/build/dir\n        dockerfile\n        command\n            覆盖容器启动后默认执行的命令。\n            command: bundle exec thin -p 3000\n        links\n            链接到其它服务中的容器\n            使用服务名称（同时作为别名）或服务名称：服务别名 （SERVICE:ALIAS） 格式都可以\n                links:\n</code></pre><ul>\n<li>db</li>\n<li>db:database</li>\n<li>redis<pre><code>使用的别名将会自动在服务容器中的 /etc/hosts 里创建,相应的环境变量也将被创建\n    172.17.2.186  db\n</code></pre>172.17.2.186  database<br>172.17.2.187  redis<pre><code>external_links\n    链接到 docker-compose.yml 外部的容器\n    甚至 并非 Compose 管理的容器。参数格式跟 links 类似\n    external_links:\n</code></pre></li>\n<li>redis_1</li>\n<li>project_db_1:mysql</li>\n<li>project_db_1:postgresql<pre><code>extra_hosts\nports\n    暴露端口信息\n    使用宿主：容器 （HOST:CONTAINER）格式或者仅仅指定容器的端口（宿主将会随机选择端口）都可以\n    ports:\n</code></pre></li>\n<li>“3000”</li>\n<li>“8000:8000”</li>\n<li>“49100:22”</li>\n<li>“127.0.0.1:8001:8001”<pre><code>expose\n    暴露端口，但不映射到宿主机，只被连接的服务访问\n    仅可以指定内部端口为参数\n    expose:\n</code></pre></li>\n<li>“3000”</li>\n<li>“8000”<pre><code>volumes\n    卷挂载路径设置\n    可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）\n    volumes:\n</code></pre></li>\n<li>/var/lib/mysql</li>\n<li>cache/:/tmp/cache</li>\n<li>~/configs:/etc/configs/:ro<pre><code>volumes_from\n    从另一个服务或容器挂载它的所有卷\n    volumes_from:\n</code></pre></li>\n<li>service_name</li>\n<li>container_name<pre><code>environment\n    设置环境变量。你可以使用数组或字典两种格式。\n    只给定名称的变量会自动获取它在 Compose 主机上的值，可以用来防止泄露不必要的数据\n    environment:\n</code></pre>RACK_ENV: development<br>SESSION_SECRET:</li>\n</ul>\n<p>environment:</p>\n<ul>\n<li>RACK_ENV=development</li>\n<li>SESSION_SECRET<pre><code>env_file\n    从文件中获取环境变量，可以为单独的文件路径或列表。\n    如果通过 docker-compose -f FILE 指定了模板文件，则 env_file 中路径会基于模板文件路径。\n    如果有变量名称与 environment 指令冲突，则以后者为准。\n    env_file: .env\n</code></pre></li>\n</ul>\n<p>env_file:</p>\n<ul>\n<li>./common.env</li>\n<li>./apps/web.env</li>\n<li>/opt/secrets.env<pre><code>环境变量文件中每一行必须符合格式，支持 # 开头的注释行\n# common.env: Set Rails/Rack environment\n</code></pre>RACK_ENV=development<pre><code>extends\n    基于已有的服务进行扩展\n    例如我们已经有了一个 webapp 服务，模板文件为 common.yml\n    # common.yml\n</code></pre>webapp:<br>build: ./webapp<br>environment:<ul>\n<li>DEBUG=false</li>\n<li>SEND_EMAILS=false<pre><code>编写一个新的 development.yml 文件，使用 common.yml 中的 webapp 服务进行扩展\n# development.yml\n</code></pre>web:<br>extends:<br>file: common.yml<br>service: webapp<br>ports:</li>\n<li>“8000:8000”<br>links:</li>\n<li>db<br>environment:</li>\n<li>DEBUG=true<br>db:<br>image: postgres<pre><code>    后者会自动继承 common.yml 中的 webapp 服务及相关环节变量\nlabels\ncontainer_name\nlog driver\nnet\n    设置网络模式\n    使用和 docker client 的 --net 参数一样的值\n    net: &quot;bridge&quot;\n</code></pre>net: “none”<br>net: “container:[name or id]”<br>net: “host”<pre><code>pid\n    跟主机系统共享进程命名空间\n    打开该选项的容器可以相互通过进程 ID 来访问和操作\n    pid: &quot;host&quot;\ndns\n    配置 DNS 服务器\n    可以是一个值，也可以是一个列表\n    dns: 8.8.8.8\n</code></pre>dns:</li>\n</ul>\n</li>\n<li>8.8.8.8</li>\n<li>9.9.9.9<pre><code>cap_add, cap_drop\n    添加或放弃容器的 Linux 能力（Capabiliity）\n    cap_add:\n</code></pre></li>\n<li>ALL</li>\n</ul>\n<p>cap_drop:</p>\n<ul>\n<li>NET_ADMIN</li>\n<li>SYS_ADMIN<pre><code>dns_search\n    配置 DNS 搜索域\n    可以是一个值，也可以是一个列表\n    dns_search: example.com\n</code></pre>dns_search:</li>\n<li>domain1.example.com</li>\n<li>domain2.example.com<pre><code>devices\nsecurity_opt\nworking_dir, entrypoint, user, hostname, domainname, \n</code></pre>mac_address, mem_limit, memswap_limit, privileged,<br>restart, stdin_open, tty, cpu_shares, cpuset,<br>read_only, volume_driver<pre><code>这些都是和 docker run 支持的选项类似\ncpu_shares: 73\n</code></pre></li>\n</ul>\n<p>working_dir: /code<br>entrypoint: /code/entrypoint.sh<br>user: postgresql</p>\n<p>hostname: foo<br>domainname: foo.com</p>\n<p>mem_limit: 1000000000<br>privileged: true</p>\n<p>restart: always</p>\n<p>stdin_open: true<br>tty: true<br>        keyword<br>            build<br>                Path to a directory containing a Dockerfile.<br>                build: /path/to/build/dir<br>            cap_add, cap_drop<br>                Add or drop container capabilities. See man 7 capabilities for a full list.<br>                cap_add:</p>\n<ul>\n<li>ALL</li>\n</ul>\n<p>cap_drop:</p>\n<ul>\n<li>NET_ADMIN</li>\n<li>SYS_ADMIN<pre><code>command\n    Override the default command.\n    command: bundle exec thin -p 3000\ncgroup_parent\n    Specify an optional parent cgroup for the container.\n    cgroup_parent: m-executor-abcd\ncontainer_name\n    Specify a custom container name, rather than a generated default name.\n    container_name: my-web-container\ndevices\n    List of device mappings. Uses the same format as the --device docker client create option.\n    devices:\n</code></pre></li>\n<li>“/dev/ttyUSB0:/dev/ttyUSB0”<pre><code>dns\n    Custom DNS servers. Can be a single value or a list.\n    dns: 8.8.8.8\n</code></pre>dns:</li>\n<li>8.8.8.8</li>\n<li>9.9.9.9<pre><code>dns_search\n    Custom DNS search domains. Can be a single value or a list.\n    dns_search: example.com\n</code></pre>dns_search:</li>\n<li>dc1.example.com</li>\n<li>dc2.example.com<pre><code>dockerfile\n    Alternate Dockerfile.\n</code></pre>Compose will use an alternate file to build with.<pre><code>    dockerfile: Dockerfile-alternate\nenv_file\n    Add environment variables from a file. Can be a single value or a list.\n</code></pre>If you have specified a Compose file with docker-compose -f FILE,<br>paths in env_file are relative to the directory that file is in.<br>Environment variables specified in environment override these values.<pre><code>env_file: .env\n</code></pre></li>\n</ul>\n<p>env_file:</p>\n<ul>\n<li>./common.env</li>\n<li>./apps/web.env</li>\n<li>/opt/secrets.env<pre><code>Compose expects each line in an env file to be in VAR=VAL format.\n</code></pre>Lines beginning with # (i.e. comments) are ignored, as are blank lines.</li>\n</ul>\n<h1 id=\"Set-Rails-Rack-environment\"><a href=\"#Set-Rails-Rack-environment\" class=\"headerlink\" title=\"Set Rails/Rack environment\"></a>Set Rails/Rack environment</h1><p>RACK_ENV=development<br>            environment<br>                Add environment variables. You can use either an array or a dictionary.<br>                Any boolean values; true, false, yes no, need to be enclosed in quotes<br> to ensure they are not converted to True or False by the YML parser.<br>                Environment variables with only a key are resolved to their values on the machine Compose is running on,<br>which can be helpful for secret or host-specific values.<br>                environment:<br>  RACK_ENV: development<br>  SHOW: ‘true’<br>  SESSION_SECRET:</p>\n<p>environment:</p>\n<ul>\n<li>RACK_ENV=development</li>\n<li>SHOW=true</li>\n<li>SESSION_SECRET<pre><code>expose\n    Expose ports without publishing them to the host machine - \n</code></pre>they’ll only be accessible to linked services. Only the internal port can be specified.<pre><code>expose:\n</code></pre><ul>\n<li>“3000”</li>\n<li>“8000”<pre><code>extends\n    Extend another service, in the current file or another, optionally overriding configuration.\n</code></pre>You can use extends on any service together with other configuration keys.<br>The extends value must be a dictionary defined with a required service and an optional file key.<pre><code>extends:\n</code></pre>file: common.yml<br>service: webapp<pre><code>external_links\n    Link to containers started outside this docker-compose.yml or even outside of Compose,\n</code></pre>especially for containers that provide shared or common services.<br>external_links follow semantics similar to links when specifying both the container name and the link alias (CONTAINER:ALIAS).<pre><code>external_links:\n</code></pre></li>\n<li>redis_1</li>\n<li>project_db_1:mysql</li>\n<li>project_db_1:postgresql<pre><code>extra_hosts\n    Add hostname mappings. Use the same values as the docker client --add-host parameter.\n    extra_hosts:\n</code></pre></li>\n<li>“somehost:162.242.195.82”</li>\n<li>“otherhost:50.31.209.229”<pre><code>An entry with the ip address and hostname will be created in /etc/hosts inside containers for this service, e.g:\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<p>162.242.195.82  somehost<br>50.31.209.229   otherhost<br>            image<br>                Tag or partial image ID. Can be local or remote -<br>Compose will attempt to pull if it doesn’t exist locally.<br>                image: ubuntu<br>image: orchardup/postgresql<br>image: a4bc65fd<br>            labels<br>                Add metadata to containers using Docker labels. You can use either an array or a dictionary.<br>It’s recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.<br>                labels:<br>  com.example.description: “Accounting webapp”<br>  com.example.department: “Finance”<br>  com.example.label-with-empty-value: “”</p>\n<p>labels:</p>\n<ul>\n<li>“com.example.description=Accounting webapp”</li>\n<li>“com.example.department=Finance”</li>\n<li>“com.example.label-with-empty-value”<pre><code>links\n    Link to containers in another service. \n</code></pre>Either specify both the service name and the link alias (SERVICE:ALIAS),<br>or just the service name (which will also be used for the alias).<pre><code>links:\n</code></pre><ul>\n<li>db</li>\n<li>db:database</li>\n<li>redis<pre><code>An entry with the alias’ name will be created in /etc/hosts \n</code></pre>inside containers for this service, e.g:</li>\n</ul>\n</li>\n</ul>\n<p>172.17.2.186  db<br>172.17.2.186  database<br>172.17.2.187  redis<br>            log_driver<br>                Specify a logging driver for the service’s containers, as with the –log-driver option for docker run<br>                The default value is json-file.<br>Note: Only the json-file driver makes the logs available directly from docker-compose up and docker-compose logs.<br>Using any other driver will not print any logs.<br>                log_driver: “json-file”<br>log_driver: “syslog”<br>log_driver: “none”<br>            log_opt<br>                Specify logging options with log_opt for the logging driver, as with the –log-opt option for docker run.<br>                log_driver: “syslog”<br>log_opt:<br>  syslog-address: “tcp://192.168.0.42:123”<br>            net<br>                Networking mode. Use the same values as the docker client –net parameter.<br>                net: “bridge”<br>net: “none”<br>net: “container:[name or id]”<br>net: “host”<br>            pid<br>                pid: “host”<br>                Sets the PID mode to the host PID mode.<br>This turns on sharing between container and the host oprating system the PID address space.<br> Containers launched with this flag will be able to access and manipulate other containers<br> in the bare-metal machine’s namespace and vise-versa.<br>            ports<br>                Expose ports. Either specify both ports (HOST:CONTAINER),<br>or just the container port (a random host port will be chosen).<br>                Note: When mapping ports in the HOST:CONTAINER format,<br>you may experience erroneous results when using a container port lower than 60,<br>because YAML will parse numbers in the format xx:yy as sexagesimal (base 60).<br>For this reason, we recommend always explicitly specifying your port mappings as strings.<br>                ports:</p>\n<ul>\n<li>“3000”</li>\n<li>“3000-3005”</li>\n<li>“8000:8000”</li>\n<li>“9090-9091:8080-8081”</li>\n<li>“49100:22”</li>\n<li>“127.0.0.1:8001:8001”</li>\n<li>“127.0.0.1:5000-5010:5000-5010”<pre><code>security_opt\n    Override the default labeling scheme for each container.\n    security_opt:\n</code></pre><ul>\n<li>label:user:USER</li>\n<li>label:role:ROLE<pre><code>ulimits\n    Override the default ulimits for a container. \n</code></pre>You can either specify a single limit as an integer or soft/hard limits as a mapping.<pre><code>ulimits:\n</code></pre>nproc: 65535<br>nofile:<br>soft: 20000<br>hard: 40000<pre><code>volumes, volume_driver\n    Mount paths as volumes, optionally specifying a path on the host machine \n</code></pre>(HOST:CONTAINER), or an access mode (HOST:CONTAINER:ro).<pre><code>volumes:\n</code></pre></li>\n</ul>\n</li>\n<li>/var/lib/mysql</li>\n<li>./cache:/tmp/cache</li>\n<li>~/configs:/etc/configs/:ro<pre><code>You can mount a relative path on the host, which will expand relative to the director\n</code></pre>y of the Compose configuration file being used. Relative paths should always begin with . or …<pre><code>If you use a volume name (instead of a volume path), you may also specify a volume_driver.\n</code></pre>volume_driver: mydriver<br>Note: No path expansion will be done if you have also specified a volume_driver.<pre><code>volumes_from\n    Mount all of the volumes from another service or container, \n</code></pre>optionally specifying read-only access(ro) or read-write(rw).<pre><code>volumes_from:\n</code></pre></li>\n<li>service_name</li>\n<li>container_name</li>\n<li>service_name:rw<pre><code>cpu_shares, cpuset, domainname, entrypoint, hostname, \n</code></pre>ipc, mac_address, mem_limit, memswap_limit, privileged,<br>read_only, restart, stdin_open, tty, user, working_dir<pre><code>Each of these is a single value, analogous to its docker run counterpart.\ncpu_shares: 73\n</code></pre>cpuset: 0,1</li>\n</ul>\n<p>entrypoint: /code/entrypoint.sh<br>user: postgresql<br>working_dir: /code</p>\n<p>domainname: foo.com<br>hostname: foo<br>ipc: host<br>mac_address: 02:42:ac:11:65:43</p>\n<p>mem_limit: 1000000000<br>memswap_limit: 2000000000<br>privileged: true</p>\n<p>restart: always</p>\n<p>read_only: true<br>stdin_open: true<br>tty: true</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cixu71iaz00028psvjqkcdzbl","category_id":"cixu71ibm00088psv9ewex0dx","_id":"cixu71ic9000j8psvexd9tsu2"},{"post_id":"cixu71ibd00058psv0hz63d7z","category_id":"cixu71ic2000f8psvk5xudhiy","_id":"cixu71ick000q8psv4c3np2mg"},{"post_id":"cixu71ic7000i8psv45godatp","category_id":"cixu71ib600038psv4kzvedkn","_id":"cixu71icp000v8psvtkltnwne"},{"post_id":"cixu71ibi00068psv6tox2e74","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixu71id1000y8psv2zwr88ym"},{"post_id":"cixu71ibk00078psv09s4xbk0","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixu71idc00158psvn9tkmc4o"},{"post_id":"cixu71ibr000b8psvb0hky11f","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixu71idl001c8psv0sovxxex"},{"post_id":"cixu71ibz000d8psv5tfhi7s7","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixu71idv001j8psvsp18jxzi"},{"post_id":"cixu71ic4000h8psvqk0q5mhf","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixu71ie7001q8psvhhexghgc"},{"post_id":"cixu71icc000n8psv2q3iscr5","category_id":"cixu71idw001m8psvaiee8fy2","_id":"cixu71iei001y8psvj762h1nh"},{"post_id":"cixu71ief001w8psvaldctusq","category_id":"cixu71ib600038psv4kzvedkn","_id":"cixu71iep00248psv5nc9wjwl"},{"post_id":"cixu71ich000p8psvd8e5qz1q","category_id":"cixu71iee001u8psvycbwyw7g","_id":"cixu71ies00298psvlotiphee"},{"post_id":"cixu71iej001z8psv9qad9c5w","category_id":"cixu71ib600038psv4kzvedkn","_id":"cixu71ieu002b8psve5x04ybe"},{"post_id":"cixu71ien00238psvut5ll6i9","category_id":"cixu71ib600038psv4kzvedkn","_id":"cixu71ieu002f8psvbwz0w0mo"},{"post_id":"cixu71icn000u8psvxkbp9b39","category_id":"cixu71iee001u8psvycbwyw7g","_id":"cixu71iev002h8psv3k6rfj9c"},{"post_id":"cixu71icr000x8psvufdlpp8x","category_id":"cixu71ier00278psv4j2mqwcx","_id":"cixu71iev002j8psv82qzyuqv"},{"post_id":"cixu71id400128psvtav99pn4","category_id":"cixu71ieu002d8psvjxy37efe","_id":"cixu71iex002o8psvfqjq0nyp"},{"post_id":"cixu71id800148psv7uso7ijc","category_id":"cixu71iev002l8psvmrg53eso","_id":"cixu71iey002u8psvo10qeaaa"},{"post_id":"cixu71idf00198psvjzp1fhec","category_id":"cixu71iex002q8psvcrj8y1q8","_id":"cixu71iez002x8psv24wy1wnx"},{"post_id":"cixu71idj001b8psvqbja36ft","category_id":"cixu71iey002v8psvukwktcam","_id":"cixu71if000308psvaf76tvwp"},{"post_id":"cixu71ido001g8psvh4qib2wo","category_id":"cixu71iez002z8psvfyjo76s8","_id":"cixu71if300358psvg4usrmm0"},{"post_id":"cixu71ids001i8psvzo7y61cd","category_id":"cixu71iez002z8psvfyjo76s8","_id":"cixu71if700398psvajddwa2j"},{"post_id":"cixu71idx001n8psvc5kda3ef","category_id":"cixu71if300368psv2wrxrx3d","_id":"cixu71if9003d8psv05f5hzvh"},{"post_id":"cixu71ie4001p8psvhy2j8r8f","category_id":"cixu71if300368psv2wrxrx3d","_id":"cixu71ifm003f8psvkli4ur2h"},{"post_id":"cixu71ie9001t8psvbs69z8j7","category_id":"cixu71if300368psv2wrxrx3d","_id":"cixu71ifn003h8psvwvy7zrtr"},{"post_id":"cixu71iep00268psv4bq2iftu","category_id":"cixu71ifm003g8psvp6i39xg1","_id":"cixu71ifn003i8psvcpvob3sn"},{"post_id":"cixvpwb530008y9svnulrqaze","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixvpwb55000ay9sv5a0srgio"},{"post_id":"cixvpwgnz000by9svilna5rsc","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixvpwgo2000dy9svx265rfuu"},{"post_id":"cixvqn1fx0003vfs64p89e0dn","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixvqn1g00005vfs6595yqflr"},{"post_id":"cixu71iaq00008psvcb7p2zeh","category_id":"cixvoynmb0000yasvpuq08a3r","_id":"cixvqphlv00010js6zlb2roqr"},{"post_id":"cixvqvsvz00033as65wwvx2kk","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixvqvsw000053as6izdz9gic"},{"post_id":"cixvrxaob0003eys6peooymvm","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixvrxaoe0005eys6go9sw816"},{"post_id":"cixvrxxxh0009eys6nx9yz5i7","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixvrxxxk000beys6r70f0kd4"},{"post_id":"cixvryeqr000feys6gy5sh8t5","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixvryeqv000heys6towtqfvm"},{"post_id":"cixvsa4yr0003nus6iizqdhj1","category_id":"cixu71icb000l8psvs6a0nvft","_id":"cixvsa4yt0005nus67m4vpvnp"}],"PostTag":[{"post_id":"cixu71iaz00028psvjqkcdzbl","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71ic3000g8psvsuintg7n"},{"post_id":"cixu71ic4000h8psvqk0q5mhf","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71icc000m8psvr6rtrsn0"},{"post_id":"cixu71ibd00058psv0hz63d7z","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71ich000o8psvojgbqwm2"},{"post_id":"cixu71ic7000i8psv45godatp","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71icm000s8psvgs1388q2"},{"post_id":"cixu71ibi00068psv6tox2e74","tag_id":"cixu71ic9000k8psvfhs1vg6b","_id":"cixu71icq000w8psvjq6j5awb"},{"post_id":"cixu71icn000u8psvxkbp9b39","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71id200108psv4xi4crmn"},{"post_id":"cixu71ibk00078psv09s4xbk0","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71id800138psv9veg6lik"},{"post_id":"cixu71icr000x8psvufdlpp8x","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71idd00178psvtezxzflr"},{"post_id":"cixu71id400128psvtav99pn4","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71idi001a8psvkkkfnsq6"},{"post_id":"cixu71ibr000b8psvb0hky11f","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71idm001e8psveg8fqjn8"},{"post_id":"cixu71id800148psv7uso7ijc","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71idr001h8psvhtn5hwjg"},{"post_id":"cixu71idf00198psvjzp1fhec","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71idv001l8psvvoxdlo4n"},{"post_id":"cixu71ibz000d8psv5tfhi7s7","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71ie3001o8psvmgk8qrsl"},{"post_id":"cixu71idj001b8psvqbja36ft","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71ie7001r8psv36wejshf"},{"post_id":"cixu71ids001i8psvzo7y61cd","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71iee001v8psvgcdpsihb"},{"post_id":"cixu71ich000p8psvd8e5qz1q","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71ieh001x8psvmtchmb0o"},{"post_id":"cixu71ich000p8psvd8e5qz1q","tag_id":"cixu71idv001k8psvuroq8132","_id":"cixu71iem00228psv4kaektmy"},{"post_id":"cixu71ie9001t8psvbs69z8j7","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71iep00258psveyakwle0"},{"post_id":"cixu71ido001g8psvh4qib2wo","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71ies002a8psvsmw8zn5g"},{"post_id":"cixu71ido001g8psvh4qib2wo","tag_id":"cixu71ie8001s8psvwhke25fr","_id":"cixu71ieu002c8psvtua7fr6a"},{"post_id":"cixu71ien00238psvut5ll6i9","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixu71iev002g8psvi0e4gzjz"},{"post_id":"cixu71idx001n8psvc5kda3ef","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71iev002i8psvb1k5rwe6"},{"post_id":"cixu71idx001n8psvc5kda3ef","tag_id":"cixu71iel00208psvrqszcq4a","_id":"cixu71iev002k8psvw7ioez2r"},{"post_id":"cixu71ie4001p8psvhy2j8r8f","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71iew002n8psv6x9hsxsl"},{"post_id":"cixu71ie4001p8psvhy2j8r8f","tag_id":"cixu71ies00288psvmz253srj","_id":"cixu71iex002p8psvaaa59ya5"},{"post_id":"cixu71ief001w8psvaldctusq","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71iex002s8psvxwipytqu"},{"post_id":"cixu71ief001w8psvaldctusq","tag_id":"cixu71ieu002e8psvij2f9nru","_id":"cixu71iey002t8psvc3sgzvqx"},{"post_id":"cixu71iej001z8psv9qad9c5w","tag_id":"cixu71iev002m8psvda7uvoyz","_id":"cixu71if200338psv2du48bkr"},{"post_id":"cixu71iej001z8psv9qad9c5w","tag_id":"cixu71iex002r8psvc2nyb4nl","_id":"cixu71if300348psvh3gg80ms"},{"post_id":"cixu71iej001z8psv9qad9c5w","tag_id":"cixu71ieu002e8psvij2f9nru","_id":"cixu71if400378psvshggcny8"},{"post_id":"cixu71iej001z8psv9qad9c5w","tag_id":"cixu71iez002y8psv7vscxfli","_id":"cixu71if700388psvaho59exu"},{"post_id":"cixu71iep00268psv4bq2iftu","tag_id":"cixu71icl000r8psv5fypbd6n","_id":"cixu71if8003b8psv95u9q5g1"},{"post_id":"cixu71iep00268psv4bq2iftu","tag_id":"cixu71if000318psv1egd1rtb","_id":"cixu71if8003c8psv8nzufgfd"},{"post_id":"cixvpwb530008y9svnulrqaze","tag_id":"cixvpw1h60006y9svtvb9snnd","_id":"cixvpwb550009y9svdvjkmoxi"},{"post_id":"cixvpwgnz000by9svilna5rsc","tag_id":"cixvpw1h60006y9svtvb9snnd","_id":"cixvpwy3d000ey9svvwd929bm"},{"post_id":"cixvqn1fx0003vfs64p89e0dn","tag_id":"cixvpw1h60006y9svtvb9snnd","_id":"cixvqn1g00004vfs6v9sdwptm"},{"post_id":"cixu71iaq00008psvcb7p2zeh","tag_id":"cixu71ibb00048psvdbny1pqz","_id":"cixvqphlu00000js6um0wnl6p"},{"post_id":"cixu71iaq00008psvcb7p2zeh","tag_id":"cixvqpw2w00030js6sga3v6ko","_id":"cixvqpw2x00040js6g7q4u3uh"},{"post_id":"cixvqvsvz00033as65wwvx2kk","tag_id":"cixvpw1h60006y9svtvb9snnd","_id":"cixvqvsw000043as64keaai52"},{"post_id":"cixvrxaob0003eys6peooymvm","tag_id":"cixvpw1h60006y9svtvb9snnd","_id":"cixvrxaoe0004eys6t0pi39wh"},{"post_id":"cixvrxxxh0009eys6nx9yz5i7","tag_id":"cixvpw1h60006y9svtvb9snnd","_id":"cixvrxxxj000aeys6ofuhgb8r"},{"post_id":"cixvryeqr000feys6gy5sh8t5","tag_id":"cixvpw1h60006y9svtvb9snnd","_id":"cixvryequ000geys6uf7jlr3w"},{"post_id":"cixvsa4yr0003nus6iizqdhj1","tag_id":"cixvpw1h60006y9svtvb9snnd","_id":"cixvsa4yt0004nus6seax80yv"}],"Tag":[{"name":"portal","_id":"cixu71ibb00048psvdbny1pqz"},{"name":"cookbook","_id":"cixu71ic9000k8psvfhs1vg6b"},{"name":"core","_id":"cixu71icl000r8psv5fypbd6n"},{"name":"openstack","_id":"cixu71idv001k8psvuroq8132"},{"name":"http","_id":"cixu71ie8001s8psvwhke25fr"},{"name":"cloudfoundry","_id":"cixu71iel00208psvrqszcq4a"},{"name":"openshift","_id":"cixu71ies00288psvmz253srj"},{"name":"django","_id":"cixu71ieu002e8psvij2f9nru"},{"name":"install","_id":"cixu71iev002m8psvda7uvoyz"},{"name":"python","_id":"cixu71iex002r8psvc2nyb4nl"},{"name":"docker","_id":"cixu71iez002y8psv7vscxfli"},{"name":"rails","_id":"cixu71if000318psv1egd1rtb"},{"name":"detail","_id":"cixvpw1h60006y9svtvb9snnd"},{"name":"portal;","_id":"cixvqp1gc0001zhs6f2d0gu5b"},{"name":"architect","_id":"cixvqpw2w00030js6sga3v6ko"}]}}