{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/images/banner-bak.jpg","path":"css/images/banner-bak.jpg","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"b48c4f7d61a5928be717d4bd654481ff1eab36ee","modified":1484147075000},{"_id":"themes/landscape/.DS_Store","hash":"9457f542cf2c3f2a50b9ecd64858fc6f50b0d0c4","modified":1484147080000},{"_id":"themes/landscape/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1484126821000},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1484126821000},{"_id":"themes/landscape/README.md","hash":"c7e83cfe8f2c724fc9cac32bd71bb5faf9ceeddb","modified":1484126821000},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1484126821000},{"_id":"themes/landscape/_config.yml","hash":"285fb948f9f50e0d2c040283251b1ce20119bfaa","modified":1484214819000},{"_id":"themes/landscape/package.json","hash":"85358dc34311c6662e841584e206a4679183943f","modified":1484126821000},{"_id":"source/about/index.md","hash":"bfee1378ee8b0c03381c10c44157efb661c62430","modified":1484214601000},{"_id":"source/_posts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1484211471000},{"_id":"source/_posts/bigdata--portal.md","hash":"d96e2c479c7fbfd6d38bea35f6f323d2014b38af","modified":1484152554000},{"_id":"source/_posts/bigdata-hadoop-portal.md","hash":"d96e2c479c7fbfd6d38bea35f6f323d2014b38af","modified":1484152554000},{"_id":"source/_posts/cloud--portal.md","hash":"ea990afde799dc9c6bf60015bf9668abd9c4d7d0","modified":1486108444000},{"_id":"source/_posts/bigdata-ml-portal.md","hash":"d96e2c479c7fbfd6d38bea35f6f323d2014b38af","modified":1484152554000},{"_id":"source/_posts/bigdata-storm-portal.md","hash":"d96e2c479c7fbfd6d38bea35f6f323d2014b38af","modified":1484152554000},{"_id":"source/_posts/cloud-paas-cf-core.md","hash":"a77e50fa1b3f67ada1bc5323779e6b3cd98b6cb7","modified":1484152524000},{"_id":"source/_posts/cloud-iaas-portal.md","hash":"5e405ec4afebf9d4a0beda52d73247535c65f739","modified":1484152398000},{"_id":"source/_posts/cloud-paas-openshift-core.md","hash":"db53a3ce03df639c195d89c45d70b0f0466d1020","modified":1484152520000},{"_id":"source/_posts/cloud-iaas-openstack-core.md","hash":"a4dfe305ed994558c7b4fc58de795922c7799462","modified":1484152388000},{"_id":"source/_posts/cloud-paas-portal.md","hash":"1a96b1ddfa2eb02998c00983879ee03adbe053f2","modified":1484152535000},{"_id":"source/_posts/cmd_django_docker.txt","hash":"278e19844de45ed90b64d49059539be018bb3fd4","modified":1484211486000},{"_id":"source/_posts/db--portal.md","hash":"200e3ea7381f233610ee05a7da0e829f44bd93d3","modified":1484152415000},{"_id":"source/_posts/db-mysql-portal.md","hash":"200e3ea7381f233610ee05a7da0e829f44bd93d3","modified":1484152415000},{"_id":"source/_posts/db-nosql-portal.md","hash":"200e3ea7381f233610ee05a7da0e829f44bd93d3","modified":1484152415000},{"_id":"source/_posts/cloud-saas-portal.md","hash":"1a96b1ddfa2eb02998c00983879ee03adbe053f2","modified":1484152535000},{"_id":"source/_posts/docker-cloud-detail.md","hash":"08f6e57862e8033af8373ef1ac51da8ffdd9faa6","modified":1484152346000},{"_id":"source/_posts/docker--portal.md","hash":"1636ea5ee9554eac1f5788794bab4e8899cd187d","modified":1484151372000},{"_id":"source/_posts/docker-compose-detail.md","hash":"3cd42fbe54ac2559af4af31dbacd44869aff9bfc","modified":1484723964000},{"_id":"source/_posts/docker-compose-file-detail.md","hash":"49be9993b1a9bbd740383c33e968a9daad204f70","modified":1484724794000},{"_id":"source/_posts/docker-compose-file-tmp.md","hash":"2bc28e5d777a9ce91daa76e3b563195d2a48da54","modified":1484724228000},{"_id":"source/_posts/docker-core.md","hash":"371801da82979044f60999285279fc46cc8c8b12","modified":1484461693000},{"_id":"source/_posts/docker-cookbook.md","hash":"8caa9454e90d4ade8268c325399b17a29c48c945","modified":1484304719000},{"_id":"source/_posts/devops--portal.md","hash":"e51f3a902a32e2295d38850467b740fe76786f1e","modified":1484144776000},{"_id":"source/_posts/docker-dockerfile-detail.md","hash":"a0e7e5e21c02381a9cd232349eed7eca7a492eaf","modified":1484308001000},{"_id":"source/_posts/docker-dockerhub-detail.md","hash":"d73c876795bd2175c53d186b816dd2585f00a254","modified":1484307994000},{"_id":"source/_posts/docker-engine-detail.md","hash":"b27a664d2c97671de05b37ee1667bde0487bd05f","modified":1484310053000},{"_id":"source/_posts/docker-filesystem-core.md","hash":"f57c094ccfa1ff199415a9bdc571f65fc25651e1","modified":1484465420000},{"_id":"source/_posts/docker-image-detail.md","hash":"21421ab56a9a54fe66765d998db6df3dab394563","modified":1484308232000},{"_id":"source/_posts/docker-k8s-core.md","hash":"c932617dd05b171229eb0cbad913f31974775902","modified":1484152331000},{"_id":"source/_posts/docker-machine-detail.md","hash":"1761bafb16454ec9b0b9035b9186ca436cc64cf4","modified":1484718613000},{"_id":"source/_posts/docker-mesos-core.md","hash":"08f6e57862e8033af8373ef1ac51da8ffdd9faa6","modified":1484152346000},{"_id":"source/_posts/docker-security-core.md","hash":"e132f49ec05126a1762374f7a7ad5909610680cb","modified":1484457984000},{"_id":"source/_posts/docker-network-core.md","hash":"4adbd26909d01e284da4302cfbe98dc794398caf","modified":1484457933000},{"_id":"source/_posts/docker-storage-core.md","hash":"aba71f3dda6a43005db308862b385778f0b7ddc3","modified":1484461617000},{"_id":"source/_posts/docker-swarm-portal.md","hash":"ce36aba7fb4f271d68ada5f3628f82fbe6fef12d","modified":1484466953000},{"_id":"source/_posts/docker-store-detail.md","hash":"08f6e57862e8033af8373ef1ac51da8ffdd9faa6","modified":1484152346000},{"_id":"source/_posts/docker-swarm-detail.md","hash":"d1ce7533dcdadbed6620c865f7193a22100c792f","modified":1484465445000},{"_id":"source/_posts/docker-swarmkit-detail.md","hash":"ecbe772c349efe2ac43cac2e81357eeabc7d99ed","modified":1484467444000},{"_id":"source/_posts/docker-yaml-detail.md","hash":"5ce41c15cd0ca11e8a6a621bc0c1a60e16c119fe","modified":1484458296000},{"_id":"source/_posts/hello-world.md","hash":"2821cef1e0b6723d18e7f2162653fe696c4dbdc0","modified":1484152366000},{"_id":"source/_posts/docker-swarmnext-detail.md","hash":"859394563adc3ede668fa8e47d0c826e4b249199","modified":1484486949000},{"_id":"source/_posts/iot-portal.md","hash":"a4dfe305ed994558c7b4fc58de795922c7799462","modified":1484152388000},{"_id":"source/_posts/jd-architect-portal.md","hash":"6932aaea71078034615157134e80029d70c28bcd","modified":1484308101000},{"_id":"source/_posts/jd-fullstack-portal.md","hash":"d96e2c479c7fbfd6d38bea35f6f323d2014b38af","modified":1484152554000},{"_id":"source/_posts/jd--portal.md","hash":"6932aaea71078034615157134e80029d70c28bcd","modified":1484308101000},{"_id":"source/_posts/lang--portal.md","hash":"2cd25c7e83b0f07406bfa8dfc5ea285c1e1936ce","modified":1484152314000},{"_id":"source/_posts/lang-cx-portal.md","hash":"2cd25c7e83b0f07406bfa8dfc5ea285c1e1936ce","modified":1484152314000},{"_id":"source/_posts/lang-java-portal.md","hash":"200e3ea7381f233610ee05a7da0e829f44bd93d3","modified":1484152415000},{"_id":"source/_posts/lang-js-nodejs-core.md","hash":"c3d8104fd5c3ba26bd0215b83a6f169248a6921c","modified":1484152422000},{"_id":"source/_posts/lang-js-portal.md","hash":"c99c24b65ab554ef3d4bb3a145ed011f17f5e369","modified":1484152428000},{"_id":"source/_posts/lang-python-django-core.md","hash":"b58bfdbcca877f4c3041e6e25fa36b7f2be82140","modified":1484214459000},{"_id":"source/_posts/lang-python-django-install.md","hash":"7f922a7b5eb9ee80cb5cd6884eb3d87f81a0d595","modified":1484214542000},{"_id":"source/_posts/lang-python-portal.md","hash":"0f1a90cb1de64442035b364589c1ffa2fd49ef4e","modified":1484214141000},{"_id":"source/_posts/lang-ruby-rails-core.md","hash":"37bf54a843a2fb191bdc49ca6c2c504750db7df7","modified":1484152581000},{"_id":"source/_posts/microservice-portal.md","hash":"5ed1f32afcdff48260522df9c824d06dd89fe368","modified":1484458179000},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1484126821000},{"_id":"source/_posts/network-http-core.md","hash":"a5853d8ae8a690d707ee6e5e669ea3470c492940","modified":1484152471000},{"_id":"source/_posts/network-portal.md","hash":"1d97325d88b500484030a30cafd44c41b51c358c","modified":1484486959000},{"_id":"source/_posts/system-linux-portal.md","hash":"4e023a556e18a248bb932ff4067513be2779b1c0","modified":1484152446000},{"_id":"themes/landscape/source/.DS_Store","hash":"1429b9c08aeb8c15b3499d150e011720f8ff275c","modified":1484147087000},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1484126821000},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1484126821000},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1484126821000},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1484126821000},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1484126821000},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1484126821000},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1484126821000},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1484126821000},{"_id":"themes/landscape/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1484126821000},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1484126821000},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1484126821000},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1484126821000},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1484126821000},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1484126821000},{"_id":"themes/landscape/source/css/_variables.styl","hash":"06e2f44b92c26c5d71abf01e7b43ee0dfd2010c7","modified":1484148828000},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1484126821000},{"_id":"themes/landscape/source/css/.DS_Store","hash":"0c4a669591bf1723e84d44bb15e7b684e25ff531","modified":1484146229000},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"9292c640bdf7c8eb6fed2e8a1800f1cc7f43722b","modified":1484145585000},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"3ff1260ab513c523a610f1d83b20961b5d140d6b","modified":1484213973000},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"931aaaffa0910a48199388ede576184ff15793ee","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"f6975a227829834c026b17ee2493d06a16202b94","modified":1484144946000},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"bfd64f2a831a6acb7f5bae852cae3098a91e1997","modified":1484145371000},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"9d7b18ae2a5479d9ae0eb053ea7043ab8a9bd642","modified":1484145235000},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1484126821000},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1484126821000},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1484126821000},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"e2c9ff91ca7c221c23e41dba0d4b8dfd90d28a6c","modified":1484146333000},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1484126821000},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"9658cb416b434dc6c3a8c2c15511eb170f363a3d","modified":1484148524000},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1484126821000},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1484213953000},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1484126821000},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1484126821000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1484126821000},{"_id":"themes/landscape/source/css/images/banner-bak.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1484126821000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1484126821000},{"_id":"public/about/index.html","hash":"039b767acebece2e4a03fbaf922ecb1836459a83","modified":1486131988514},{"_id":"public/python/lang-python-django-install/index.html","hash":"336b7301a719f85bec5694c9401b3c9e8f806f17","modified":1486131988514},{"_id":"public/docker/docker-machine-detail/index.html","hash":"2b490e1171b215de4d90d3edeee19c44101b8418","modified":1486131988514},{"_id":"public/python/bigdata-ml-portal/index.html","hash":"cdae9965c33b72ad42436868e6ec87d7700b98f4","modified":1486131988514},{"_id":"public/python/bigdata-storm-portal/index.html","hash":"42def3d74f9f4c089c063710314e43695dc7148a","modified":1486131988514},{"_id":"public/paas/cloud-paas-cf-core/index.html","hash":"bbcf8abc106598e84e758ba01dfcc3d76273801b","modified":1486131988514},{"_id":"public/paas/cloud-paas-openshift-core/index.html","hash":"e4500823ec81b31d794d88e874ed8ff034b70473","modified":1486131988514},{"_id":"public/iaas/cloud-iaas-portal/index.html","hash":"4131e035532470b71e2ca1313aa196bbf7e1c14d","modified":1486131988515},{"_id":"public/iaas/cloud-iaas-openstack-core/index.html","hash":"dc345b77cf5045a5df8a2e02981b549c1924bae8","modified":1486131988515},{"_id":"public/paas/cloud-paas-portal/index.html","hash":"575ce95c7726d4d74de9d217b6bf2630ab13cd8b","modified":1486131988515},{"_id":"public/java/db--portal/index.html","hash":"ccf270dc1190ff42405403d777b6987f48f3f22e","modified":1486131988515},{"_id":"public/java/db-mysql-portal/index.html","hash":"bec0c6982f80c662685da149815c8a15e7a72d95","modified":1486131988515},{"_id":"public/java/db-nosql-portal/index.html","hash":"b2d3ecfe7e96ba1ff59c991d6ce69ab6dad369bb","modified":1486131988515},{"_id":"public/docker/docker-cloud-detail/index.html","hash":"93ac00df1a2c71e39d8ead7e1fe3e7a6e766d46e","modified":1486131988515},{"_id":"public/paas/cloud-saas-portal/index.html","hash":"a0130257cc01037b155b0776c2e40c2da6bd5e57","modified":1486131988515},{"_id":"public/docker/docker-compose-detail/index.html","hash":"052cd60726cbdac0657808cfadb8a4d77f5bb63d","modified":1486131988515},{"_id":"public/docker/docker-compose-file-detail/index.html","hash":"032f838e9ce43903dd0d5ac145f93ed11206aa4f","modified":1486131988515},{"_id":"public/python/bigdata--portal/index.html","hash":"408421e7a8b92955e9d45804c39a427a72816f71","modified":1486131988515},{"_id":"public/docker/docker-core/index.html","hash":"4094848bf94fedb4f1d64d185fa3b8680d59b561","modified":1486131988515},{"_id":"public/docker/docker-cookbook/index.html","hash":"aef832a765c6934f1b8c1146d7d55ccb21f876e3","modified":1486131988515},{"_id":"public/devops/devops--portal/index.html","hash":"79155385077b759e09209aae991682afe959b077","modified":1486131988515},{"_id":"public/docker/docker-dockerfile-detail/index.html","hash":"effd56245564255d7f6c00fe244460e2e2757516","modified":1486131988515},{"_id":"public/docker/docker-dockerhub-detail/index.html","hash":"a9559100e8fef720d87e1a8c9941c50143b32842","modified":1486131988515},{"_id":"public/docker/docker-engine-detail/index.html","hash":"5fed36fb192f8e45b0de17d1d80e4ba73976f8e0","modified":1486131988515},{"_id":"public/docker/docker-filesystem-core/index.html","hash":"9c7d707f84c4028f40e1aedd8959d26c1dddd559","modified":1486131988516},{"_id":"public/docker/docker-image-detail/index.html","hash":"416d6b98492c89669d930b4c608501303ad01d7f","modified":1486131988516},{"_id":"public/docker/docker-k8s-core/index.html","hash":"2199a14c910e0c5c2414554f5bf84547bdec320b","modified":1486131988516},{"_id":"public/python/bigdata-hadoop-portal/index.html","hash":"4470ccdd1f3201a97814f7ca3fdce9bb1e95d964","modified":1486131988516},{"_id":"public/docker/docker-mesos-core/index.html","hash":"fdceea7efe3e57ba91b2f8757aeb89e9e3cdfc68","modified":1486131988516},{"_id":"public/docker/docker-security-core/index.html","hash":"a90e96b29f1e77290c9523e4d83830864a97974d","modified":1486131988516},{"_id":"public/docker/docker-network-core/index.html","hash":"c3aaa0580b399cfb3ccfe9747e3a4e9f5662b1c1","modified":1486131988516},{"_id":"public/docker/docker-storage-core/index.html","hash":"eff4a62ce2deb7486b636f2edb94f36834009b4c","modified":1486131988516},{"_id":"public/docker/docker-swarm-portal/index.html","hash":"e4d9ee7c62bb1c3da8afc53599a66650f5338afa","modified":1486131988516},{"_id":"public/docker/docker-store-detail/index.html","hash":"bd47404074b3a183eae620c412b54f0cebc4c56b","modified":1486131988516},{"_id":"public/docker/docker-swarm-detail/index.html","hash":"e970a12557e7450a39cc280084a40c2b11ecc5e1","modified":1486131988516},{"_id":"public/iaas/docker-swarmkit-detail/index.html","hash":"06bd10e0840018652e27993ea281360a817c583d","modified":1486131988516},{"_id":"public/docker/docker-yaml-detail/index.html","hash":"c7a311a2ad99feeec188cda72b30e2fdc058385f","modified":1486131988516},{"_id":"public/network/network-portal/index.html","hash":"e62ec98985e7aba79b9bffc89ea0990805182f58","modified":1486131988516},{"_id":"public/docker/docker-swarmnext-detail/index.html","hash":"78301a8e601f4d8691c4c94385f23a8b2da7eb3a","modified":1486131988516},{"_id":"public/iaas/iot-portal/index.html","hash":"5023667f8c1aff882429b01694f4dc734760dc2a","modified":1486131988516},{"_id":"public/cloud/jd-architect-portal/index.html","hash":"f0e78c279769de47617306e0d25ba96611768377","modified":1486131988516},{"_id":"public/python/jd-fullstack-portal/index.html","hash":"6f2fb73efb038e778c1ec03dcc30cfa73175a538","modified":1486131988517},{"_id":"public/cloud/jd--portal/index.html","hash":"dddf22e274a4ca2551a9c905b37b428674904a0e","modified":1486131988517},{"_id":"public/cx/lang--portal/index.html","hash":"5c4773c98207352c4c08d227a28100f26dee625d","modified":1486131988517},{"_id":"public/cx/lang-cx-portal/index.html","hash":"3e23cf92681fc57377184331ebbd64e80c0103ee","modified":1486131988517},{"_id":"public/java/lang-java-portal/index.html","hash":"1287225d25b65415f0f810aa5971a653bc830069","modified":1486131988517},{"_id":"public/nodejs/lang-js-nodejs-core/index.html","hash":"2967e0716e860d65927c1a95d9fb36b10a0564da","modified":1486131988517},{"_id":"public/js/lang-js-portal/index.html","hash":"4e6b89631c51096f1d093792810f613fff1db028","modified":1486131988517},{"_id":"public/python/lang-python-django-core/index.html","hash":"9eefb46abcb19f0459fd1348eee8b3b405e28915","modified":1486131988517},{"_id":"public/python/cloud--portal/index.html","hash":"6783cc23816c99f2a379655dc7810624c2a12c65","modified":1486131988517},{"_id":"public/python/lang-python-portal/index.html","hash":"f851451e46d7653e9ba8a19d40698268f266ccd6","modified":1486131988517},{"_id":"public/microservice/microservice-portal/index.html","hash":"7494af9df8a0fc1b3c650f29bef7cc0ca94a18c8","modified":1486131988517},{"_id":"public/ruby/lang-ruby-rails-core/index.html","hash":"19244df81b9add9f81dc9120dd02d2db6d91142b","modified":1486131988517},{"_id":"public/network/network-http-core/index.html","hash":"33ba283c2a1407d9a26c1e7a785ceea1e25b1fa0","modified":1486131988517},{"_id":"public/linux/system-linux-portal/index.html","hash":"03af121cd58afc99f9ce3c3df0dca8b49ceb0330","modified":1486131988517},{"_id":"public/tmp/hello-world/index.html","hash":"9def59e437851a159fa2265bcdd26561fe494d00","modified":1486131988517},{"_id":"public/archives/index.html","hash":"cea3b8874d7313317c0e1c5becc14cd78bdfe475","modified":1486131988517},{"_id":"public/archives/page/2/index.html","hash":"fb641a965da590f258685e4fce416dd405536a29","modified":1486131988517},{"_id":"public/archives/page/3/index.html","hash":"684ae16adee0fbe24492617f4aa5787e1dab3b53","modified":1486131988517},{"_id":"public/archives/page/4/index.html","hash":"e132faa287d4aaaac3bc3c87ab97d57b4567781b","modified":1486131988517},{"_id":"public/archives/page/5/index.html","hash":"2b84b93e14ba9db3cd392ea69d06f2851eb0dec1","modified":1486131988517},{"_id":"public/archives/page/6/index.html","hash":"79ba92caff70e5e5851a58c0b887a66e3513ccc8","modified":1486131988517},{"_id":"public/archives/2017/index.html","hash":"4f87f112c65b577575a93650626c5b77def82e6c","modified":1486131988517},{"_id":"public/archives/2017/page/2/index.html","hash":"57ff6c534a634c4c335fd43b79246007144eab12","modified":1486131988517},{"_id":"public/archives/2017/page/3/index.html","hash":"3fa76c04a59454877e0e8e753e1bd5a9c94fcc10","modified":1486131988517},{"_id":"public/archives/2017/page/4/index.html","hash":"2f907b96d8d58d8e08c6ef886475deb5e26663d4","modified":1486131988518},{"_id":"public/archives/2017/page/5/index.html","hash":"d1637a562280cb54c30249b04414cd4ff8d7a7c0","modified":1486131988518},{"_id":"public/archives/2017/page/6/index.html","hash":"5dcdf7649ffd4126deabe46d9a9a32d584b30d5e","modified":1486131988519},{"_id":"public/archives/2017/01/index.html","hash":"66993604fa6ed0c14d4dd84bd18aa006c5aaf4c6","modified":1486131988519},{"_id":"public/archives/2017/01/page/2/index.html","hash":"afe49f654c468e33bcdfc1775a600eb6e2d74572","modified":1486131988519},{"_id":"public/archives/2017/01/page/3/index.html","hash":"a8546e0cff074d6591ecf0d70ab6cbe3ea3c7e8a","modified":1486131988519},{"_id":"public/archives/2017/01/page/4/index.html","hash":"04f48a9435c58c21d4a0f3158e6182e06149954d","modified":1486131988519},{"_id":"public/archives/2017/01/page/5/index.html","hash":"e06502bf63a749e1ef62a8bfe4b77396624a0589","modified":1486131988519},{"_id":"public/archives/2017/01/page/6/index.html","hash":"e83abe343129b0333a11c205f7dd09406ef76d29","modified":1486131988519},{"_id":"public/categories/python/index.html","hash":"b4cd3c8590e6835a3a234aeabddfbe193a8f196d","modified":1486131988519},{"_id":"public/categories/paas/index.html","hash":"bf77cb4b4fb4848860f54cc041b211a5367bb2a8","modified":1486131988519},{"_id":"public/categories/iaas/index.html","hash":"3bc9747344c04e0189c991ee501c3c9fd3f9b621","modified":1486131988519},{"_id":"public/categories/java/index.html","hash":"b3e4d232a92d899b4ba53620f21cd4286f693701","modified":1486131988519},{"_id":"public/categories/docker/index.html","hash":"59a12e71cae3679306f1f5bca1683c2f192068fc","modified":1486131988519},{"_id":"public/categories/docker/page/2/index.html","hash":"528ac54a207c617d2a2f4ad588e38bbab33ee9dd","modified":1486131988519},{"_id":"public/categories/docker/page/3/index.html","hash":"3044d31055ba232ac8e16e2bd9cb03b13f3035ef","modified":1486131988519},{"_id":"public/categories/devops/index.html","hash":"bd4968064ae18ab07269de806d163066438952ea","modified":1486131988519},{"_id":"public/categories/tmp/index.html","hash":"4943f8a19f1118cb96e3292a8e489cfb43998a7c","modified":1486131988519},{"_id":"public/categories/cloud/index.html","hash":"24e6c7607df8c7c50b94435463b9542950eab7f3","modified":1486131988519},{"_id":"public/categories/cx/index.html","hash":"cd7c1dd0a6ad20a03ce05e1ce82836470a2a041c","modified":1486131988519},{"_id":"public/categories/nodejs/index.html","hash":"e63be2c0fd0049c64afdfce800f54b9a673b601c","modified":1486131988519},{"_id":"public/categories/js/index.html","hash":"335ecb5eb4421fc0a1c23bdfab6328c7c1c78082","modified":1486131988519},{"_id":"public/categories/microservice/index.html","hash":"688abbb94199d15f0e84621d333d4556837cc33a","modified":1486131988519},{"_id":"public/categories/ruby/index.html","hash":"641df9b1706f95b365c47b37804261b3f000b341","modified":1486131988519},{"_id":"public/categories/network/index.html","hash":"127a7f808340cb46500c10830e201e6580750f68","modified":1486131988519},{"_id":"public/categories/linux/index.html","hash":"6a26ee3881ed9dc89063fecccf23b759493c6db4","modified":1486131988520},{"_id":"public/tags/portal/index.html","hash":"cabaa3a8f0db809c6342c94a6132ad783bd22309","modified":1486131988520},{"_id":"public/tags/portal/page/2/index.html","hash":"d62d7e850469597039925643e73cc91057f51dce","modified":1486131988520},{"_id":"public/tags/portal/page/3/index.html","hash":"72c696c807f14da23d53d3e52e5d4b318f4f63f0","modified":1486131988520},{"_id":"public/tags/core/index.html","hash":"ee6fab4e06c4a4d5380e6ff49fdfc66c31b77b3f","modified":1486131988520},{"_id":"public/tags/core/page/2/index.html","hash":"96f83807e926a3722d8abce30c857a3e0fee4030","modified":1486131988520},{"_id":"public/tags/cloudfoundry/index.html","hash":"c3df26dd46e71159680086c08965bdb65851a9b5","modified":1486131988520},{"_id":"public/tags/openshift/index.html","hash":"ef31a8253c2849934c98708e7d150f3942f70684","modified":1486131988520},{"_id":"public/tags/openstack/index.html","hash":"5aeefd9849308785ed2dc8a7fa3b86cf3d8a337f","modified":1486131988520},{"_id":"public/tags/detail/index.html","hash":"bebeb20da8c18599196cf3c42a1bd7a02b9aafec","modified":1486131988520},{"_id":"public/tags/cookbook/index.html","hash":"2e60cbabb7d124c4bf4616fe1270014f2f1ef8d0","modified":1486131988520},{"_id":"public/tags/filesystem/index.html","hash":"6175f8d96ed6d9a6515afc18e852367b22549d98","modified":1486131988521},{"_id":"public/tags/security/index.html","hash":"a05ec2f21a2ef67bf23a335bd253e79b3e3eceab","modified":1486131988521},{"_id":"public/tags/network/index.html","hash":"eb9423dbe6f94e13bbae2ecd0f41be22057fb5ba","modified":1486131988521},{"_id":"public/tags/storage/index.html","hash":"b20e96470590cbff9de9f95692b7cf650c153318","modified":1486131988521},{"_id":"public/tags/swarm/index.html","hash":"7979bcd11d0a8749dcc0a2576575ccddacc3e221","modified":1486131988521},{"_id":"public/tags/architect/index.html","hash":"596f60d4ef97f94d67d9c858dcedd7751f94746c","modified":1486131988521},{"_id":"public/tags/django/index.html","hash":"06e5e9ac5cb610944d950699488f08fef757bf07","modified":1486131988521},{"_id":"public/tags/install/index.html","hash":"3275ce22c058255356f318f243f1efe521e076eb","modified":1486131988522},{"_id":"public/tags/python/index.html","hash":"0dd3dd06c9ef73657a000651137451f465ce6214","modified":1486131988522},{"_id":"public/tags/docker/index.html","hash":"46a52d2d5a1a1525b6fb72636dfb5043fa7ff379","modified":1486131988522},{"_id":"public/tags/rails/index.html","hash":"7cdee3370f76b4c52477cb2edabb479f39729f3c","modified":1486131988522},{"_id":"public/tags/http/index.html","hash":"b46ad367b16fd221fd32b6448fe0e3faeb9bc124","modified":1486131988522},{"_id":"public/uncategorized/docker-compose-file-tmp/index.html","hash":"0f3c3ee8248962b513d82007c2ced1f97e3e9279","modified":1486131988522},{"_id":"public/docker/docker--portal/index.html","hash":"1663e515f61f10d5491d6e774f37d362a5d13fa3","modified":1486131988522},{"_id":"public/index.html","hash":"e9ac184685e0e52a40ea65e347324a6b85b5193a","modified":1486131988522},{"_id":"public/page/2/index.html","hash":"8e68d3d89bc73f85583d3c4788453e19c4911473","modified":1486131988522},{"_id":"public/page/3/index.html","hash":"6097a54100346ac097d9fd3c8dcb2fd2f496ebde","modified":1486131988522},{"_id":"public/page/4/index.html","hash":"676d6d9bc902f001ebcbc14080ff604f69523902","modified":1486131988522},{"_id":"public/page/5/index.html","hash":"6aaf7b7c925fdae5dbdbe667017137e020ece708","modified":1486131988522},{"_id":"public/page/6/index.html","hash":"b3187206a40aaf95f7b4976261d86f3f2f42d812","modified":1486131988522},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1486131988537},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1486131988537},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1486131988537},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1486131988537},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1486131988537},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1486131988537},{"_id":"public/css/images/banner.jpg","hash":"e2c9ff91ca7c221c23e41dba0d4b8dfd90d28a6c","modified":1486131988537},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1486131988537},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1486131988537},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1486131988537},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1486131988537},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1486131990461},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1486131990470},{"_id":"public/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1486131990470},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1486131990470},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1486131990470},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1486131990470},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1486131990470},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1486131990470},{"_id":"public/css/style.css","hash":"f1bdee26c06f8dca10fa0df089e978e0469d755a","modified":1486131990470},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1486131990470},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1486131990471},{"_id":"public/css/images/banner-bak.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1486131990480},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1486131990480}],"Category":[{"name":"python","_id":"ciypwm36s000321sv2ayq74mg"},{"name":"paas","_id":"ciypwm37q000n21sv6dlm59y0"},{"name":"iaas","_id":"ciypwm37x000v21svrncf6pj1"},{"name":"java","_id":"ciypwm38k001h21svxlgxac0o"},{"name":"docker","_id":"ciypwm396002421svh3qvjzup"},{"name":"devops","_id":"ciypwm3am003e21svty5ib55t"},{"name":"tmp","_id":"ciypwm3b3004121svtkx85z4d"},{"name":"cloud","_id":"ciypwm3b9004921svnu7nqm17"},{"name":"cx","_id":"ciypwm3bj004q21sve4wap485"},{"name":"nodejs","_id":"ciypwm3c0005621svwg9s5r8n"},{"name":"js","_id":"ciypwm3c6005e21sv23z2ug6y"},{"name":"microservice","_id":"ciypwm3cd005m21sva7pdlkq9"},{"name":"ruby","_id":"ciypwm3ce005u21sv403nox6t"},{"name":"network","_id":"ciypwm3cg006021svbgr4bjye"},{"name":"linux","_id":"ciypwm3ci006c21svajl2sgwk"}],"Data":[],"Page":[{"title":"about","date":"2017-01-12T17:49:37.000Z","_content":"\n123","source":"about/index.md","raw":"---\ntitle: about\ndate: 2017-01-12 17:49:37\n---\n\n123","updated":"2017-01-12T09:50:01.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"ciypwm35q000021sv7ev9hb2x","content":"<p>123</p>\n","excerpt":"","more":"<p>123</p>\n"}],"Post":[{"title":"python portal","_content":"\n# 123","source":"_posts/bigdata--portal.md","raw":"---\ntitle: python portal\ncategories:\n- python\ntags:\n- portal\n---\n\n# 123","slug":"bigdata--portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm36l000121sv4vi8ieps","content":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>","excerpt":"","more":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>"},{"title":"python portal","_content":"\n# 123","source":"_posts/bigdata-hadoop-portal.md","raw":"---\ntitle: python portal\ncategories:\n- python\ntags:\n- portal\n---\n\n# 123","slug":"bigdata-hadoop-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm36p000221svq1phbbk0","content":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>","excerpt":"","more":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>"},{"title":"cloud portal","_content":"\n# top resource\n\nIBM doc:\nhttp://www.ibm.com/analytics/cn/zh/\n\nOracle doc: http://docs.oracle.com/en/\nSAP doc: http://www.sap.com/developer.html\nSAP case: http://www.bestsapchina.com/ResourceCenter/i-t-s.html","source":"_posts/cloud--portal.md","raw":"---\ntitle: cloud portal\ncategories:\n- python\ntags:\n- portal\n---\n\n# top resource\n\nIBM doc:\nhttp://www.ibm.com/analytics/cn/zh/\n\nOracle doc: http://docs.oracle.com/en/\nSAP doc: http://www.sap.com/developer.html\nSAP case: http://www.bestsapchina.com/ResourceCenter/i-t-s.html","slug":"cloud--portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-02-03T07:54:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm36y000521svf4gipt4m","content":"<h1 id=\"top-resource\"><a href=\"#top-resource\" class=\"headerlink\" title=\"top resource\"></a>top resource</h1><p>IBM doc:<br><a href=\"http://www.ibm.com/analytics/cn/zh/\" target=\"_blank\" rel=\"external\">http://www.ibm.com/analytics/cn/zh/</a></p>\n<p>Oracle doc: <a href=\"http://docs.oracle.com/en/\" target=\"_blank\" rel=\"external\">http://docs.oracle.com/en/</a><br>SAP doc: <a href=\"http://www.sap.com/developer.html\" target=\"_blank\" rel=\"external\">http://www.sap.com/developer.html</a><br>SAP case: <a href=\"http://www.bestsapchina.com/ResourceCenter/i-t-s.html\" target=\"_blank\" rel=\"external\">http://www.bestsapchina.com/ResourceCenter/i-t-s.html</a></p>\n","excerpt":"","more":"<h1 id=\"top-resource\"><a href=\"#top-resource\" class=\"headerlink\" title=\"top resource\"></a>top resource</h1><p>IBM doc:<br><a href=\"http://www.ibm.com/analytics/cn/zh/\">http://www.ibm.com/analytics/cn/zh/</a></p>\n<p>Oracle doc: <a href=\"http://docs.oracle.com/en/\">http://docs.oracle.com/en/</a><br>SAP doc: <a href=\"http://www.sap.com/developer.html\">http://www.sap.com/developer.html</a><br>SAP case: <a href=\"http://www.bestsapchina.com/ResourceCenter/i-t-s.html\">http://www.bestsapchina.com/ResourceCenter/i-t-s.html</a></p>\n"},{"title":"python portal","_content":"\n# 123","source":"_posts/bigdata-ml-portal.md","raw":"---\ntitle: python portal\ncategories:\n- python\ntags:\n- portal\n---\n\n# 123","slug":"bigdata-ml-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm370000621sv5wqww7o5","content":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>","excerpt":"","more":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>"},{"title":"python portal","_content":"\n# 123","source":"_posts/bigdata-storm-portal.md","raw":"---\ntitle: python portal\ncategories:\n- python\ntags:\n- portal\n---\n\n# 123","slug":"bigdata-storm-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm373000721sve8sra0p8","content":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>","excerpt":"","more":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>"},{"title":"cloudfoundry core","_content":"\n# ","source":"_posts/cloud-paas-cf-core.md","raw":"---\ntitle: cloudfoundry core\ncategories:\n- paas\ntags:\n- core\n- cloudfoundry\n---\n\n# ","slug":"cloud-paas-cf-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm37b000b21svs9suqb35","content":"<p># </p>\n","excerpt":"","more":"<p># </p>\n"},{"title":"iaas core","_content":"\n# iaas core","source":"_posts/cloud-iaas-portal.md","raw":"---\ntitle: iaas core\ncategories:\n- iaas\ntags:\n- portal\n---\n\n# iaas core","slug":"cloud-iaas-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm37g000e21sv4w08jqwz","content":"<h1 id=\"iaas-core\"><a href=\"#iaas-core\" class=\"headerlink\" title=\"iaas core\"></a>iaas core</h1>","excerpt":"","more":"<h1 id=\"iaas-core\"><a href=\"#iaas-core\" class=\"headerlink\" title=\"iaas core\"></a>iaas core</h1>"},{"title":"openshift core","_content":"\n# ","source":"_posts/cloud-paas-openshift-core.md","raw":"---\ntitle: openshift core\ncategories:\n- paas\ntags:\n- core\n- openshift\n---\n\n# ","slug":"cloud-paas-openshift-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm37k000j21svx26uzv21","content":"<p># </p>\n","excerpt":"","more":"<p># </p>\n"},{"title":"openstack core","_content":"\n# core","source":"_posts/cloud-iaas-openstack-core.md","raw":"---\ntitle: openstack core\ncategories:\n- iaas\ntags:\n- core\n- openstack\n---\n\n# core","slug":"cloud-iaas-openstack-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm37n000m21svlowv6kfh","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"paas portal","_content":"\n","source":"_posts/cloud-paas-portal.md","raw":"---\ntitle: paas portal\ncategories:\n- paas\ntags:\n- portal\n---\n\n","slug":"cloud-paas-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm37s000r21svd81wuly4","content":"","excerpt":"","more":""},{"title":"java portal","_content":"\n#  portal","source":"_posts/db--portal.md","raw":"---\ntitle: java portal\ncategories:\n- java\ntags:\n- portal\n---\n\n#  portal","slug":"db--portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm37v000u21svtfny6hag","content":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>","excerpt":"","more":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>"},{"title":"java portal","_content":"\n#  portal","source":"_posts/db-mysql-portal.md","raw":"---\ntitle: java portal\ncategories:\n- java\ntags:\n- portal\n---\n\n#  portal","slug":"db-mysql-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm37z000y21sv7ku7mwqz","content":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>","excerpt":"","more":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>"},{"title":"java portal","_content":"\n#  portal","source":"_posts/db-nosql-portal.md","raw":"---\ntitle: java portal\ncategories:\n- java\ntags:\n- portal\n---\n\n#  portal","slug":"db-nosql-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm381001121svtap4yfqx","content":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>","excerpt":"","more":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>"},{"title":"mesos core","_content":"\n#  core","source":"_posts/docker-cloud-detail.md","raw":"---\ntitle: mesos core\ncategories:\n- docker\ntags:\n- core\n---\n\n#  core","slug":"docker-cloud-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:32:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm387001621sv0tyyvktn","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"paas portal","_content":"\n","source":"_posts/cloud-saas-portal.md","raw":"---\ntitle: paas portal\ncategories:\n- paas\ntags:\n- portal\n---\n\n","slug":"cloud-saas-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm38b001821svqerj6t12","content":"","excerpt":"","more":""},{"title":"docker portal","_content":"\n# resource\n\nofficial:\n[https://www.docker.com/](https://www.docker.com/)\n[https://blog.docker.com/](https://blog.docker.com/)\n[https://linuxcontainers.org/](https://linuxcontainers.org/)\n\nawesome:\n[https://github.com/Friz-zy/awesome-linux-containers](https://github.com/Friz-zy/awesome-linux-containers)\n\ngithub:\n[docker-library](https://github.com/docker-library)\n[dockerfile](https://github.com/tianon/dockerfiles)   \n[docker-cheat-sheet](https://github.com/wsargent/docker-cheat-sheet)\n[Chef Cookbook for Docker](https://github.com/chef-cookbooks/docker)\n\ncommunity:\n[dockerpool](http://dockerpool.com/)\n[dockerone](http://dockerone.com)\n[devops-china](http://devops-china.org)\n[ceph china](http://bbs.ceph.org.cn/)    \ncloud stack(http://www.cloudstack-china.org/)\natcontainer(http://atcontainer.com/)\ngoogle plus(https://plus.google.com/u/0/+DockerIo)\nzhihu(https://www.zhihu.com/topic/19950993)\nreddit\nstackoverflow(http://superuser.com/questions/tagged/docker)\n\norganization:\nopen container project: [link](http://www.opencontainers.org/), [doc](http://blog.docker.com/2015/06/open-container-project-foundation/)\noci:[](https://www.opencontainers.org/), [](https://github.com/opencontainers)\nabout:DockerrktDockerGoogleIntelRedhatMicrosoftEMCIBMAmazonVMwareOraclePivotalRancherHPEFacebookTwitterIT20156OCIOpen Container InitiativeOCIOCIOCIDocker\nCNCF: Cloud Native Computing Foundation\n\nconf\nQConf:http://2016.qconshanghai.com/, http://qconferences.com/\nDockerCon\n    link\n        http://www.slideshare.net/Docker/presentations\n        http://www.dockercon.com/\n    2015\n        guidebook app\n        http://europe-2015.dockercon.com/\n        http://dockerconeu2015.sched.org/\n    2016\n        http://2016.dockercon.com/\n        https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/\nContainerCon\nContainerCamp\nOperability 1.0\nGoTo Conference\nSoftware Circus\n\n    http://atcontainer.com/\n\n    http://www.bagevent.com/event/176371\n\ndocker vs x\n    docker vs virtual machine\n        link\n            http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#\n            http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution\n            http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker\n\nmooc\n    https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info\n    \nread:\n- infoq: [infoq cn](http://www.infoq.com/cn/dockers/), [infoq en](https://www.infoq.com/docker-2)\n- bot: [yidian](http://www.yidianzixun.com/home?page=channel&keyword=docker), [toutiao](http://toutiao.com/tag85482990/)\n- book\n    Docker Cookbook\n    Docker:publish,[opensource](http://dockerpool.com/static/books/docker_practice/index.html)\n    Docker\n    Docker lts        \n    [docker](http://yuedu.baidu.com/ebook/d817967416fc700abb68fca1)\n    [Service discovery with Docker](http://adetante.github.io/articles/service-discovery-with-docker-1/ )\n- tut\n    [](http://www.alauda.cn/tutorial/)\n    [](http://help.daocloud.io/)        \n    [](https://coreos.com/os/docs/latest/quickstart.html   )        \n- course\n    https://training.docker.com/self-paced-training\n    http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice              \nlanguages:\n- php\n    https://github.com/schmunk42/docker-yii2-app-basic\n    https://github.com/eko/docker-symfony\n    https://github.com/harshjv/docker-laravel\n    https://github.com/tkyk/docker-compose-lamp\n    https://github.com/docker-library/php\n    compose\n    https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml\n    https://github.com/tkyk/docker-compose-lamp\n    https://github.com/larryprice/docker-compose-example\n- py\n    https://github.com/dockerfiles/django-uwsgi-nginx\n    https://github.com/mbentley/docker-django-uwsgi-nginx\n    https://github.com/dockerfiles/django-uwsgi-nginx\n    django:https://docs.docker.com/compose/django/\n    flask:dockercook 3.1\n- ruby\n    rails:https://docs.docker.com/compose/rails/\n- js\n    https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon\n- other\n    https://github.com/docker/compose/blob/master/SWARM.md\n    wordpress:https://docs.docker.com/compose/wordpress/\n\n12 factor\n    http://www.the12factorapp.com/\n    https://12factor.net/\n    https://chixq.com/articles/12-factor-app/\n\n\n        ","source":"_posts/docker--portal.md","raw":"---\ntitle: docker portal\ncategories:\n- docker\ntags:\n- portal\n---\n\n# resource\n\nofficial:\n[https://www.docker.com/](https://www.docker.com/)\n[https://blog.docker.com/](https://blog.docker.com/)\n[https://linuxcontainers.org/](https://linuxcontainers.org/)\n\nawesome:\n[https://github.com/Friz-zy/awesome-linux-containers](https://github.com/Friz-zy/awesome-linux-containers)\n\ngithub:\n[docker-library](https://github.com/docker-library)\n[dockerfile](https://github.com/tianon/dockerfiles)   \n[docker-cheat-sheet](https://github.com/wsargent/docker-cheat-sheet)\n[Chef Cookbook for Docker](https://github.com/chef-cookbooks/docker)\n\ncommunity:\n[dockerpool](http://dockerpool.com/)\n[dockerone](http://dockerone.com)\n[devops-china](http://devops-china.org)\n[ceph china](http://bbs.ceph.org.cn/)    \ncloud stack(http://www.cloudstack-china.org/)\natcontainer(http://atcontainer.com/)\ngoogle plus(https://plus.google.com/u/0/+DockerIo)\nzhihu(https://www.zhihu.com/topic/19950993)\nreddit\nstackoverflow(http://superuser.com/questions/tagged/docker)\n\norganization:\nopen container project: [link](http://www.opencontainers.org/), [doc](http://blog.docker.com/2015/06/open-container-project-foundation/)\noci:[](https://www.opencontainers.org/), [](https://github.com/opencontainers)\nabout:DockerrktDockerGoogleIntelRedhatMicrosoftEMCIBMAmazonVMwareOraclePivotalRancherHPEFacebookTwitterIT20156OCIOpen Container InitiativeOCIOCIOCIDocker\nCNCF: Cloud Native Computing Foundation\n\nconf\nQConf:http://2016.qconshanghai.com/, http://qconferences.com/\nDockerCon\n    link\n        http://www.slideshare.net/Docker/presentations\n        http://www.dockercon.com/\n    2015\n        guidebook app\n        http://europe-2015.dockercon.com/\n        http://dockerconeu2015.sched.org/\n    2016\n        http://2016.dockercon.com/\n        https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/\nContainerCon\nContainerCamp\nOperability 1.0\nGoTo Conference\nSoftware Circus\n\n    http://atcontainer.com/\n\n    http://www.bagevent.com/event/176371\n\ndocker vs x\n    docker vs virtual machine\n        link\n            http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#\n            http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution\n            http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker\n\nmooc\n    https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info\n    \nread:\n- infoq: [infoq cn](http://www.infoq.com/cn/dockers/), [infoq en](https://www.infoq.com/docker-2)\n- bot: [yidian](http://www.yidianzixun.com/home?page=channel&keyword=docker), [toutiao](http://toutiao.com/tag85482990/)\n- book\n    Docker Cookbook\n    Docker:publish,[opensource](http://dockerpool.com/static/books/docker_practice/index.html)\n    Docker\n    Docker lts        \n    [docker](http://yuedu.baidu.com/ebook/d817967416fc700abb68fca1)\n    [Service discovery with Docker](http://adetante.github.io/articles/service-discovery-with-docker-1/ )\n- tut\n    [](http://www.alauda.cn/tutorial/)\n    [](http://help.daocloud.io/)        \n    [](https://coreos.com/os/docs/latest/quickstart.html   )        \n- course\n    https://training.docker.com/self-paced-training\n    http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice              \nlanguages:\n- php\n    https://github.com/schmunk42/docker-yii2-app-basic\n    https://github.com/eko/docker-symfony\n    https://github.com/harshjv/docker-laravel\n    https://github.com/tkyk/docker-compose-lamp\n    https://github.com/docker-library/php\n    compose\n    https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml\n    https://github.com/tkyk/docker-compose-lamp\n    https://github.com/larryprice/docker-compose-example\n- py\n    https://github.com/dockerfiles/django-uwsgi-nginx\n    https://github.com/mbentley/docker-django-uwsgi-nginx\n    https://github.com/dockerfiles/django-uwsgi-nginx\n    django:https://docs.docker.com/compose/django/\n    flask:dockercook 3.1\n- ruby\n    rails:https://docs.docker.com/compose/rails/\n- js\n    https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon\n- other\n    https://github.com/docker/compose/blob/master/SWARM.md\n    wordpress:https://docs.docker.com/compose/wordpress/\n\n12 factor\n    http://www.the12factorapp.com/\n    https://12factor.net/\n    https://chixq.com/articles/12-factor-app/\n\n\n        ","slug":"docker--portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:16:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm38f001d21svebn6o2x0","content":"<h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1><p>official:<br><a href=\"https://www.docker.com/\" target=\"_blank\" rel=\"external\">https://www.docker.com/</a><br><a href=\"https://blog.docker.com/\" target=\"_blank\" rel=\"external\">https://blog.docker.com/</a><br><a href=\"https://linuxcontainers.org/\" target=\"_blank\" rel=\"external\">https://linuxcontainers.org/</a></p>\n<p>awesome:<br><a href=\"https://github.com/Friz-zy/awesome-linux-containers\" target=\"_blank\" rel=\"external\">https://github.com/Friz-zy/awesome-linux-containers</a></p>\n<p>github:<br><a href=\"https://github.com/docker-library\" target=\"_blank\" rel=\"external\">docker-library</a><br><a href=\"https://github.com/tianon/dockerfiles\" target=\"_blank\" rel=\"external\">dockerfile</a><br><a href=\"https://github.com/wsargent/docker-cheat-sheet\" target=\"_blank\" rel=\"external\">docker-cheat-sheet</a><br><a href=\"https://github.com/chef-cookbooks/docker\" target=\"_blank\" rel=\"external\">Chef Cookbook for Docker</a></p>\n<p>community:<br><a href=\"http://dockerpool.com/\" target=\"_blank\" rel=\"external\">dockerpool</a><br><a href=\"http://dockerone.com\" target=\"_blank\" rel=\"external\">dockerone</a><br><a href=\"http://devops-china.org\" target=\"_blank\" rel=\"external\">devops-china</a><br><a href=\"http://bbs.ceph.org.cn/\" target=\"_blank\" rel=\"external\">ceph china</a><br>cloud stack(<a href=\"http://www.cloudstack-china.org/\" target=\"_blank\" rel=\"external\">http://www.cloudstack-china.org/</a>)<br>atcontainer(<a href=\"http://atcontainer.com/\" target=\"_blank\" rel=\"external\">http://atcontainer.com/</a>)<br>google plus(<a href=\"https://plus.google.com/u/0/+DockerIo\" target=\"_blank\" rel=\"external\">https://plus.google.com/u/0/+DockerIo</a>)<br>zhihu(<a href=\"https://www.zhihu.com/topic/19950993\" target=\"_blank\" rel=\"external\">https://www.zhihu.com/topic/19950993</a>)<br>reddit<br>stackoverflow(<a href=\"http://superuser.com/questions/tagged/docker\" target=\"_blank\" rel=\"external\">http://superuser.com/questions/tagged/docker</a>)</p>\n<p>organization:<br>open container project: <a href=\"http://www.opencontainers.org/\" target=\"_blank\" rel=\"external\">link</a>, <a href=\"http://blog.docker.com/2015/06/open-container-project-foundation/\" target=\"_blank\" rel=\"external\">doc</a><br>oci:<a href=\"https://www.opencontainers.org/\" target=\"_blank\" rel=\"external\"></a>, <a href=\"https://github.com/opencontainers\" target=\"_blank\" rel=\"external\"></a><br>about:DockerrktDockerGoogleIntelRedhatMicrosoftEMCIBMAmazonVMwareOraclePivotalRancherHPEFacebookTwitterIT20156OCIOpen Container InitiativeOCIOCIOCIDocker<br>CNCF: Cloud Native Computing Foundation</p>\n<p>conf<br>QConf:<a href=\"http://2016.qconshanghai.com/\" target=\"_blank\" rel=\"external\">http://2016.qconshanghai.com/</a>, <a href=\"http://qconferences.com/\" target=\"_blank\" rel=\"external\">http://qconferences.com/</a><br>DockerCon<br>    link<br>        <a href=\"http://www.slideshare.net/Docker/presentations\" target=\"_blank\" rel=\"external\">http://www.slideshare.net/Docker/presentations</a><br>        <a href=\"http://www.dockercon.com/\" target=\"_blank\" rel=\"external\">http://www.dockercon.com/</a><br>    2015<br>        guidebook app<br>        <a href=\"http://europe-2015.dockercon.com/\" target=\"_blank\" rel=\"external\">http://europe-2015.dockercon.com/</a><br>        <a href=\"http://dockerconeu2015.sched.org/\" target=\"_blank\" rel=\"external\">http://dockerconeu2015.sched.org/</a><br>    2016<br>        <a href=\"http://2016.dockercon.com/\" target=\"_blank\" rel=\"external\">http://2016.dockercon.com/</a><br>        <a href=\"https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/\" target=\"_blank\" rel=\"external\">https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/</a><br>ContainerCon<br>ContainerCamp<br>Operability 1.0<br>GoTo Conference<br>Software Circus<br><br>    <a href=\"http://atcontainer.com/\" target=\"_blank\" rel=\"external\">http://atcontainer.com/</a><br><br>    <a href=\"http://www.bagevent.com/event/176371\" target=\"_blank\" rel=\"external\">http://www.bagevent.com/event/176371</a></p>\n<p>docker vs x<br>    docker vs virtual machine<br>        link<br>            <a href=\"http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#</a><br>            <a href=\"http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution</a><br>            <a href=\"http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker</a></p>\n<p>mooc<br>    <a href=\"https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info\" target=\"_blank\" rel=\"external\">https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info</a></p>\n<p>read:</p>\n<ul>\n<li>infoq: <a href=\"http://www.infoq.com/cn/dockers/\" target=\"_blank\" rel=\"external\">infoq cn</a>, <a href=\"https://www.infoq.com/docker-2\" target=\"_blank\" rel=\"external\">infoq en</a></li>\n<li>bot: <a href=\"http://www.yidianzixun.com/home?page=channel&amp;keyword=docker\" target=\"_blank\" rel=\"external\">yidian</a>, <a href=\"http://toutiao.com/tag85482990/\" target=\"_blank\" rel=\"external\">toutiao</a></li>\n<li>book<br>  Docker Cookbook<br>  Docker:publish,<a href=\"http://dockerpool.com/static/books/docker_practice/index.html\" target=\"_blank\" rel=\"external\">opensource</a><br>  Docker<br>  Docker lts<br>  <a href=\"http://yuedu.baidu.com/ebook/d817967416fc700abb68fca1\" target=\"_blank\" rel=\"external\">docker</a><br>  <a href=\"http://adetante.github.io/articles/service-discovery-with-docker-1/\" target=\"_blank\" rel=\"external\">Service discovery with Docker</a></li>\n<li>tut<br>  <a href=\"http://www.alauda.cn/tutorial/\" target=\"_blank\" rel=\"external\"></a><br>  <a href=\"http://help.daocloud.io/\" target=\"_blank\" rel=\"external\"></a><br>  <a href=\"https://coreos.com/os/docs/latest/quickstart.html\" target=\"_blank\" rel=\"external\"></a>        </li>\n<li>course<br>  <a href=\"https://training.docker.com/self-paced-training\" target=\"_blank\" rel=\"external\">https://training.docker.com/self-paced-training</a><br>  <a href=\"http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice\" target=\"_blank\" rel=\"external\">http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice</a><br>languages:</li>\n<li>php<br>  <a href=\"https://github.com/schmunk42/docker-yii2-app-basic\" target=\"_blank\" rel=\"external\">https://github.com/schmunk42/docker-yii2-app-basic</a><br>  <a href=\"https://github.com/eko/docker-symfony\" target=\"_blank\" rel=\"external\">https://github.com/eko/docker-symfony</a><br>  <a href=\"https://github.com/harshjv/docker-laravel\" target=\"_blank\" rel=\"external\">https://github.com/harshjv/docker-laravel</a><br>  <a href=\"https://github.com/tkyk/docker-compose-lamp\" target=\"_blank\" rel=\"external\">https://github.com/tkyk/docker-compose-lamp</a><br>  <a href=\"https://github.com/docker-library/php\" target=\"_blank\" rel=\"external\">https://github.com/docker-library/php</a><br>  compose<br>  <a href=\"https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml\" target=\"_blank\" rel=\"external\">https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml</a><br>  <a href=\"https://github.com/tkyk/docker-compose-lamp\" target=\"_blank\" rel=\"external\">https://github.com/tkyk/docker-compose-lamp</a><br>  <a href=\"https://github.com/larryprice/docker-compose-example\" target=\"_blank\" rel=\"external\">https://github.com/larryprice/docker-compose-example</a></li>\n<li>py<br>  <a href=\"https://github.com/dockerfiles/django-uwsgi-nginx\" target=\"_blank\" rel=\"external\">https://github.com/dockerfiles/django-uwsgi-nginx</a><br>  <a href=\"https://github.com/mbentley/docker-django-uwsgi-nginx\" target=\"_blank\" rel=\"external\">https://github.com/mbentley/docker-django-uwsgi-nginx</a><br>  <a href=\"https://github.com/dockerfiles/django-uwsgi-nginx\" target=\"_blank\" rel=\"external\">https://github.com/dockerfiles/django-uwsgi-nginx</a><br>  django:<a href=\"https://docs.docker.com/compose/django/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/django/</a><br>  flask:dockercook 3.1</li>\n<li>ruby<br>  rails:<a href=\"https://docs.docker.com/compose/rails/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/rails/</a></li>\n<li>js<br>  <a href=\"https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon\" target=\"_blank\" rel=\"external\">https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon</a></li>\n<li>other<br>  <a href=\"https://github.com/docker/compose/blob/master/SWARM.md\" target=\"_blank\" rel=\"external\">https://github.com/docker/compose/blob/master/SWARM.md</a><br>  wordpress:<a href=\"https://docs.docker.com/compose/wordpress/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/wordpress/</a></li>\n</ul>\n<p>12 factor<br>    <a href=\"http://www.the12factorapp.com/\" target=\"_blank\" rel=\"external\">http://www.the12factorapp.com/</a><br>    <a href=\"https://12factor.net/\" target=\"_blank\" rel=\"external\">https://12factor.net/</a><br>    <a href=\"https://chixq.com/articles/12-factor-app/\" target=\"_blank\" rel=\"external\">https://chixq.com/articles/12-factor-app/</a></p>\n","excerpt":"","more":"<h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1><p>official:<br><a href=\"https://www.docker.com/\">https://www.docker.com/</a><br><a href=\"https://blog.docker.com/\">https://blog.docker.com/</a><br><a href=\"https://linuxcontainers.org/\">https://linuxcontainers.org/</a></p>\n<p>awesome:<br><a href=\"https://github.com/Friz-zy/awesome-linux-containers\">https://github.com/Friz-zy/awesome-linux-containers</a></p>\n<p>github:<br><a href=\"https://github.com/docker-library\">docker-library</a><br><a href=\"https://github.com/tianon/dockerfiles\">dockerfile</a><br><a href=\"https://github.com/wsargent/docker-cheat-sheet\">docker-cheat-sheet</a><br><a href=\"https://github.com/chef-cookbooks/docker\">Chef Cookbook for Docker</a></p>\n<p>community:<br><a href=\"http://dockerpool.com/\">dockerpool</a><br><a href=\"http://dockerone.com\">dockerone</a><br><a href=\"http://devops-china.org\">devops-china</a><br><a href=\"http://bbs.ceph.org.cn/\">ceph china</a><br>cloud stack(<a href=\"http://www.cloudstack-china.org/\">http://www.cloudstack-china.org/</a>)<br>atcontainer(<a href=\"http://atcontainer.com/\">http://atcontainer.com/</a>)<br>google plus(<a href=\"https://plus.google.com/u/0/+DockerIo\">https://plus.google.com/u/0/+DockerIo</a>)<br>zhihu(<a href=\"https://www.zhihu.com/topic/19950993\">https://www.zhihu.com/topic/19950993</a>)<br>reddit<br>stackoverflow(<a href=\"http://superuser.com/questions/tagged/docker\">http://superuser.com/questions/tagged/docker</a>)</p>\n<p>organization:<br>open container project: <a href=\"http://www.opencontainers.org/\">link</a>, <a href=\"http://blog.docker.com/2015/06/open-container-project-foundation/\">doc</a><br>oci:<a href=\"https://www.opencontainers.org/\"></a>, <a href=\"https://github.com/opencontainers\"></a><br>about:DockerrktDockerGoogleIntelRedhatMicrosoftEMCIBMAmazonVMwareOraclePivotalRancherHPEFacebookTwitterIT20156OCIOpen Container InitiativeOCIOCIOCIDocker<br>CNCF: Cloud Native Computing Foundation</p>\n<p>conf<br>QConf:<a href=\"http://2016.qconshanghai.com/\">http://2016.qconshanghai.com/</a>, <a href=\"http://qconferences.com/\">http://qconferences.com/</a><br>DockerCon<br>    link<br>        <a href=\"http://www.slideshare.net/Docker/presentations\">http://www.slideshare.net/Docker/presentations</a><br>        <a href=\"http://www.dockercon.com/\">http://www.dockercon.com/</a><br>    2015<br>        guidebook app<br>        <a href=\"http://europe-2015.dockercon.com/\">http://europe-2015.dockercon.com/</a><br>        <a href=\"http://dockerconeu2015.sched.org/\">http://dockerconeu2015.sched.org/</a><br>    2016<br>        <a href=\"http://2016.dockercon.com/\">http://2016.dockercon.com/</a><br>        <a href=\"https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/\">https://blog.docker.com/2016/06/dockercon-general-session-day-1-and-day-2-videos/</a><br>ContainerCon<br>ContainerCamp<br>Operability 1.0<br>GoTo Conference<br>Software Circus<br><br>    <a href=\"http://atcontainer.com/\">http://atcontainer.com/</a><br><br>    <a href=\"http://www.bagevent.com/event/176371\">http://www.bagevent.com/event/176371</a></p>\n<p>docker vs x<br>    docker vs virtual machine<br>        link<br>            <a href=\"http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#\">http://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-normal-virtual-machine#</a><br>            <a href=\"http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution\">http://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution</a><br>            <a href=\"http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker\">http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker</a></p>\n<p>mooc<br>    <a href=\"https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info\">https://courses.edx.org/courses/course-v1:LinuxFoundationX+LFS151.x+2T2016/info</a></p>\n<p>read:</p>\n<ul>\n<li>infoq: <a href=\"http://www.infoq.com/cn/dockers/\">infoq cn</a>, <a href=\"https://www.infoq.com/docker-2\">infoq en</a></li>\n<li>bot: <a href=\"http://www.yidianzixun.com/home?page=channel&amp;keyword=docker\">yidian</a>, <a href=\"http://toutiao.com/tag85482990/\">toutiao</a></li>\n<li>book<br>  Docker Cookbook<br>  Docker:publish,<a href=\"http://dockerpool.com/static/books/docker_practice/index.html\">opensource</a><br>  Docker<br>  Docker lts<br>  <a href=\"http://yuedu.baidu.com/ebook/d817967416fc700abb68fca1\">docker</a><br>  <a href=\"http://adetante.github.io/articles/service-discovery-with-docker-1/\">Service discovery with Docker</a></li>\n<li>tut<br>  <a href=\"http://www.alauda.cn/tutorial/\"></a><br>  <a href=\"http://help.daocloud.io/\"></a><br>  <a href=\"https://coreos.com/os/docs/latest/quickstart.html\"></a>        </li>\n<li>course<br>  <a href=\"https://training.docker.com/self-paced-training\">https://training.docker.com/self-paced-training</a><br>  <a href=\"http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice\">http://www.infoq.com/cn/presentations/antgroup-financial-cloud-paas-docker-practice</a><br>languages:</li>\n<li>php<br>  <a href=\"https://github.com/schmunk42/docker-yii2-app-basic\">https://github.com/schmunk42/docker-yii2-app-basic</a><br>  <a href=\"https://github.com/eko/docker-symfony\">https://github.com/eko/docker-symfony</a><br>  <a href=\"https://github.com/harshjv/docker-laravel\">https://github.com/harshjv/docker-laravel</a><br>  <a href=\"https://github.com/tkyk/docker-compose-lamp\">https://github.com/tkyk/docker-compose-lamp</a><br>  <a href=\"https://github.com/docker-library/php\">https://github.com/docker-library/php</a><br>  compose<br>  <a href=\"https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml\">https://github.com/DockerNuts/docker-compose-php-mysql/blob/master/docker-compose.yml</a><br>  <a href=\"https://github.com/tkyk/docker-compose-lamp\">https://github.com/tkyk/docker-compose-lamp</a><br>  <a href=\"https://github.com/larryprice/docker-compose-example\">https://github.com/larryprice/docker-compose-example</a></li>\n<li>py<br>  <a href=\"https://github.com/dockerfiles/django-uwsgi-nginx\">https://github.com/dockerfiles/django-uwsgi-nginx</a><br>  <a href=\"https://github.com/mbentley/docker-django-uwsgi-nginx\">https://github.com/mbentley/docker-django-uwsgi-nginx</a><br>  <a href=\"https://github.com/dockerfiles/django-uwsgi-nginx\">https://github.com/dockerfiles/django-uwsgi-nginx</a><br>  django:<a href=\"https://docs.docker.com/compose/django/\">https://docs.docker.com/compose/django/</a><br>  flask:dockercook 3.1</li>\n<li>ruby<br>  rails:<a href=\"https://docs.docker.com/compose/rails/\">https://docs.docker.com/compose/rails/</a></li>\n<li>js<br>  <a href=\"https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon\">https://github.com/b00giZm/docker-compose-nodejs-examples/tree/master/01-express-nodemon</a></li>\n<li>other<br>  <a href=\"https://github.com/docker/compose/blob/master/SWARM.md\">https://github.com/docker/compose/blob/master/SWARM.md</a><br>  wordpress:<a href=\"https://docs.docker.com/compose/wordpress/\">https://docs.docker.com/compose/wordpress/</a></li>\n</ul>\n<p>12 factor<br>    <a href=\"http://www.the12factorapp.com/\">http://www.the12factorapp.com/</a><br>    <a href=\"https://12factor.net/\">https://12factor.net/</a><br>    <a href=\"https://chixq.com/articles/12-factor-app/\">https://chixq.com/articles/12-factor-app/</a></p>\n"},{"title":"docker compose","_content":"\n# about\n\n- official: https://docs.docker.com/compose/\n- in production: https://docs.docker.com/compose/production/\n\n\norchestration , \nFig: [fig](http://www.fig.sh/),YAML;\nFit cmd: add fig.yml; fig up\n\n# install\n\n[link](http://docs.docker.com/compose/install/)\n            \n        docker-compose --version\n\n    64bits Linux or MacOS X:\n\n            curl -L https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\n            chmod +x /usr/local/bin/docker-compose\n    \n    win and other:\n\n            sudo pip install -U docker-compose\n# command\n\n- docker-compose up -d\n\n- docker exec\n    \n    docker exec -it example_web_1 bash\n\n- docker-compose stop && docker-compose rm --force\n\n- docker-compose build\n    Build or rebuild services\n\n- docker-compose help\n\n- docker-compose kill\n    Kill containers  SIGKILL \n    \n        docker-compose kill -s SIGINT\n\n- docker-compose logs\n    View output from containers\n\n- docker-compose port\n    Print the public port for a port binding\n\n- docker-compose ps\n    List containers\n\n- docker-compose pull\n    Pulls service images\n\n- docker-compose rm\n    Remove stopped containers\n\n- docker-compose run\n\n    Run a one-off command \n    docker-compose run ubuntu ping docker.com\n         ubuntu  ping docker.com \n    \n    \n    \n        \n        \n     --no-deps \n        docker-compose run --no-deps web python manage.py shell\n         web \n\n- docker-compose scale\n\n    Set number of containers for a service \n    service=num\n    docker-compose scale web=2 worker=3\n\n- docker-compose start\n\n    Start services\n\n- docker-compose stop\n\n    Stop services\n\n- docker-compose restart\n\n    Restart services\n        env variable\n\n            COMPOSE_PROJECT_NAME\n                 Compose \n            COMPOSE_FILE\n                 docker-compose.yml \n            DOCKER_HOST\n                 Docker daemon  unix:///var/run/docker.sock Docker \n            DOCKER_TLS_VERIFY\n                 Docker daemon  TLS \n            DOCKER_CERT_PATH\n                 TLS ca.pemcert.pem  key.pem ~/.docker \n\n- docker-compose up\n\n    Create and start containers\n        $ docker-compose up -d\n\n- docker-compose logs\n\n- docker-compose version\n\n    Show the Docker-Compose version information\n\n- docker-compose unpause\n\n    Unpause services\n\n- docker-compose migrate-to-labels\n\n    Recreate containers to add labels\n   ","source":"_posts/docker-compose-detail.md","raw":"---\ntitle: docker compose\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about\n\n- official: https://docs.docker.com/compose/\n- in production: https://docs.docker.com/compose/production/\n\n\norchestration , \nFig: [fig](http://www.fig.sh/),YAML;\nFit cmd: add fig.yml; fig up\n\n# install\n\n[link](http://docs.docker.com/compose/install/)\n            \n        docker-compose --version\n\n    64bits Linux or MacOS X:\n\n            curl -L https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\n            chmod +x /usr/local/bin/docker-compose\n    \n    win and other:\n\n            sudo pip install -U docker-compose\n# command\n\n- docker-compose up -d\n\n- docker exec\n    \n    docker exec -it example_web_1 bash\n\n- docker-compose stop && docker-compose rm --force\n\n- docker-compose build\n    Build or rebuild services\n\n- docker-compose help\n\n- docker-compose kill\n    Kill containers  SIGKILL \n    \n        docker-compose kill -s SIGINT\n\n- docker-compose logs\n    View output from containers\n\n- docker-compose port\n    Print the public port for a port binding\n\n- docker-compose ps\n    List containers\n\n- docker-compose pull\n    Pulls service images\n\n- docker-compose rm\n    Remove stopped containers\n\n- docker-compose run\n\n    Run a one-off command \n    docker-compose run ubuntu ping docker.com\n         ubuntu  ping docker.com \n    \n    \n    \n        \n        \n     --no-deps \n        docker-compose run --no-deps web python manage.py shell\n         web \n\n- docker-compose scale\n\n    Set number of containers for a service \n    service=num\n    docker-compose scale web=2 worker=3\n\n- docker-compose start\n\n    Start services\n\n- docker-compose stop\n\n    Stop services\n\n- docker-compose restart\n\n    Restart services\n        env variable\n\n            COMPOSE_PROJECT_NAME\n                 Compose \n            COMPOSE_FILE\n                 docker-compose.yml \n            DOCKER_HOST\n                 Docker daemon  unix:///var/run/docker.sock Docker \n            DOCKER_TLS_VERIFY\n                 Docker daemon  TLS \n            DOCKER_CERT_PATH\n                 TLS ca.pemcert.pem  key.pem ~/.docker \n\n- docker-compose up\n\n    Create and start containers\n        $ docker-compose up -d\n\n- docker-compose logs\n\n- docker-compose version\n\n    Show the Docker-Compose version information\n\n- docker-compose unpause\n\n    Unpause services\n\n- docker-compose migrate-to-labels\n\n    Recreate containers to add labels\n   ","slug":"docker-compose-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-18T07:19:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm38h001f21sv8w2usj1k","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>official: <a href=\"https://docs.docker.com/compose/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/</a></li>\n<li>in production: <a href=\"https://docs.docker.com/compose/production/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/production/</a></li>\n</ul>\n<p>orchestration , <br>Fig: <a href=\"http://www.fig.sh/\" target=\"_blank\" rel=\"external\">fig</a>,YAML;<br>Fit cmd: add fig.yml; fig up</p>\n<h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><p><a href=\"http://docs.docker.com/compose/install/\" target=\"_blank\" rel=\"external\">link</a></p>\n<pre><code>    docker-compose --version\n\n64bits Linux or MacOS X:\n\n        curl -L https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose\n        chmod +x /usr/local/bin/docker-compose\n\nwin and other:\n\n        sudo pip install -U docker-compose\n</code></pre><h1 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h1><ul>\n<li><p>docker-compose up -d</p>\n</li>\n<li><p>docker exec</p>\n<p>  docker exec -it example_web_1 bash</p>\n</li>\n<li><p>docker-compose stop &amp;&amp; docker-compose rm force</p>\n</li>\n<li><p>docker-compose build<br>  Build or rebuild services</p>\n</li>\n<li><p>docker-compose help</p>\n</li>\n<li><p>docker-compose kill<br>  Kill containers  SIGKILL <br>  </p>\n<pre><code>docker-compose kill -s SIGINT\n</code></pre></li>\n<li><p>docker-compose logs<br>  View output from containers</p>\n</li>\n<li><p>docker-compose port<br>  Print the public port for a port binding</p>\n</li>\n<li><p>docker-compose ps<br>  List containers</p>\n</li>\n<li><p>docker-compose pull<br>  Pulls service images</p>\n</li>\n<li><p>docker-compose rm<br>  Remove stopped containers</p>\n</li>\n<li><p>docker-compose run</p>\n<p>  Run a one-off command <br>  docker-compose run ubuntu ping docker.com</p>\n<pre><code> ubuntu  ping docker.com \n</code></pre><p>  <br>  <br>  </p>\n<pre><code>\n\n</code></pre><p>   no-deps </p>\n<pre><code>docker-compose run --no-deps web python manage.py shell\n web \n</code></pre></li>\n<li><p>docker-compose scale</p>\n<p>  Set number of containers for a service <br>  service=num<br>  docker-compose scale web=2 worker=3</p>\n</li>\n<li><p>docker-compose start</p>\n<p>  Start services</p>\n</li>\n<li><p>docker-compose stop</p>\n<p>  Stop services</p>\n</li>\n<li><p>docker-compose restart</p>\n<p>  Restart services</p>\n<pre><code>env variable\n\n    COMPOSE_PROJECT_NAME\n         Compose \n    COMPOSE_FILE\n         docker-compose.yml \n    DOCKER_HOST\n         Docker daemon  unix:///var/run/docker.sock Docker \n    DOCKER_TLS_VERIFY\n         Docker daemon  TLS \n    DOCKER_CERT_PATH\n         TLS ca.pemcert.pem  key.pem ~/.docker \n</code></pre></li>\n<li><p>docker-compose up</p>\n<p>  Create and start containers</p>\n<pre><code>$ docker-compose up -d\n</code></pre></li>\n<li><p>docker-compose logs</p>\n</li>\n<li><p>docker-compose version</p>\n<p>  Show the Docker-Compose version information</p>\n</li>\n<li><p>docker-compose unpause</p>\n<p>  Unpause services</p>\n</li>\n<li><p>docker-compose migrate-to-labels</p>\n<p>  Recreate containers to add labels</p>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>official: <a href=\"https://docs.docker.com/compose/\">https://docs.docker.com/compose/</a></li>\n<li>in production: <a href=\"https://docs.docker.com/compose/production/\">https://docs.docker.com/compose/production/</a></li>\n</ul>\n<p>orchestration , <br>Fig: <a href=\"http://www.fig.sh/\">fig</a>,YAML;<br>Fit cmd: add fig.yml; fig up</p>\n<h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><p><a href=\"http://docs.docker.com/compose/install/\">link</a></p>\n<pre><code>    docker-compose --version\n\n64bits Linux or MacOS X:\n\n        curl -L https://github.com/docker/compose/releases/download/1.1.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose\n        chmod +x /usr/local/bin/docker-compose\n\nwin and other:\n\n        sudo pip install -U docker-compose\n</code></pre><h1 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h1><ul>\n<li><p>docker-compose up -d</p>\n</li>\n<li><p>docker exec</p>\n<p>  docker exec -it example_web_1 bash</p>\n</li>\n<li><p>docker-compose stop &amp;&amp; docker-compose rm force</p>\n</li>\n<li><p>docker-compose build<br>  Build or rebuild services</p>\n</li>\n<li><p>docker-compose help</p>\n</li>\n<li><p>docker-compose kill<br>  Kill containers  SIGKILL <br>  </p>\n<pre><code>docker-compose kill -s SIGINT\n</code></pre></li>\n<li><p>docker-compose logs<br>  View output from containers</p>\n</li>\n<li><p>docker-compose port<br>  Print the public port for a port binding</p>\n</li>\n<li><p>docker-compose ps<br>  List containers</p>\n</li>\n<li><p>docker-compose pull<br>  Pulls service images</p>\n</li>\n<li><p>docker-compose rm<br>  Remove stopped containers</p>\n</li>\n<li><p>docker-compose run</p>\n<p>  Run a one-off command <br>  docker-compose run ubuntu ping docker.com</p>\n<pre><code> ubuntu  ping docker.com \n</code></pre><p>  <br>  <br>  </p>\n<pre><code>\n\n</code></pre><p>   no-deps </p>\n<pre><code>docker-compose run --no-deps web python manage.py shell\n web \n</code></pre></li>\n<li><p>docker-compose scale</p>\n<p>  Set number of containers for a service <br>  service=num<br>  docker-compose scale web=2 worker=3</p>\n</li>\n<li><p>docker-compose start</p>\n<p>  Start services</p>\n</li>\n<li><p>docker-compose stop</p>\n<p>  Stop services</p>\n</li>\n<li><p>docker-compose restart</p>\n<p>  Restart services</p>\n<pre><code>env variable\n\n    COMPOSE_PROJECT_NAME\n         Compose \n    COMPOSE_FILE\n         docker-compose.yml \n    DOCKER_HOST\n         Docker daemon  unix:///var/run/docker.sock Docker \n    DOCKER_TLS_VERIFY\n         Docker daemon  TLS \n    DOCKER_CERT_PATH\n         TLS ca.pemcert.pem  key.pem ~/.docker \n</code></pre></li>\n<li><p>docker-compose up</p>\n<p>  Create and start containers</p>\n<pre><code>$ docker-compose up -d\n</code></pre></li>\n<li><p>docker-compose logs</p>\n</li>\n<li><p>docker-compose version</p>\n<p>  Show the Docker-Compose version information</p>\n</li>\n<li><p>docker-compose unpause</p>\n<p>  Unpause services</p>\n</li>\n<li><p>docker-compose migrate-to-labels</p>\n<p>  Recreate containers to add labels</p>\n</li>\n</ul>\n"},{"title":"docker compose","_content":"\n# about\n\n- official: https://docs.docker.com/compose/compose-file/\n- django example: https://docs.docker.com/compose/django/\n- rails example: https://docs.docker.com/compose/rails/\n- machine, swarm, compose: https://blog.docker.com/2015/02/orchestrating-docker-with-machine-swarm-and-compose/\n\nThe Compose file is a YAML file defining services, networks and volumes. The default path for a Compose file is ./docker-compose.yml.\n\nA service definition contains configuration which will be applied to each container started for that service, much like passing command-line parameters to docker run. Likewise, network and volume definitions are analogous to docker network create and docker volume create.\n\nAs with docker run, options specified in the Dockerfile (e.g., CMD, EXPOSE, VOLUME, ENV) are respected by default - you dont need to specify them again in docker-compose.yml.\n\n# service configuration reference\n\n- build\n\n# volume configuration reference\n\n# network configuration reference\n\n# versioning\n\n# variable substitution","source":"_posts/docker-compose-file-detail.md","raw":"---\ntitle: docker compose\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about\n\n- official: https://docs.docker.com/compose/compose-file/\n- django example: https://docs.docker.com/compose/django/\n- rails example: https://docs.docker.com/compose/rails/\n- machine, swarm, compose: https://blog.docker.com/2015/02/orchestrating-docker-with-machine-swarm-and-compose/\n\nThe Compose file is a YAML file defining services, networks and volumes. The default path for a Compose file is ./docker-compose.yml.\n\nA service definition contains configuration which will be applied to each container started for that service, much like passing command-line parameters to docker run. Likewise, network and volume definitions are analogous to docker network create and docker volume create.\n\nAs with docker run, options specified in the Dockerfile (e.g., CMD, EXPOSE, VOLUME, ENV) are respected by default - you dont need to specify them again in docker-compose.yml.\n\n# service configuration reference\n\n- build\n\n# volume configuration reference\n\n# network configuration reference\n\n# versioning\n\n# variable substitution","slug":"docker-compose-file-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-18T07:33:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm38l001k21svmq9vzpvt","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>official: <a href=\"https://docs.docker.com/compose/compose-file/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/compose-file/</a></li>\n<li>django example: <a href=\"https://docs.docker.com/compose/django/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/django/</a></li>\n<li>rails example: <a href=\"https://docs.docker.com/compose/rails/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/rails/</a></li>\n<li>machine, swarm, compose: <a href=\"https://blog.docker.com/2015/02/orchestrating-docker-with-machine-swarm-and-compose/\" target=\"_blank\" rel=\"external\">https://blog.docker.com/2015/02/orchestrating-docker-with-machine-swarm-and-compose/</a></li>\n</ul>\n<p>The Compose file is a YAML file defining services, networks and volumes. The default path for a Compose file is ./docker-compose.yml.</p>\n<p>A service definition contains configuration which will be applied to each container started for that service, much like passing command-line parameters to docker run. Likewise, network and volume definitions are analogous to docker network create and docker volume create.</p>\n<p>As with docker run, options specified in the Dockerfile (e.g., CMD, EXPOSE, VOLUME, ENV) are respected by default - you dont need to specify them again in docker-compose.yml.</p>\n<h1 id=\"service-configuration-reference\"><a href=\"#service-configuration-reference\" class=\"headerlink\" title=\"service configuration reference\"></a>service configuration reference</h1><ul>\n<li>build</li>\n</ul>\n<h1 id=\"volume-configuration-reference\"><a href=\"#volume-configuration-reference\" class=\"headerlink\" title=\"volume configuration reference\"></a>volume configuration reference</h1><h1 id=\"network-configuration-reference\"><a href=\"#network-configuration-reference\" class=\"headerlink\" title=\"network configuration reference\"></a>network configuration reference</h1><h1 id=\"versioning\"><a href=\"#versioning\" class=\"headerlink\" title=\"versioning\"></a>versioning</h1><h1 id=\"variable-substitution\"><a href=\"#variable-substitution\" class=\"headerlink\" title=\"variable substitution\"></a>variable substitution</h1>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>official: <a href=\"https://docs.docker.com/compose/compose-file/\">https://docs.docker.com/compose/compose-file/</a></li>\n<li>django example: <a href=\"https://docs.docker.com/compose/django/\">https://docs.docker.com/compose/django/</a></li>\n<li>rails example: <a href=\"https://docs.docker.com/compose/rails/\">https://docs.docker.com/compose/rails/</a></li>\n<li>machine, swarm, compose: <a href=\"https://blog.docker.com/2015/02/orchestrating-docker-with-machine-swarm-and-compose/\">https://blog.docker.com/2015/02/orchestrating-docker-with-machine-swarm-and-compose/</a></li>\n</ul>\n<p>The Compose file is a YAML file defining services, networks and volumes. The default path for a Compose file is ./docker-compose.yml.</p>\n<p>A service definition contains configuration which will be applied to each container started for that service, much like passing command-line parameters to docker run. Likewise, network and volume definitions are analogous to docker network create and docker volume create.</p>\n<p>As with docker run, options specified in the Dockerfile (e.g., CMD, EXPOSE, VOLUME, ENV) are respected by default - you dont need to specify them again in docker-compose.yml.</p>\n<h1 id=\"service-configuration-reference\"><a href=\"#service-configuration-reference\" class=\"headerlink\" title=\"service configuration reference\"></a>service configuration reference</h1><ul>\n<li>build</li>\n</ul>\n<h1 id=\"volume-configuration-reference\"><a href=\"#volume-configuration-reference\" class=\"headerlink\" title=\"volume configuration reference\"></a>volume configuration reference</h1><h1 id=\"network-configuration-reference\"><a href=\"#network-configuration-reference\" class=\"headerlink\" title=\"network configuration reference\"></a>network configuration reference</h1><h1 id=\"versioning\"><a href=\"#versioning\" class=\"headerlink\" title=\"versioning\"></a>versioning</h1><h1 id=\"variable-substitution\"><a href=\"#variable-substitution\" class=\"headerlink\" title=\"variable substitution\"></a>variable substitution</h1>"},{"_content":"    ```\n        containers:\n        web:\n         build: .\n         command: python app.py\n         ports:\n         - \"5000:5000\"\n         volumes:\n         - .:/code\n         links:\n         - redis\n         environment:\n         - PYTHONUNBUFFERED=1\n        redis:\n         image: redis:latest\n         command: redis-server --appendonly yes\n     ```\n\n     ```\n        wiki2:\n        image: 'nickstenning/mediawiki'\n        ports:\n            - \"8880:80\"\n        links:\n            - db:database\n        volumes:\n            - /data/wiki2:/data\n\n        db:\n        image: \"mysql\"\n        expose:\n            - \"3306\"\n        environment:\n            - MYSQL_ROOT_PASSWORD=defaultpass\n\n    YAMLPythonDockerfile\n    Docker HubRedislinksPythonRedis\n    \n\n    docker-compose up\n\n    linksPythonRedisRedisPython\n\n# Variable substitution\n            \nBoth $VARIABLE and ${VARIABLE} syntax are supported. \nExtended shell-style features, such as ${VARIABLE-default} and ${VARIABLE/foo/bar}, are not supported.\n            db:\n  image: \"postgres:${POSTGRES_VERSION}\"\n            web:\n  build: .\n  command: \"$$VAR_NOT_INTERPOLATED_BY_COMPOSE\"\n        \n# install\n\n    curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose --version | awk 'NR==1{print $NF}')/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose\n        doc\n            docker-compose.yml reference\n                https://docs.docker.com/compose/yml/\n        keywords\n            image\n                 IDCompose \n                image: ubuntu\n            build\n                 Dockerfile \n                Compose \n                build: /path/to/build/dir\n            dockerfile\n            command\n                \n                command: bundle exec thin -p 3000\n            links\n                \n                 SERVICE:ALIAS \n                    links:\n - db\n - db:database\n - redis\n                 /etc/hosts ,\n                    172.17.2.186  db\n172.17.2.186  database\n172.17.2.187  redis\n            external_links\n                 docker-compose.yml \n                  Compose  links \n                external_links:\n - redis_1\n - project_db_1:mysql\n - project_db_1:postgresql\n            extra_hosts\n            ports\n                \n                 HOST:CONTAINER\n                ports:\n - \"3000\"\n - \"8000:8000\"\n - \"49100:22\"\n - \"127.0.0.1:8001:8001\"\n            expose\n                \n                \n                expose:\n - \"3000\"\n - \"8000\"\n            volumes\n                \n                 HOST:CONTAINER  HOST:CONTAINER:ro\n                volumes:\n - /var/lib/mysql\n - cache/:/tmp/cache\n - ~/configs:/etc/configs/:ro\n            volumes_from\n                \n                volumes_from:\n - service_name\n - container_name\n            environment\n                \n                 Compose \n                environment:\n  RACK_ENV: development\n  SESSION_SECRET:\n\nenvironment:\n  - RACK_ENV=development\n  - SESSION_SECRET\n            env_file\n                \n                 docker-compose -f FILE  env_file \n                 environment \n                env_file: .env\n\nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/secrets.env\n                 # \n                # common.env: Set Rails/Rack environment\nRACK_ENV=development\n            extends\n                \n                 webapp  common.yml\n                # common.yml\nwebapp:\n  build: ./webapp\n  environment:\n    - DEBUG=false\n    - SEND_EMAILS=false\n                 development.yml  common.yml  webapp \n                # development.yml\nweb:\n  extends:\n    file: common.yml\n    service: webapp\n  ports:\n    - \"8000:8000\"\n  links:\n    - db\n  environment:\n    - DEBUG=true\ndb:\n  image: postgres\n                 common.yml  webapp \n            labels\n            container_name\n            log driver\n            net\n                \n                 docker client  --net \n                net: \"bridge\"\nnet: \"none\"\nnet: \"container:[name or id]\"\nnet: \"host\"\n            pid\n                \n                 ID \n                pid: \"host\"\n            dns\n                 DNS \n                \n                dns: 8.8.8.8\n- dns:\n\n  - 8.8.8.8\n  - 9.9.9.9\n            cap_add, cap_drop\n                 Linux Capabiliity\n                cap_add:\n  - ALL\n\n- cap_drop:\n\n  - NET_ADMIN\n  - SYS_ADMIN\n            dns_search\n                 DNS \n                \n                dns_search: example.com\n- dns_search:\n\n  - domain1.example.com\n  - domain2.example.com\n            devices\n            security_opt\n            working_dir, entrypoint, user, hostname, domainname, \nmac_address, mem_limit, memswap_limit, privileged, \nrestart, stdin_open, tty, cpu_shares, cpuset, \nread_only, volume_driver\n                 docker run \n                cpu_shares: 73\n\nworking_dir: /code\nentrypoint: /code/entrypoint.sh\nuser: postgresql\n\nhostname: foo\ndomainname: foo.com\n\nmem_limit: 1000000000\nprivileged: true\n\nrestart: always\n\nstdin_open: true\ntty: true\n        keyword\n            build\n                Path to a directory containing a Dockerfile.\n                build: /path/to/build/dir\n            cap_add, cap_drop\n                Add or drop container capabilities. See man 7 capabilities for a full list.\n                cap_add:\n  - ALL\n\ncap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n            command\n                Override the default command.\n                command: bundle exec thin -p 3000\n            cgroup_parent\n                Specify an optional parent cgroup for the container.\n                cgroup_parent: m-executor-abcd\n            container_name\n                Specify a custom container name, rather than a generated default name.\n                container_name: my-web-container\n            devices\n                List of device mappings. Uses the same format as the --device docker client create option.\n                devices:\n  - \"/dev/ttyUSB0:/dev/ttyUSB0\"\n            dns\n                Custom DNS servers. Can be a single value or a list.\n                dns: 8.8.8.8\ndns:\n  - 8.8.8.8\n  - 9.9.9.9\n            dns_search\n                Custom DNS search domains. Can be a single value or a list.\n                dns_search: example.com\ndns_search:\n  - dc1.example.com\n  - dc2.example.com\n            dockerfile\n                Alternate Dockerfile.\nCompose will use an alternate file to build with.\n                dockerfile: Dockerfile-alternate\n            env_file\n                Add environment variables from a file. Can be a single value or a list.\nIf you have specified a Compose file with docker-compose -f FILE, \npaths in env_file are relative to the directory that file is in.\nEnvironment variables specified in environment override these values.\n                env_file: .env\n\nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/secrets.env\n                Compose expects each line in an env file to be in VAR=VAL format.\n Lines beginning with # (i.e. comments) are ignored, as are blank lines.\n\n# Set Rails/Rack environment\nRACK_ENV=development\n            environment\n                Add environment variables. You can use either an array or a dictionary.\n                Any boolean values; true, false, yes no, need to be enclosed in quotes\n to ensure they are not converted to True or False by the YML parser.\n                Environment variables with only a key are resolved to their values on the machine Compose is running on, \nwhich can be helpful for secret or host-specific values.\n                environment:\n  RACK_ENV: development\n  SHOW: 'true'\n  SESSION_SECRET:\n\nenvironment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET\n            expose\n                Expose ports without publishing them to the host machine - \ntheyll only be accessible to linked services. Only the internal port can be specified.\n                expose:\n - \"3000\"\n - \"8000\"\n            extends\n                Extend another service, in the current file or another, optionally overriding configuration.\nYou can use extends on any service together with other configuration keys.\n The extends value must be a dictionary defined with a required service and an optional file key.\n                extends:\n  file: common.yml\n  service: webapp\n            external_links\n                Link to containers started outside this docker-compose.yml or even outside of Compose,\n especially for containers that provide shared or common services. \nexternal_links follow semantics similar to links when specifying both the container name and the link alias (CONTAINER:ALIAS).\n                external_links:\n - redis_1\n - project_db_1:mysql\n - project_db_1:postgresql\n            extra_hosts\n                Add hostname mappings. Use the same values as the docker client --add-host parameter.\n                extra_hosts:\n - \"somehost:162.242.195.82\"\n - \"otherhost:50.31.209.229\"\n                An entry with the ip address and hostname will be created in /etc/hosts inside containers for this service, e.g:\n\n162.242.195.82  somehost\n50.31.209.229   otherhost\n            image\n                Tag or partial image ID. Can be local or remote - \nCompose will attempt to pull if it doesnt exist locally.\n                image: ubuntu\nimage: orchardup/postgresql\nimage: a4bc65fd\n            labels\n                Add metadata to containers using Docker labels. You can use either an array or a dictionary.\nIts recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n                labels:\n  com.example.description: \"Accounting webapp\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n\nlabels:\n  - \"com.example.description=Accounting webapp\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n            links\n                Link to containers in another service. \nEither specify both the service name and the link alias (SERVICE:ALIAS), \nor just the service name (which will also be used for the alias).\n                links:\n - db\n - db:database\n - redis\n                An entry with the alias name will be created in /etc/hosts \ninside containers for this service, e.g:\n\n172.17.2.186  db\n172.17.2.186  database\n172.17.2.187  redis\n            log_driver\n                Specify a logging driver for the services containers, as with the --log-driver option for docker run\n                The default value is json-file.\nNote: Only the json-file driver makes the logs available directly from docker-compose up and docker-compose logs. \nUsing any other driver will not print any logs.\n                log_driver: \"json-file\"\nlog_driver: \"syslog\"\nlog_driver: \"none\"\n            log_opt\n                Specify logging options with log_opt for the logging driver, as with the --log-opt option for docker run.\n                log_driver: \"syslog\"\nlog_opt:\n  syslog-address: \"tcp://192.168.0.42:123\"\n            net\n                Networking mode. Use the same values as the docker client --net parameter.\n                net: \"bridge\"\nnet: \"none\"\nnet: \"container:[name or id]\"\nnet: \"host\"\n            pid\n                pid: \"host\"\n                Sets the PID mode to the host PID mode. \nThis turns on sharing between container and the host oprating system the PID address space.\n Containers launched with this flag will be able to access and manipulate other containers\n in the bare-metal machines namespace and vise-versa.\n            ports\n                Expose ports. Either specify both ports (HOST:CONTAINER), \nor just the container port (a random host port will be chosen).\n                Note: When mapping ports in the HOST:CONTAINER format, \nyou may experience erroneous results when using a container port lower than 60, \nbecause YAML will parse numbers in the format xx:yy as sexagesimal (base 60). \nFor this reason, we recommend always explicitly specifying your port mappings as strings.\n                ports:\n - \"3000\"\n - \"3000-3005\"\n - \"8000:8000\"\n - \"9090-9091:8080-8081\"\n - \"49100:22\"\n - \"127.0.0.1:8001:8001\"\n - \"127.0.0.1:5000-5010:5000-5010\"\n            security_opt\n                Override the default labeling scheme for each container.\n                security_opt:\n    - label:user:USER\n    - label:role:ROLE\n            ulimits\n                Override the default ulimits for a container. \nYou can either specify a single limit as an integer or soft/hard limits as a mapping.\n                ulimits:\n    nproc: 65535\n    nofile:\n      soft: 20000\n      hard: 40000\n            volumes, volume_driver\n                Mount paths as volumes, optionally specifying a path on the host machine \n(HOST:CONTAINER), or an access mode (HOST:CONTAINER:ro).\n                volumes:\n - /var/lib/mysql\n - ./cache:/tmp/cache\n - ~/configs:/etc/configs/:ro\n                You can mount a relative path on the host, which will expand relative to the director\ny of the Compose configuration file being used. Relative paths should always begin with . or ...\n                If you use a volume name (instead of a volume path), you may also specify a volume_driver.\nvolume_driver: mydriver\nNote: No path expansion will be done if you have also specified a volume_driver.\n            volumes_from\n                Mount all of the volumes from another service or container, \noptionally specifying read-only access(ro) or read-write(rw).\n                volumes_from:\n - service_name\n - container_name\n - service_name:rw\n            cpu_shares, cpuset, domainname, entrypoint, hostname, \nipc, mac_address, mem_limit, memswap_limit, privileged, \nread_only, restart, stdin_open, tty, user, working_dir\n                Each of these is a single value, analogous to its docker run counterpart.\n                cpu_shares: 73\ncpuset: 0,1\n\nentrypoint: /code/entrypoint.sh\nuser: postgresql\nworking_dir: /code\n\ndomainname: foo.com\nhostname: foo\nipc: host\nmac_address: 02:42:ac:11:65:43\n\nmem_limit: 1000000000\nmemswap_limit: 2000000000\nprivileged: true\n\nrestart: always\n\nread_only: true\nstdin_open: true\ntty: true","source":"_posts/docker-compose-file-tmp.md","raw":"    ```\n        containers:\n        web:\n         build: .\n         command: python app.py\n         ports:\n         - \"5000:5000\"\n         volumes:\n         - .:/code\n         links:\n         - redis\n         environment:\n         - PYTHONUNBUFFERED=1\n        redis:\n         image: redis:latest\n         command: redis-server --appendonly yes\n     ```\n\n     ```\n        wiki2:\n        image: 'nickstenning/mediawiki'\n        ports:\n            - \"8880:80\"\n        links:\n            - db:database\n        volumes:\n            - /data/wiki2:/data\n\n        db:\n        image: \"mysql\"\n        expose:\n            - \"3306\"\n        environment:\n            - MYSQL_ROOT_PASSWORD=defaultpass\n\n    YAMLPythonDockerfile\n    Docker HubRedislinksPythonRedis\n    \n\n    docker-compose up\n\n    linksPythonRedisRedisPython\n\n# Variable substitution\n            \nBoth $VARIABLE and ${VARIABLE} syntax are supported. \nExtended shell-style features, such as ${VARIABLE-default} and ${VARIABLE/foo/bar}, are not supported.\n            db:\n  image: \"postgres:${POSTGRES_VERSION}\"\n            web:\n  build: .\n  command: \"$$VAR_NOT_INTERPOLATED_BY_COMPOSE\"\n        \n# install\n\n    curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose --version | awk 'NR==1{print $NF}')/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose\n        doc\n            docker-compose.yml reference\n                https://docs.docker.com/compose/yml/\n        keywords\n            image\n                 IDCompose \n                image: ubuntu\n            build\n                 Dockerfile \n                Compose \n                build: /path/to/build/dir\n            dockerfile\n            command\n                \n                command: bundle exec thin -p 3000\n            links\n                \n                 SERVICE:ALIAS \n                    links:\n - db\n - db:database\n - redis\n                 /etc/hosts ,\n                    172.17.2.186  db\n172.17.2.186  database\n172.17.2.187  redis\n            external_links\n                 docker-compose.yml \n                  Compose  links \n                external_links:\n - redis_1\n - project_db_1:mysql\n - project_db_1:postgresql\n            extra_hosts\n            ports\n                \n                 HOST:CONTAINER\n                ports:\n - \"3000\"\n - \"8000:8000\"\n - \"49100:22\"\n - \"127.0.0.1:8001:8001\"\n            expose\n                \n                \n                expose:\n - \"3000\"\n - \"8000\"\n            volumes\n                \n                 HOST:CONTAINER  HOST:CONTAINER:ro\n                volumes:\n - /var/lib/mysql\n - cache/:/tmp/cache\n - ~/configs:/etc/configs/:ro\n            volumes_from\n                \n                volumes_from:\n - service_name\n - container_name\n            environment\n                \n                 Compose \n                environment:\n  RACK_ENV: development\n  SESSION_SECRET:\n\nenvironment:\n  - RACK_ENV=development\n  - SESSION_SECRET\n            env_file\n                \n                 docker-compose -f FILE  env_file \n                 environment \n                env_file: .env\n\nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/secrets.env\n                 # \n                # common.env: Set Rails/Rack environment\nRACK_ENV=development\n            extends\n                \n                 webapp  common.yml\n                # common.yml\nwebapp:\n  build: ./webapp\n  environment:\n    - DEBUG=false\n    - SEND_EMAILS=false\n                 development.yml  common.yml  webapp \n                # development.yml\nweb:\n  extends:\n    file: common.yml\n    service: webapp\n  ports:\n    - \"8000:8000\"\n  links:\n    - db\n  environment:\n    - DEBUG=true\ndb:\n  image: postgres\n                 common.yml  webapp \n            labels\n            container_name\n            log driver\n            net\n                \n                 docker client  --net \n                net: \"bridge\"\nnet: \"none\"\nnet: \"container:[name or id]\"\nnet: \"host\"\n            pid\n                \n                 ID \n                pid: \"host\"\n            dns\n                 DNS \n                \n                dns: 8.8.8.8\n- dns:\n\n  - 8.8.8.8\n  - 9.9.9.9\n            cap_add, cap_drop\n                 Linux Capabiliity\n                cap_add:\n  - ALL\n\n- cap_drop:\n\n  - NET_ADMIN\n  - SYS_ADMIN\n            dns_search\n                 DNS \n                \n                dns_search: example.com\n- dns_search:\n\n  - domain1.example.com\n  - domain2.example.com\n            devices\n            security_opt\n            working_dir, entrypoint, user, hostname, domainname, \nmac_address, mem_limit, memswap_limit, privileged, \nrestart, stdin_open, tty, cpu_shares, cpuset, \nread_only, volume_driver\n                 docker run \n                cpu_shares: 73\n\nworking_dir: /code\nentrypoint: /code/entrypoint.sh\nuser: postgresql\n\nhostname: foo\ndomainname: foo.com\n\nmem_limit: 1000000000\nprivileged: true\n\nrestart: always\n\nstdin_open: true\ntty: true\n        keyword\n            build\n                Path to a directory containing a Dockerfile.\n                build: /path/to/build/dir\n            cap_add, cap_drop\n                Add or drop container capabilities. See man 7 capabilities for a full list.\n                cap_add:\n  - ALL\n\ncap_drop:\n  - NET_ADMIN\n  - SYS_ADMIN\n            command\n                Override the default command.\n                command: bundle exec thin -p 3000\n            cgroup_parent\n                Specify an optional parent cgroup for the container.\n                cgroup_parent: m-executor-abcd\n            container_name\n                Specify a custom container name, rather than a generated default name.\n                container_name: my-web-container\n            devices\n                List of device mappings. Uses the same format as the --device docker client create option.\n                devices:\n  - \"/dev/ttyUSB0:/dev/ttyUSB0\"\n            dns\n                Custom DNS servers. Can be a single value or a list.\n                dns: 8.8.8.8\ndns:\n  - 8.8.8.8\n  - 9.9.9.9\n            dns_search\n                Custom DNS search domains. Can be a single value or a list.\n                dns_search: example.com\ndns_search:\n  - dc1.example.com\n  - dc2.example.com\n            dockerfile\n                Alternate Dockerfile.\nCompose will use an alternate file to build with.\n                dockerfile: Dockerfile-alternate\n            env_file\n                Add environment variables from a file. Can be a single value or a list.\nIf you have specified a Compose file with docker-compose -f FILE, \npaths in env_file are relative to the directory that file is in.\nEnvironment variables specified in environment override these values.\n                env_file: .env\n\nenv_file:\n  - ./common.env\n  - ./apps/web.env\n  - /opt/secrets.env\n                Compose expects each line in an env file to be in VAR=VAL format.\n Lines beginning with # (i.e. comments) are ignored, as are blank lines.\n\n# Set Rails/Rack environment\nRACK_ENV=development\n            environment\n                Add environment variables. You can use either an array or a dictionary.\n                Any boolean values; true, false, yes no, need to be enclosed in quotes\n to ensure they are not converted to True or False by the YML parser.\n                Environment variables with only a key are resolved to their values on the machine Compose is running on, \nwhich can be helpful for secret or host-specific values.\n                environment:\n  RACK_ENV: development\n  SHOW: 'true'\n  SESSION_SECRET:\n\nenvironment:\n  - RACK_ENV=development\n  - SHOW=true\n  - SESSION_SECRET\n            expose\n                Expose ports without publishing them to the host machine - \ntheyll only be accessible to linked services. Only the internal port can be specified.\n                expose:\n - \"3000\"\n - \"8000\"\n            extends\n                Extend another service, in the current file or another, optionally overriding configuration.\nYou can use extends on any service together with other configuration keys.\n The extends value must be a dictionary defined with a required service and an optional file key.\n                extends:\n  file: common.yml\n  service: webapp\n            external_links\n                Link to containers started outside this docker-compose.yml or even outside of Compose,\n especially for containers that provide shared or common services. \nexternal_links follow semantics similar to links when specifying both the container name and the link alias (CONTAINER:ALIAS).\n                external_links:\n - redis_1\n - project_db_1:mysql\n - project_db_1:postgresql\n            extra_hosts\n                Add hostname mappings. Use the same values as the docker client --add-host parameter.\n                extra_hosts:\n - \"somehost:162.242.195.82\"\n - \"otherhost:50.31.209.229\"\n                An entry with the ip address and hostname will be created in /etc/hosts inside containers for this service, e.g:\n\n162.242.195.82  somehost\n50.31.209.229   otherhost\n            image\n                Tag or partial image ID. Can be local or remote - \nCompose will attempt to pull if it doesnt exist locally.\n                image: ubuntu\nimage: orchardup/postgresql\nimage: a4bc65fd\n            labels\n                Add metadata to containers using Docker labels. You can use either an array or a dictionary.\nIts recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.\n                labels:\n  com.example.description: \"Accounting webapp\"\n  com.example.department: \"Finance\"\n  com.example.label-with-empty-value: \"\"\n\nlabels:\n  - \"com.example.description=Accounting webapp\"\n  - \"com.example.department=Finance\"\n  - \"com.example.label-with-empty-value\"\n            links\n                Link to containers in another service. \nEither specify both the service name and the link alias (SERVICE:ALIAS), \nor just the service name (which will also be used for the alias).\n                links:\n - db\n - db:database\n - redis\n                An entry with the alias name will be created in /etc/hosts \ninside containers for this service, e.g:\n\n172.17.2.186  db\n172.17.2.186  database\n172.17.2.187  redis\n            log_driver\n                Specify a logging driver for the services containers, as with the --log-driver option for docker run\n                The default value is json-file.\nNote: Only the json-file driver makes the logs available directly from docker-compose up and docker-compose logs. \nUsing any other driver will not print any logs.\n                log_driver: \"json-file\"\nlog_driver: \"syslog\"\nlog_driver: \"none\"\n            log_opt\n                Specify logging options with log_opt for the logging driver, as with the --log-opt option for docker run.\n                log_driver: \"syslog\"\nlog_opt:\n  syslog-address: \"tcp://192.168.0.42:123\"\n            net\n                Networking mode. Use the same values as the docker client --net parameter.\n                net: \"bridge\"\nnet: \"none\"\nnet: \"container:[name or id]\"\nnet: \"host\"\n            pid\n                pid: \"host\"\n                Sets the PID mode to the host PID mode. \nThis turns on sharing between container and the host oprating system the PID address space.\n Containers launched with this flag will be able to access and manipulate other containers\n in the bare-metal machines namespace and vise-versa.\n            ports\n                Expose ports. Either specify both ports (HOST:CONTAINER), \nor just the container port (a random host port will be chosen).\n                Note: When mapping ports in the HOST:CONTAINER format, \nyou may experience erroneous results when using a container port lower than 60, \nbecause YAML will parse numbers in the format xx:yy as sexagesimal (base 60). \nFor this reason, we recommend always explicitly specifying your port mappings as strings.\n                ports:\n - \"3000\"\n - \"3000-3005\"\n - \"8000:8000\"\n - \"9090-9091:8080-8081\"\n - \"49100:22\"\n - \"127.0.0.1:8001:8001\"\n - \"127.0.0.1:5000-5010:5000-5010\"\n            security_opt\n                Override the default labeling scheme for each container.\n                security_opt:\n    - label:user:USER\n    - label:role:ROLE\n            ulimits\n                Override the default ulimits for a container. \nYou can either specify a single limit as an integer or soft/hard limits as a mapping.\n                ulimits:\n    nproc: 65535\n    nofile:\n      soft: 20000\n      hard: 40000\n            volumes, volume_driver\n                Mount paths as volumes, optionally specifying a path on the host machine \n(HOST:CONTAINER), or an access mode (HOST:CONTAINER:ro).\n                volumes:\n - /var/lib/mysql\n - ./cache:/tmp/cache\n - ~/configs:/etc/configs/:ro\n                You can mount a relative path on the host, which will expand relative to the director\ny of the Compose configuration file being used. Relative paths should always begin with . or ...\n                If you use a volume name (instead of a volume path), you may also specify a volume_driver.\nvolume_driver: mydriver\nNote: No path expansion will be done if you have also specified a volume_driver.\n            volumes_from\n                Mount all of the volumes from another service or container, \noptionally specifying read-only access(ro) or read-write(rw).\n                volumes_from:\n - service_name\n - container_name\n - service_name:rw\n            cpu_shares, cpuset, domainname, entrypoint, hostname, \nipc, mac_address, mem_limit, memswap_limit, privileged, \nread_only, restart, stdin_open, tty, user, working_dir\n                Each of these is a single value, analogous to its docker run counterpart.\n                cpu_shares: 73\ncpuset: 0,1\n\nentrypoint: /code/entrypoint.sh\nuser: postgresql\nworking_dir: /code\n\ndomainname: foo.com\nhostname: foo\nipc: host\nmac_address: 02:42:ac:11:65:43\n\nmem_limit: 1000000000\nmemswap_limit: 2000000000\nprivileged: true\n\nrestart: always\n\nread_only: true\nstdin_open: true\ntty: true","slug":"docker-compose-file-tmp","published":1,"date":"2017-01-18T07:23:48.000Z","updated":"2017-01-18T07:23:48.000Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm38p001n21sv7kz4kcuv","content":"<pre><code><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">containers:</div><div class=\"line\">web:</div><div class=\"line\"> build: .</div><div class=\"line\"> command: python app.py</div><div class=\"line\"> ports:</div><div class=\"line\"> - &quot;5000:5000&quot;</div><div class=\"line\"> volumes:</div><div class=\"line\"> - .:/code</div><div class=\"line\"> links:</div><div class=\"line\"> - redis</div><div class=\"line\"> environment:</div><div class=\"line\"> - PYTHONUNBUFFERED=1</div><div class=\"line\">redis:</div><div class=\"line\"> image: redis:latest</div><div class=\"line\"> command: redis-server --appendonly yes</div></pre></td></tr></table></figure>\n\n ```\n    wiki2:\n    image: &apos;nickstenning/mediawiki&apos;\n    ports:\n        - &quot;8880:80&quot;\n    links:\n        - db:database\n    volumes:\n        - /data/wiki2:/data\n\n    db:\n    image: &quot;mysql&quot;\n    expose:\n        - &quot;3306&quot;\n    environment:\n        - MYSQL_ROOT_PASSWORD=defaultpass\n\nYAMLPythonDockerfile\nDocker HubRedislinksPythonRedis\n\n\ndocker-compose up\n\nlinksPythonRedisRedisPython\n</code></pre><h1 id=\"Variable-substitution\"><a href=\"#Variable-substitution\" class=\"headerlink\" title=\"Variable substitution\"></a>Variable substitution</h1><p>Both $VARIABLE and ${VARIABLE} syntax are supported.<br>Extended shell-style features, such as ${VARIABLE-default} and ${VARIABLE/foo/bar}, are not supported.<br>            db:<br>  image: postgres:${POSTGRES_VERSION}<br>            web:<br>  build: .<br>  command: $$VAR_NOT_INTERPOLATED_BY_COMPOSE</p>\n<h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><pre><code>curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose --version | awk &apos;NR==1{print $NF}&apos;)/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose\n    doc\n        docker-compose.yml reference\n            https://docs.docker.com/compose/yml/\n    keywords\n        image\n             IDCompose \n            image: ubuntu\n        build\n             Dockerfile \n            Compose \n            build: /path/to/build/dir\n        dockerfile\n        command\n            \n            command: bundle exec thin -p 3000\n        links\n            \n             SERVICE:ALIAS \n                links:\n</code></pre><ul>\n<li>db</li>\n<li>db:database</li>\n<li>redis<pre><code> /etc/hosts ,\n    172.17.2.186  db\n</code></pre>172.17.2.186  database<br>172.17.2.187  redis<pre><code>external_links\n     docker-compose.yml \n      Compose  links \n    external_links:\n</code></pre></li>\n<li>redis_1</li>\n<li>project_db_1:mysql</li>\n<li>project_db_1:postgresql<pre><code>extra_hosts\nports\n    \n     HOST:CONTAINER\n    ports:\n</code></pre></li>\n<li>3000</li>\n<li>8000:8000</li>\n<li>49100:22</li>\n<li>127.0.0.1:8001:8001<pre><code>expose\n    \n    \n    expose:\n</code></pre></li>\n<li>3000</li>\n<li>8000<pre><code>volumes\n    \n     HOST:CONTAINER  HOST:CONTAINER:ro\n    volumes:\n</code></pre></li>\n<li>/var/lib/mysql</li>\n<li>cache/:/tmp/cache</li>\n<li>~/configs:/etc/configs/:ro<pre><code>volumes_from\n    \n    volumes_from:\n</code></pre></li>\n<li>service_name</li>\n<li>container_name<pre><code>environment\n    \n     Compose \n    environment:\n</code></pre>RACK_ENV: development<br>SESSION_SECRET:</li>\n</ul>\n<p>environment:</p>\n<ul>\n<li>RACK_ENV=development</li>\n<li>SESSION_SECRET<pre><code>env_file\n    \n     docker-compose -f FILE  env_file \n     environment \n    env_file: .env\n</code></pre></li>\n</ul>\n<p>env_file:</p>\n<ul>\n<li>./common.env</li>\n<li>./apps/web.env</li>\n<li><p>/opt/secrets.env</p>\n<pre><code> # \n# common.env: Set Rails/Rack environment\n</code></pre><p>RACK_ENV=development</p>\n<pre><code>extends\n    \n     webapp  common.yml\n    # common.yml\n</code></pre><p>webapp:<br>build: ./webapp<br>environment:</p>\n<ul>\n<li>DEBUG=false</li>\n<li>SEND_EMAILS=false<pre><code> development.yml  common.yml  webapp \n# development.yml\n</code></pre>web:<br>extends:<br>file: common.yml<br>service: webapp<br>ports:</li>\n<li>8000:8000<br>links:</li>\n<li>db<br>environment:</li>\n<li>DEBUG=true<br>db:<br>image: postgres<pre><code>     common.yml  webapp \nlabels\ncontainer_name\nlog driver\nnet\n    \n     docker client  --net \n    net: &quot;bridge&quot;\n</code></pre>net: none<br>net: container:[name or id]<br>net: host<pre><code>pid\n    \n     ID \n    pid: &quot;host&quot;\ndns\n     DNS \n    \n    dns: 8.8.8.8\n</code></pre></li>\n<li>dns:</li>\n</ul>\n</li>\n<li><p>8.8.8.8</p>\n</li>\n<li>9.9.9.9<pre><code>cap_add, cap_drop\n     Linux Capabiliity\n    cap_add:\n</code></pre></li>\n<li>ALL</li>\n</ul>\n<ul>\n<li><p>cap_drop:</p>\n<ul>\n<li>NET_ADMIN</li>\n<li>SYS_ADMIN<pre><code>dns_search\n     DNS \n    \n    dns_search: example.com\n</code></pre></li>\n</ul>\n</li>\n<li><p>dns_search:</p>\n<ul>\n<li>domain1.example.com</li>\n<li>domain2.example.com<pre><code>devices\nsecurity_opt\nworking_dir, entrypoint, user, hostname, domainname, \n</code></pre>mac_address, mem_limit, memswap_limit, privileged,<br>restart, stdin_open, tty, cpu_shares, cpuset,<br>read_only, volume_driver<pre><code> docker run \ncpu_shares: 73\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<p>working_dir: /code<br>entrypoint: /code/entrypoint.sh<br>user: postgresql</p>\n<p>hostname: foo<br>domainname: foo.com</p>\n<p>mem_limit: 1000000000<br>privileged: true</p>\n<p>restart: always</p>\n<p>stdin_open: true<br>tty: true<br>        keyword<br>            build<br>                Path to a directory containing a Dockerfile.<br>                build: /path/to/build/dir<br>            cap_add, cap_drop<br>                Add or drop container capabilities. See man 7 capabilities for a full list.<br>                cap_add:</p>\n<ul>\n<li>ALL</li>\n</ul>\n<p>cap_drop:</p>\n<ul>\n<li>NET_ADMIN</li>\n<li>SYS_ADMIN<pre><code>command\n    Override the default command.\n    command: bundle exec thin -p 3000\ncgroup_parent\n    Specify an optional parent cgroup for the container.\n    cgroup_parent: m-executor-abcd\ncontainer_name\n    Specify a custom container name, rather than a generated default name.\n    container_name: my-web-container\ndevices\n    List of device mappings. Uses the same format as the --device docker client create option.\n    devices:\n</code></pre></li>\n<li>/dev/ttyUSB0:/dev/ttyUSB0<pre><code>dns\n    Custom DNS servers. Can be a single value or a list.\n    dns: 8.8.8.8\n</code></pre>dns:</li>\n<li>8.8.8.8</li>\n<li>9.9.9.9<pre><code>dns_search\n    Custom DNS search domains. Can be a single value or a list.\n    dns_search: example.com\n</code></pre>dns_search:</li>\n<li>dc1.example.com</li>\n<li>dc2.example.com<pre><code>dockerfile\n    Alternate Dockerfile.\n</code></pre>Compose will use an alternate file to build with.<pre><code>    dockerfile: Dockerfile-alternate\nenv_file\n    Add environment variables from a file. Can be a single value or a list.\n</code></pre>If you have specified a Compose file with docker-compose -f FILE,<br>paths in env_file are relative to the directory that file is in.<br>Environment variables specified in environment override these values.<pre><code>env_file: .env\n</code></pre></li>\n</ul>\n<p>env_file:</p>\n<ul>\n<li>./common.env</li>\n<li>./apps/web.env</li>\n<li>/opt/secrets.env<pre><code>Compose expects each line in an env file to be in VAR=VAL format.\n</code></pre>Lines beginning with # (i.e. comments) are ignored, as are blank lines.</li>\n</ul>\n<h1 id=\"Set-Rails-Rack-environment\"><a href=\"#Set-Rails-Rack-environment\" class=\"headerlink\" title=\"Set Rails/Rack environment\"></a>Set Rails/Rack environment</h1><p>RACK_ENV=development<br>            environment<br>                Add environment variables. You can use either an array or a dictionary.<br>                Any boolean values; true, false, yes no, need to be enclosed in quotes<br> to ensure they are not converted to True or False by the YML parser.<br>                Environment variables with only a key are resolved to their values on the machine Compose is running on,<br>which can be helpful for secret or host-specific values.<br>                environment:<br>  RACK_ENV: development<br>  SHOW: true<br>  SESSION_SECRET:</p>\n<p>environment:</p>\n<ul>\n<li>RACK_ENV=development</li>\n<li>SHOW=true</li>\n<li>SESSION_SECRET<pre><code>expose\n    Expose ports without publishing them to the host machine - \n</code></pre>theyll only be accessible to linked services. Only the internal port can be specified.<pre><code>expose:\n</code></pre><ul>\n<li>3000</li>\n<li>8000<pre><code>extends\n    Extend another service, in the current file or another, optionally overriding configuration.\n</code></pre>You can use extends on any service together with other configuration keys.<br>The extends value must be a dictionary defined with a required service and an optional file key.<pre><code>extends:\n</code></pre>file: common.yml<br>service: webapp<pre><code>external_links\n    Link to containers started outside this docker-compose.yml or even outside of Compose,\n</code></pre>especially for containers that provide shared or common services.<br>external_links follow semantics similar to links when specifying both the container name and the link alias (CONTAINER:ALIAS).<pre><code>external_links:\n</code></pre></li>\n<li>redis_1</li>\n<li>project_db_1:mysql</li>\n<li>project_db_1:postgresql<pre><code>extra_hosts\n    Add hostname mappings. Use the same values as the docker client --add-host parameter.\n    extra_hosts:\n</code></pre></li>\n<li>somehost:162.242.195.82</li>\n<li>otherhost:50.31.209.229<pre><code>An entry with the ip address and hostname will be created in /etc/hosts inside containers for this service, e.g:\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<p>162.242.195.82  somehost<br>50.31.209.229   otherhost<br>            image<br>                Tag or partial image ID. Can be local or remote -<br>Compose will attempt to pull if it doesnt exist locally.<br>                image: ubuntu<br>image: orchardup/postgresql<br>image: a4bc65fd<br>            labels<br>                Add metadata to containers using Docker labels. You can use either an array or a dictionary.<br>Its recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.<br>                labels:<br>  com.example.description: Accounting webapp<br>  com.example.department: Finance<br>  com.example.label-with-empty-value: </p>\n<p>labels:</p>\n<ul>\n<li>com.example.description=Accounting webapp</li>\n<li>com.example.department=Finance</li>\n<li>com.example.label-with-empty-value<pre><code>links\n    Link to containers in another service. \n</code></pre>Either specify both the service name and the link alias (SERVICE:ALIAS),<br>or just the service name (which will also be used for the alias).<pre><code>links:\n</code></pre><ul>\n<li>db</li>\n<li>db:database</li>\n<li>redis<pre><code>An entry with the alias name will be created in /etc/hosts \n</code></pre>inside containers for this service, e.g:</li>\n</ul>\n</li>\n</ul>\n<p>172.17.2.186  db<br>172.17.2.186  database<br>172.17.2.187  redis<br>            log_driver<br>                Specify a logging driver for the services containers, as with the log-driver option for docker run<br>                The default value is json-file.<br>Note: Only the json-file driver makes the logs available directly from docker-compose up and docker-compose logs.<br>Using any other driver will not print any logs.<br>                log_driver: json-file<br>log_driver: syslog<br>log_driver: none<br>            log_opt<br>                Specify logging options with log_opt for the logging driver, as with the log-opt option for docker run.<br>                log_driver: syslog<br>log_opt:<br>  syslog-address: tcp://192.168.0.42:123<br>            net<br>                Networking mode. Use the same values as the docker client net parameter.<br>                net: bridge<br>net: none<br>net: container:[name or id]<br>net: host<br>            pid<br>                pid: host<br>                Sets the PID mode to the host PID mode.<br>This turns on sharing between container and the host oprating system the PID address space.<br> Containers launched with this flag will be able to access and manipulate other containers<br> in the bare-metal machines namespace and vise-versa.<br>            ports<br>                Expose ports. Either specify both ports (HOST:CONTAINER),<br>or just the container port (a random host port will be chosen).<br>                Note: When mapping ports in the HOST:CONTAINER format,<br>you may experience erroneous results when using a container port lower than 60,<br>because YAML will parse numbers in the format xx:yy as sexagesimal (base 60).<br>For this reason, we recommend always explicitly specifying your port mappings as strings.<br>                ports:</p>\n<ul>\n<li>3000</li>\n<li>3000-3005</li>\n<li>8000:8000</li>\n<li>9090-9091:8080-8081</li>\n<li>49100:22</li>\n<li>127.0.0.1:8001:8001</li>\n<li>127.0.0.1:5000-5010:5000-5010<pre><code>security_opt\n    Override the default labeling scheme for each container.\n    security_opt:\n</code></pre><ul>\n<li>label:user:USER</li>\n<li>label:role:ROLE<pre><code>ulimits\n    Override the default ulimits for a container. \n</code></pre>You can either specify a single limit as an integer or soft/hard limits as a mapping.<pre><code>ulimits:\n</code></pre>nproc: 65535<br>nofile:<br>soft: 20000<br>hard: 40000<pre><code>volumes, volume_driver\n    Mount paths as volumes, optionally specifying a path on the host machine \n</code></pre>(HOST:CONTAINER), or an access mode (HOST:CONTAINER:ro).<pre><code>volumes:\n</code></pre></li>\n</ul>\n</li>\n<li>/var/lib/mysql</li>\n<li>./cache:/tmp/cache</li>\n<li>~/configs:/etc/configs/:ro<pre><code>You can mount a relative path on the host, which will expand relative to the director\n</code></pre>y of the Compose configuration file being used. Relative paths should always begin with . or <pre><code>If you use a volume name (instead of a volume path), you may also specify a volume_driver.\n</code></pre>volume_driver: mydriver<br>Note: No path expansion will be done if you have also specified a volume_driver.<pre><code>volumes_from\n    Mount all of the volumes from another service or container, \n</code></pre>optionally specifying read-only access(ro) or read-write(rw).<pre><code>volumes_from:\n</code></pre></li>\n<li>service_name</li>\n<li>container_name</li>\n<li>service_name:rw<pre><code>cpu_shares, cpuset, domainname, entrypoint, hostname, \n</code></pre>ipc, mac_address, mem_limit, memswap_limit, privileged,<br>read_only, restart, stdin_open, tty, user, working_dir<pre><code>Each of these is a single value, analogous to its docker run counterpart.\ncpu_shares: 73\n</code></pre>cpuset: 0,1</li>\n</ul>\n<p>entrypoint: /code/entrypoint.sh<br>user: postgresql<br>working_dir: /code</p>\n<p>domainname: foo.com<br>hostname: foo<br>ipc: host<br>mac_address: 02:42:ac:11:65:43</p>\n<p>mem_limit: 1000000000<br>memswap_limit: 2000000000<br>privileged: true</p>\n<p>restart: always</p>\n<p>read_only: true<br>stdin_open: true<br>tty: true</p>\n","excerpt":"","more":"<pre><code><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">containers:</div><div class=\"line\">web:</div><div class=\"line\"> build: .</div><div class=\"line\"> command: python app.py</div><div class=\"line\"> ports:</div><div class=\"line\"> - &quot;5000:5000&quot;</div><div class=\"line\"> volumes:</div><div class=\"line\"> - .:/code</div><div class=\"line\"> links:</div><div class=\"line\"> - redis</div><div class=\"line\"> environment:</div><div class=\"line\"> - PYTHONUNBUFFERED=1</div><div class=\"line\">redis:</div><div class=\"line\"> image: redis:latest</div><div class=\"line\"> command: redis-server --appendonly yes</div></pre></td></tr></table></figure>\n\n ```\n    wiki2:\n    image: &apos;nickstenning/mediawiki&apos;\n    ports:\n        - &quot;8880:80&quot;\n    links:\n        - db:database\n    volumes:\n        - /data/wiki2:/data\n\n    db:\n    image: &quot;mysql&quot;\n    expose:\n        - &quot;3306&quot;\n    environment:\n        - MYSQL_ROOT_PASSWORD=defaultpass\n\nYAMLPythonDockerfile\nDocker HubRedislinksPythonRedis\n\n\ndocker-compose up\n\nlinksPythonRedisRedisPython\n</code></pre><h1 id=\"Variable-substitution\"><a href=\"#Variable-substitution\" class=\"headerlink\" title=\"Variable substitution\"></a>Variable substitution</h1><p>Both $VARIABLE and ${VARIABLE} syntax are supported.<br>Extended shell-style features, such as ${VARIABLE-default} and ${VARIABLE/foo/bar}, are not supported.<br>            db:<br>  image: postgres:${POSTGRES_VERSION}<br>            web:<br>  build: .<br>  command: $$VAR_NOT_INTERPOLATED_BY_COMPOSE</p>\n<h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><pre><code>curl -L https://raw.githubusercontent.com/docker/compose/$(docker-compose --version | awk &apos;NR==1{print $NF}&apos;)/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose\n    doc\n        docker-compose.yml reference\n            https://docs.docker.com/compose/yml/\n    keywords\n        image\n             IDCompose \n            image: ubuntu\n        build\n             Dockerfile \n            Compose \n            build: /path/to/build/dir\n        dockerfile\n        command\n            \n            command: bundle exec thin -p 3000\n        links\n            \n             SERVICE:ALIAS \n                links:\n</code></pre><ul>\n<li>db</li>\n<li>db:database</li>\n<li>redis<pre><code> /etc/hosts ,\n    172.17.2.186  db\n</code></pre>172.17.2.186  database<br>172.17.2.187  redis<pre><code>external_links\n     docker-compose.yml \n      Compose  links \n    external_links:\n</code></pre></li>\n<li>redis_1</li>\n<li>project_db_1:mysql</li>\n<li>project_db_1:postgresql<pre><code>extra_hosts\nports\n    \n     HOST:CONTAINER\n    ports:\n</code></pre></li>\n<li>3000</li>\n<li>8000:8000</li>\n<li>49100:22</li>\n<li>127.0.0.1:8001:8001<pre><code>expose\n    \n    \n    expose:\n</code></pre></li>\n<li>3000</li>\n<li>8000<pre><code>volumes\n    \n     HOST:CONTAINER  HOST:CONTAINER:ro\n    volumes:\n</code></pre></li>\n<li>/var/lib/mysql</li>\n<li>cache/:/tmp/cache</li>\n<li>~/configs:/etc/configs/:ro<pre><code>volumes_from\n    \n    volumes_from:\n</code></pre></li>\n<li>service_name</li>\n<li>container_name<pre><code>environment\n    \n     Compose \n    environment:\n</code></pre>RACK_ENV: development<br>SESSION_SECRET:</li>\n</ul>\n<p>environment:</p>\n<ul>\n<li>RACK_ENV=development</li>\n<li>SESSION_SECRET<pre><code>env_file\n    \n     docker-compose -f FILE  env_file \n     environment \n    env_file: .env\n</code></pre></li>\n</ul>\n<p>env_file:</p>\n<ul>\n<li>./common.env</li>\n<li>./apps/web.env</li>\n<li><p>/opt/secrets.env</p>\n<pre><code> # \n# common.env: Set Rails/Rack environment\n</code></pre><p>RACK_ENV=development</p>\n<pre><code>extends\n    \n     webapp  common.yml\n    # common.yml\n</code></pre><p>webapp:<br>build: ./webapp<br>environment:</p>\n<ul>\n<li>DEBUG=false</li>\n<li>SEND_EMAILS=false<pre><code> development.yml  common.yml  webapp \n# development.yml\n</code></pre>web:<br>extends:<br>file: common.yml<br>service: webapp<br>ports:</li>\n<li>8000:8000<br>links:</li>\n<li>db<br>environment:</li>\n<li>DEBUG=true<br>db:<br>image: postgres<pre><code>     common.yml  webapp \nlabels\ncontainer_name\nlog driver\nnet\n    \n     docker client  --net \n    net: &quot;bridge&quot;\n</code></pre>net: none<br>net: container:[name or id]<br>net: host<pre><code>pid\n    \n     ID \n    pid: &quot;host&quot;\ndns\n     DNS \n    \n    dns: 8.8.8.8\n</code></pre></li>\n<li>dns:</li>\n</ul>\n</li>\n<li><p>8.8.8.8</p>\n</li>\n<li>9.9.9.9<pre><code>cap_add, cap_drop\n     Linux Capabiliity\n    cap_add:\n</code></pre></li>\n<li>ALL</li>\n</ul>\n<ul>\n<li><p>cap_drop:</p>\n<ul>\n<li>NET_ADMIN</li>\n<li>SYS_ADMIN<pre><code>dns_search\n     DNS \n    \n    dns_search: example.com\n</code></pre></li>\n</ul>\n</li>\n<li><p>dns_search:</p>\n<ul>\n<li>domain1.example.com</li>\n<li>domain2.example.com<pre><code>devices\nsecurity_opt\nworking_dir, entrypoint, user, hostname, domainname, \n</code></pre>mac_address, mem_limit, memswap_limit, privileged,<br>restart, stdin_open, tty, cpu_shares, cpuset,<br>read_only, volume_driver<pre><code> docker run \ncpu_shares: 73\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<p>working_dir: /code<br>entrypoint: /code/entrypoint.sh<br>user: postgresql</p>\n<p>hostname: foo<br>domainname: foo.com</p>\n<p>mem_limit: 1000000000<br>privileged: true</p>\n<p>restart: always</p>\n<p>stdin_open: true<br>tty: true<br>        keyword<br>            build<br>                Path to a directory containing a Dockerfile.<br>                build: /path/to/build/dir<br>            cap_add, cap_drop<br>                Add or drop container capabilities. See man 7 capabilities for a full list.<br>                cap_add:</p>\n<ul>\n<li>ALL</li>\n</ul>\n<p>cap_drop:</p>\n<ul>\n<li>NET_ADMIN</li>\n<li>SYS_ADMIN<pre><code>command\n    Override the default command.\n    command: bundle exec thin -p 3000\ncgroup_parent\n    Specify an optional parent cgroup for the container.\n    cgroup_parent: m-executor-abcd\ncontainer_name\n    Specify a custom container name, rather than a generated default name.\n    container_name: my-web-container\ndevices\n    List of device mappings. Uses the same format as the --device docker client create option.\n    devices:\n</code></pre></li>\n<li>/dev/ttyUSB0:/dev/ttyUSB0<pre><code>dns\n    Custom DNS servers. Can be a single value or a list.\n    dns: 8.8.8.8\n</code></pre>dns:</li>\n<li>8.8.8.8</li>\n<li>9.9.9.9<pre><code>dns_search\n    Custom DNS search domains. Can be a single value or a list.\n    dns_search: example.com\n</code></pre>dns_search:</li>\n<li>dc1.example.com</li>\n<li>dc2.example.com<pre><code>dockerfile\n    Alternate Dockerfile.\n</code></pre>Compose will use an alternate file to build with.<pre><code>    dockerfile: Dockerfile-alternate\nenv_file\n    Add environment variables from a file. Can be a single value or a list.\n</code></pre>If you have specified a Compose file with docker-compose -f FILE,<br>paths in env_file are relative to the directory that file is in.<br>Environment variables specified in environment override these values.<pre><code>env_file: .env\n</code></pre></li>\n</ul>\n<p>env_file:</p>\n<ul>\n<li>./common.env</li>\n<li>./apps/web.env</li>\n<li>/opt/secrets.env<pre><code>Compose expects each line in an env file to be in VAR=VAL format.\n</code></pre>Lines beginning with # (i.e. comments) are ignored, as are blank lines.</li>\n</ul>\n<h1 id=\"Set-Rails-Rack-environment\"><a href=\"#Set-Rails-Rack-environment\" class=\"headerlink\" title=\"Set Rails/Rack environment\"></a>Set Rails/Rack environment</h1><p>RACK_ENV=development<br>            environment<br>                Add environment variables. You can use either an array or a dictionary.<br>                Any boolean values; true, false, yes no, need to be enclosed in quotes<br> to ensure they are not converted to True or False by the YML parser.<br>                Environment variables with only a key are resolved to their values on the machine Compose is running on,<br>which can be helpful for secret or host-specific values.<br>                environment:<br>  RACK_ENV: development<br>  SHOW: true<br>  SESSION_SECRET:</p>\n<p>environment:</p>\n<ul>\n<li>RACK_ENV=development</li>\n<li>SHOW=true</li>\n<li>SESSION_SECRET<pre><code>expose\n    Expose ports without publishing them to the host machine - \n</code></pre>theyll only be accessible to linked services. Only the internal port can be specified.<pre><code>expose:\n</code></pre><ul>\n<li>3000</li>\n<li>8000<pre><code>extends\n    Extend another service, in the current file or another, optionally overriding configuration.\n</code></pre>You can use extends on any service together with other configuration keys.<br>The extends value must be a dictionary defined with a required service and an optional file key.<pre><code>extends:\n</code></pre>file: common.yml<br>service: webapp<pre><code>external_links\n    Link to containers started outside this docker-compose.yml or even outside of Compose,\n</code></pre>especially for containers that provide shared or common services.<br>external_links follow semantics similar to links when specifying both the container name and the link alias (CONTAINER:ALIAS).<pre><code>external_links:\n</code></pre></li>\n<li>redis_1</li>\n<li>project_db_1:mysql</li>\n<li>project_db_1:postgresql<pre><code>extra_hosts\n    Add hostname mappings. Use the same values as the docker client --add-host parameter.\n    extra_hosts:\n</code></pre></li>\n<li>somehost:162.242.195.82</li>\n<li>otherhost:50.31.209.229<pre><code>An entry with the ip address and hostname will be created in /etc/hosts inside containers for this service, e.g:\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<p>162.242.195.82  somehost<br>50.31.209.229   otherhost<br>            image<br>                Tag or partial image ID. Can be local or remote -<br>Compose will attempt to pull if it doesnt exist locally.<br>                image: ubuntu<br>image: orchardup/postgresql<br>image: a4bc65fd<br>            labels<br>                Add metadata to containers using Docker labels. You can use either an array or a dictionary.<br>Its recommended that you use reverse-DNS notation to prevent your labels from conflicting with those used by other software.<br>                labels:<br>  com.example.description: Accounting webapp<br>  com.example.department: Finance<br>  com.example.label-with-empty-value: </p>\n<p>labels:</p>\n<ul>\n<li>com.example.description=Accounting webapp</li>\n<li>com.example.department=Finance</li>\n<li>com.example.label-with-empty-value<pre><code>links\n    Link to containers in another service. \n</code></pre>Either specify both the service name and the link alias (SERVICE:ALIAS),<br>or just the service name (which will also be used for the alias).<pre><code>links:\n</code></pre><ul>\n<li>db</li>\n<li>db:database</li>\n<li>redis<pre><code>An entry with the alias name will be created in /etc/hosts \n</code></pre>inside containers for this service, e.g:</li>\n</ul>\n</li>\n</ul>\n<p>172.17.2.186  db<br>172.17.2.186  database<br>172.17.2.187  redis<br>            log_driver<br>                Specify a logging driver for the services containers, as with the log-driver option for docker run<br>                The default value is json-file.<br>Note: Only the json-file driver makes the logs available directly from docker-compose up and docker-compose logs.<br>Using any other driver will not print any logs.<br>                log_driver: json-file<br>log_driver: syslog<br>log_driver: none<br>            log_opt<br>                Specify logging options with log_opt for the logging driver, as with the log-opt option for docker run.<br>                log_driver: syslog<br>log_opt:<br>  syslog-address: tcp://192.168.0.42:123<br>            net<br>                Networking mode. Use the same values as the docker client net parameter.<br>                net: bridge<br>net: none<br>net: container:[name or id]<br>net: host<br>            pid<br>                pid: host<br>                Sets the PID mode to the host PID mode.<br>This turns on sharing between container and the host oprating system the PID address space.<br> Containers launched with this flag will be able to access and manipulate other containers<br> in the bare-metal machines namespace and vise-versa.<br>            ports<br>                Expose ports. Either specify both ports (HOST:CONTAINER),<br>or just the container port (a random host port will be chosen).<br>                Note: When mapping ports in the HOST:CONTAINER format,<br>you may experience erroneous results when using a container port lower than 60,<br>because YAML will parse numbers in the format xx:yy as sexagesimal (base 60).<br>For this reason, we recommend always explicitly specifying your port mappings as strings.<br>                ports:</p>\n<ul>\n<li>3000</li>\n<li>3000-3005</li>\n<li>8000:8000</li>\n<li>9090-9091:8080-8081</li>\n<li>49100:22</li>\n<li>127.0.0.1:8001:8001</li>\n<li>127.0.0.1:5000-5010:5000-5010<pre><code>security_opt\n    Override the default labeling scheme for each container.\n    security_opt:\n</code></pre><ul>\n<li>label:user:USER</li>\n<li>label:role:ROLE<pre><code>ulimits\n    Override the default ulimits for a container. \n</code></pre>You can either specify a single limit as an integer or soft/hard limits as a mapping.<pre><code>ulimits:\n</code></pre>nproc: 65535<br>nofile:<br>soft: 20000<br>hard: 40000<pre><code>volumes, volume_driver\n    Mount paths as volumes, optionally specifying a path on the host machine \n</code></pre>(HOST:CONTAINER), or an access mode (HOST:CONTAINER:ro).<pre><code>volumes:\n</code></pre></li>\n</ul>\n</li>\n<li>/var/lib/mysql</li>\n<li>./cache:/tmp/cache</li>\n<li>~/configs:/etc/configs/:ro<pre><code>You can mount a relative path on the host, which will expand relative to the director\n</code></pre>y of the Compose configuration file being used. Relative paths should always begin with . or <pre><code>If you use a volume name (instead of a volume path), you may also specify a volume_driver.\n</code></pre>volume_driver: mydriver<br>Note: No path expansion will be done if you have also specified a volume_driver.<pre><code>volumes_from\n    Mount all of the volumes from another service or container, \n</code></pre>optionally specifying read-only access(ro) or read-write(rw).<pre><code>volumes_from:\n</code></pre></li>\n<li>service_name</li>\n<li>container_name</li>\n<li>service_name:rw<pre><code>cpu_shares, cpuset, domainname, entrypoint, hostname, \n</code></pre>ipc, mac_address, mem_limit, memswap_limit, privileged,<br>read_only, restart, stdin_open, tty, user, working_dir<pre><code>Each of these is a single value, analogous to its docker run counterpart.\ncpu_shares: 73\n</code></pre>cpuset: 0,1</li>\n</ul>\n<p>entrypoint: /code/entrypoint.sh<br>user: postgresql<br>working_dir: /code</p>\n<p>domainname: foo.com<br>hostname: foo<br>ipc: host<br>mac_address: 02:42:ac:11:65:43</p>\n<p>mem_limit: 1000000000<br>memswap_limit: 2000000000<br>privileged: true</p>\n<p>restart: always</p>\n<p>read_only: true<br>stdin_open: true<br>tty: true</p>\n"},{"title":"docker core","_content":"\n# about docker\n\n\n# basic concept\n\n- [dockerfile]()\n- [image]()\n- [yaml]()\n- [file system]()\n\n- [dockerhub]()\n\n# basic component\n\n- [docker engine]()\n- [docker compose]()\n- [docker swarm]()\n\n# basic topic\n\n- [storage]()\n- [network]()\n- [security]()","source":"_posts/docker-core.md","raw":"---\ntitle: docker core\ncategories:\n- docker\ntags:\n- core\n---\n\n# about docker\n\n\n# basic concept\n\n- [dockerfile]()\n- [image]()\n- [yaml]()\n- [file system]()\n\n- [dockerhub]()\n\n# basic component\n\n- [docker engine]()\n- [docker compose]()\n- [docker swarm]()\n\n# basic topic\n\n- [storage]()\n- [network]()\n- [security]()","slug":"docker-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T06:28:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm38t001s21svt0sqa4iq","content":"<h1 id=\"about-docker\"><a href=\"#about-docker\" class=\"headerlink\" title=\"about docker\"></a>about docker</h1><h1 id=\"basic-concept\"><a href=\"#basic-concept\" class=\"headerlink\" title=\"basic concept\"></a>basic concept</h1><ul>\n<li><a href=\"\">dockerfile</a></li>\n<li><a href=\"\">image</a></li>\n<li><a href=\"\">yaml</a></li>\n<li><p><a href=\"\">file system</a></p>\n</li>\n<li><p><a href=\"\">dockerhub</a></p>\n</li>\n</ul>\n<h1 id=\"basic-component\"><a href=\"#basic-component\" class=\"headerlink\" title=\"basic component\"></a>basic component</h1><ul>\n<li><a href=\"\">docker engine</a></li>\n<li><a href=\"\">docker compose</a></li>\n<li><a href=\"\">docker swarm</a></li>\n</ul>\n<h1 id=\"basic-topic\"><a href=\"#basic-topic\" class=\"headerlink\" title=\"basic topic\"></a>basic topic</h1><ul>\n<li><a href=\"\">storage</a></li>\n<li><a href=\"\">network</a></li>\n<li><a href=\"\">security</a></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about-docker\"><a href=\"#about-docker\" class=\"headerlink\" title=\"about docker\"></a>about docker</h1><h1 id=\"basic-concept\"><a href=\"#basic-concept\" class=\"headerlink\" title=\"basic concept\"></a>basic concept</h1><ul>\n<li><a href=\"\">dockerfile</a></li>\n<li><a href=\"\">image</a></li>\n<li><a href=\"\">yaml</a></li>\n<li><p><a href=\"\">file system</a></p>\n</li>\n<li><p><a href=\"\">dockerhub</a></p>\n</li>\n</ul>\n<h1 id=\"basic-component\"><a href=\"#basic-component\" class=\"headerlink\" title=\"basic component\"></a>basic component</h1><ul>\n<li><a href=\"\">docker engine</a></li>\n<li><a href=\"\">docker compose</a></li>\n<li><a href=\"\">docker swarm</a></li>\n</ul>\n<h1 id=\"basic-topic\"><a href=\"#basic-topic\" class=\"headerlink\" title=\"basic topic\"></a>basic topic</h1><ul>\n<li><a href=\"\">storage</a></li>\n<li><a href=\"\">network</a></li>\n<li><a href=\"\">security</a></li>\n</ul>\n"},{"title":"docker cookbook","_content":"\n# docker cookbook","source":"_posts/docker-cookbook.md","raw":"---\ntitle: docker cookbook\ncategories:\n- docker\ntags:\n- cookbook\n---\n\n# docker cookbook","slug":"docker-cookbook","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T10:51:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm38y001u21svs7mji43n","content":"<h1 id=\"docker-cookbook\"><a href=\"#docker-cookbook\" class=\"headerlink\" title=\"docker cookbook\"></a>docker cookbook</h1>","excerpt":"","more":"<h1 id=\"docker-cookbook\"><a href=\"#docker-cookbook\" class=\"headerlink\" title=\"docker cookbook\"></a>docker cookbook</h1>"},{"title":"devops portal","_content":"\n# about\n\n","source":"_posts/devops--portal.md","raw":"---\ntitle: devops portal\ncategories:\n- devops\ntags:\n- portal\n---\n\n# about\n\n","slug":"devops--portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T14:26:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm391001y21svngtxbmr2","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1>"},{"title":"dockerfile","_content":"\n# about dockerfile\n\n\n# dockerfile command\n\n- point to a Dockerfile anywhere in your file system\n    \n        docker build -f /path/to/a/Dockerfile .\n\n- specify a repository and tag at which to save the new image if the build succeeds\n    \n        docker build -t shykes/myapp .\n\n# dockerfile keyword\n\n- FROM: base image\n\n- MAINTAINER\n\n        MAINTAINER ag \"allengaller@gmail.com\"\n\n- USER: set user\n\n        USER root\n\n- RUN: run system cmd\n\n        RUN apt-get update\n        RUN [\"apt-get\", \"update\"]\n        RUN apt-get install -y nginx\n        RUN touch test.txt && echo \"abc\" >> abc.txt\n\n- EXPOSE: expose port\n\n- ADD\n\n    The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the container at the path <dest>.\n    \n    pattern: ADD <src>... <dest>; ADD [\"<src>\",... \"<dest>\"]\n    add folder: ADD /webapp /opt/webapp\n    add file: ADD abc.txt /opt/\n    add network file: ADD https://www.baidu.com/img/bd_logo1.png /opt/\n\n- ENV: set env variable\n\n        ENV WEBAPP_PORT = 9090\n\n- WORKDIR: set working directory\n    \n    The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.The WORKDIR instruction can resolve environment variables previously set using ENV. You can only use environment variables explicitly set in the Dockerfile. For example:\n\n        ENV DIRPATH /path\n        WORKDIR $DIRPATH/$DIRNAME\n        RUN pwd\n\n    The output of the final pwd command in this Dockerfile would be /path/$DIRNAME.It can be used multiple times in the one Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:\n\n        WORKDIR /a\n        WORKDIR b\n        WORKDIR c\n        RUN pwd\n\n    The output of the final pwd command in this Dockerfile would be /a/b/c.\n    \n        WORKDIR /opt/\n\n- ENTRYPOINT: set boot command, append parameter to boot cmd\n    \n    An ENTRYPOINT allows you to configure a container that will run as an executable.For example, the following will start nginx with its default content, listening on port 80:\n            \n        docker run -i -t --rm -p 80:80 nginx\n    \n        ENTRYPOINT [\"ls\"]\n        ENTRYPOINT [\"ls\"]\n        CMD [\"-l\", \"-a\"]\n\n- CMD: set boot parameter\n    \n        CMD [\"ls\", \"-a\", \"-l\"]\n        CMD ls -l -a\n\n- VOLUME: set volume\n    \n        VOLUME [\"/data\", \"/var/www\"]\n\n- ONBUILD: trigger for child image\n    \n        ONBUILD ADD . /app/src\n        ONBUILD RUN echo \"on build excuted\" >> onbuild.txt\n\n- ARG\n\n- STOPSIGNAL\n\n# best practice [link](https://docs.docker.com/engine/articles/dockerfile_best-practices/)\n\n- Containers should be ephemeral\n\n    The container produced by the image your Dockerfile defines should be as ephemeral as possible.By ephemeral, we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration.\n\n- Use a .dockerignore file\n\n    In most cases, its best to put each Dockerfile in an empty directory. Then, add to that directory only the files needed for building the Dockerfile. To increase the builds performance, you can exclude files and directories by adding a .dockerignore file to that directory as well. This file supports exclusion patterns similar to .gitignore files. For information on creating one, see the .dockerignore file.\n    \n- Avoid installing unnecessary packages\n\n    In order to reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be nice to have. For example, you dont need to include a text editor in a database image.\n\n- Run only one process per container\n\n    In almost all cases, you should only run a single process in a single container. Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. If that service depends on another service, make use of container linking.\n\n- Minimize the number of layers\n\n    You need to find the balance between readability (and thus long-term maintainability) of the Dockerfile and minimizing the number of layers it uses. Be strategic and cautious about the number of layers you use.\n\n- Sort multi-line arguments\n\n    Heres an example from the buildpack-deps image:\n\n    RUN apt-get update && apt-get install -y \\\n      bzr \\\n      cvs \\\n      git \\\n      mercurial \\\n      subversion\n\n- Build cache\n\n# .dockerignore\n\n    */temp*\n    */*/temp*\n    temp?\n","source":"_posts/docker-dockerfile-detail.md","raw":"---\ntitle: dockerfile\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about dockerfile\n\n\n# dockerfile command\n\n- point to a Dockerfile anywhere in your file system\n    \n        docker build -f /path/to/a/Dockerfile .\n\n- specify a repository and tag at which to save the new image if the build succeeds\n    \n        docker build -t shykes/myapp .\n\n# dockerfile keyword\n\n- FROM: base image\n\n- MAINTAINER\n\n        MAINTAINER ag \"allengaller@gmail.com\"\n\n- USER: set user\n\n        USER root\n\n- RUN: run system cmd\n\n        RUN apt-get update\n        RUN [\"apt-get\", \"update\"]\n        RUN apt-get install -y nginx\n        RUN touch test.txt && echo \"abc\" >> abc.txt\n\n- EXPOSE: expose port\n\n- ADD\n\n    The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the container at the path <dest>.\n    \n    pattern: ADD <src>... <dest>; ADD [\"<src>\",... \"<dest>\"]\n    add folder: ADD /webapp /opt/webapp\n    add file: ADD abc.txt /opt/\n    add network file: ADD https://www.baidu.com/img/bd_logo1.png /opt/\n\n- ENV: set env variable\n\n        ENV WEBAPP_PORT = 9090\n\n- WORKDIR: set working directory\n    \n    The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.The WORKDIR instruction can resolve environment variables previously set using ENV. You can only use environment variables explicitly set in the Dockerfile. For example:\n\n        ENV DIRPATH /path\n        WORKDIR $DIRPATH/$DIRNAME\n        RUN pwd\n\n    The output of the final pwd command in this Dockerfile would be /path/$DIRNAME.It can be used multiple times in the one Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:\n\n        WORKDIR /a\n        WORKDIR b\n        WORKDIR c\n        RUN pwd\n\n    The output of the final pwd command in this Dockerfile would be /a/b/c.\n    \n        WORKDIR /opt/\n\n- ENTRYPOINT: set boot command, append parameter to boot cmd\n    \n    An ENTRYPOINT allows you to configure a container that will run as an executable.For example, the following will start nginx with its default content, listening on port 80:\n            \n        docker run -i -t --rm -p 80:80 nginx\n    \n        ENTRYPOINT [\"ls\"]\n        ENTRYPOINT [\"ls\"]\n        CMD [\"-l\", \"-a\"]\n\n- CMD: set boot parameter\n    \n        CMD [\"ls\", \"-a\", \"-l\"]\n        CMD ls -l -a\n\n- VOLUME: set volume\n    \n        VOLUME [\"/data\", \"/var/www\"]\n\n- ONBUILD: trigger for child image\n    \n        ONBUILD ADD . /app/src\n        ONBUILD RUN echo \"on build excuted\" >> onbuild.txt\n\n- ARG\n\n- STOPSIGNAL\n\n# best practice [link](https://docs.docker.com/engine/articles/dockerfile_best-practices/)\n\n- Containers should be ephemeral\n\n    The container produced by the image your Dockerfile defines should be as ephemeral as possible.By ephemeral, we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration.\n\n- Use a .dockerignore file\n\n    In most cases, its best to put each Dockerfile in an empty directory. Then, add to that directory only the files needed for building the Dockerfile. To increase the builds performance, you can exclude files and directories by adding a .dockerignore file to that directory as well. This file supports exclusion patterns similar to .gitignore files. For information on creating one, see the .dockerignore file.\n    \n- Avoid installing unnecessary packages\n\n    In order to reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be nice to have. For example, you dont need to include a text editor in a database image.\n\n- Run only one process per container\n\n    In almost all cases, you should only run a single process in a single container. Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. If that service depends on another service, make use of container linking.\n\n- Minimize the number of layers\n\n    You need to find the balance between readability (and thus long-term maintainability) of the Dockerfile and minimizing the number of layers it uses. Be strategic and cautious about the number of layers you use.\n\n- Sort multi-line arguments\n\n    Heres an example from the buildpack-deps image:\n\n    RUN apt-get update && apt-get install -y \\\n      bzr \\\n      cvs \\\n      git \\\n      mercurial \\\n      subversion\n\n- Build cache\n\n# .dockerignore\n\n    */temp*\n    */*/temp*\n    temp?\n","slug":"docker-dockerfile-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T11:46:41.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm394002121svo7zb0zb3","content":"<h1 id=\"about-dockerfile\"><a href=\"#about-dockerfile\" class=\"headerlink\" title=\"about dockerfile\"></a>about dockerfile</h1><h1 id=\"dockerfile-command\"><a href=\"#dockerfile-command\" class=\"headerlink\" title=\"dockerfile command\"></a>dockerfile command</h1><ul>\n<li><p>point to a Dockerfile anywhere in your file system</p>\n<pre><code>docker build -f /path/to/a/Dockerfile .\n</code></pre></li>\n<li><p>specify a repository and tag at which to save the new image if the build succeeds</p>\n<pre><code>docker build -t shykes/myapp .\n</code></pre></li>\n</ul>\n<h1 id=\"dockerfile-keyword\"><a href=\"#dockerfile-keyword\" class=\"headerlink\" title=\"dockerfile keyword\"></a>dockerfile keyword</h1><ul>\n<li><p>FROM: base image</p>\n</li>\n<li><p>MAINTAINER</p>\n<pre><code>MAINTAINER ag &quot;allengaller@gmail.com&quot;\n</code></pre></li>\n<li><p>USER: set user</p>\n<pre><code>USER root\n</code></pre></li>\n<li><p>RUN: run system cmd</p>\n<pre><code>RUN apt-get update\nRUN [&quot;apt-get&quot;, &quot;update&quot;]\nRUN apt-get install -y nginx\nRUN touch test.txt &amp;&amp; echo &quot;abc&quot; &gt;&gt; abc.txt\n</code></pre></li>\n<li><p>EXPOSE: expose port</p>\n</li>\n<li><p>ADD</p>\n<p>  The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the container at the path <dest>.</dest></src></p>\n<p>  pattern: ADD <src> <dest>; ADD [<src>, <dest>]<br>  add folder: ADD /webapp /opt/webapp<br>  add file: ADD abc.txt /opt/<br>  add network file: ADD <a href=\"https://www.baidu.com/img/bd_logo1.png\" target=\"_blank\" rel=\"external\">https://www.baidu.com/img/bd_logo1.png</a> /opt/</dest></src></dest></src></p>\n</li>\n<li><p>ENV: set env variable</p>\n<pre><code>ENV WEBAPP_PORT = 9090\n</code></pre></li>\n<li><p>WORKDIR: set working directory</p>\n<p>  The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.The WORKDIR instruction can resolve environment variables previously set using ENV. You can only use environment variables explicitly set in the Dockerfile. For example:</p>\n<pre><code>ENV DIRPATH /path\nWORKDIR $DIRPATH/$DIRNAME\nRUN pwd\n</code></pre><p>  The output of the final pwd command in this Dockerfile would be /path/$DIRNAME.It can be used multiple times in the one Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:</p>\n<pre><code>WORKDIR /a\nWORKDIR b\nWORKDIR c\nRUN pwd\n</code></pre><p>  The output of the final pwd command in this Dockerfile would be /a/b/c.</p>\n<pre><code>WORKDIR /opt/\n</code></pre></li>\n<li><p>ENTRYPOINT: set boot command, append parameter to boot cmd</p>\n<p>  An ENTRYPOINT allows you to configure a container that will run as an executable.For example, the following will start nginx with its default content, listening on port 80:</p>\n<pre><code>docker run -i -t --rm -p 80:80 nginx\n\nENTRYPOINT [&quot;ls&quot;]\nENTRYPOINT [&quot;ls&quot;]\nCMD [&quot;-l&quot;, &quot;-a&quot;]\n</code></pre></li>\n<li><p>CMD: set boot parameter</p>\n<pre><code>CMD [&quot;ls&quot;, &quot;-a&quot;, &quot;-l&quot;]\nCMD ls -l -a\n</code></pre></li>\n<li><p>VOLUME: set volume</p>\n<pre><code>VOLUME [&quot;/data&quot;, &quot;/var/www&quot;]\n</code></pre></li>\n<li><p>ONBUILD: trigger for child image</p>\n<pre><code>ONBUILD ADD . /app/src\nONBUILD RUN echo &quot;on build excuted&quot; &gt;&gt; onbuild.txt\n</code></pre></li>\n<li><p>ARG</p>\n</li>\n<li><p>STOPSIGNAL</p>\n</li>\n</ul>\n<h1 id=\"best-practice-link\"><a href=\"#best-practice-link\" class=\"headerlink\" title=\"best practice link\"></a>best practice <a href=\"https://docs.docker.com/engine/articles/dockerfile_best-practices/\" target=\"_blank\" rel=\"external\">link</a></h1><ul>\n<li><p>Containers should be ephemeral</p>\n<p>  The container produced by the image your Dockerfile defines should be as ephemeral as possible.By ephemeral, we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration.</p>\n</li>\n<li><p>Use a .dockerignore file</p>\n<p>  In most cases, its best to put each Dockerfile in an empty directory. Then, add to that directory only the files needed for building the Dockerfile. To increase the builds performance, you can exclude files and directories by adding a .dockerignore file to that directory as well. This file supports exclusion patterns similar to .gitignore files. For information on creating one, see the .dockerignore file.</p>\n</li>\n<li><p>Avoid installing unnecessary packages</p>\n<p>  In order to reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be nice to have. For example, you dont need to include a text editor in a database image.</p>\n</li>\n<li><p>Run only one process per container</p>\n<p>  In almost all cases, you should only run a single process in a single container. Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. If that service depends on another service, make use of container linking.</p>\n</li>\n<li><p>Minimize the number of layers</p>\n<p>  You need to find the balance between readability (and thus long-term maintainability) of the Dockerfile and minimizing the number of layers it uses. Be strategic and cautious about the number of layers you use.</p>\n</li>\n<li><p>Sort multi-line arguments</p>\n<p>  Heres an example from the buildpack-deps image:</p>\n<p>  RUN apt-get update &amp;&amp; apt-get install -y \\</p>\n<pre><code>bzr \\\ncvs \\\ngit \\\nmercurial \\\nsubversion\n</code></pre></li>\n<li><p>Build cache</p>\n</li>\n</ul>\n<h1 id=\"dockerignore\"><a href=\"#dockerignore\" class=\"headerlink\" title=\".dockerignore\"></a>.dockerignore</h1><pre><code>*/temp*\n*/*/temp*\ntemp?\n</code></pre>","excerpt":"","more":"<h1 id=\"about-dockerfile\"><a href=\"#about-dockerfile\" class=\"headerlink\" title=\"about dockerfile\"></a>about dockerfile</h1><h1 id=\"dockerfile-command\"><a href=\"#dockerfile-command\" class=\"headerlink\" title=\"dockerfile command\"></a>dockerfile command</h1><ul>\n<li><p>point to a Dockerfile anywhere in your file system</p>\n<pre><code>docker build -f /path/to/a/Dockerfile .\n</code></pre></li>\n<li><p>specify a repository and tag at which to save the new image if the build succeeds</p>\n<pre><code>docker build -t shykes/myapp .\n</code></pre></li>\n</ul>\n<h1 id=\"dockerfile-keyword\"><a href=\"#dockerfile-keyword\" class=\"headerlink\" title=\"dockerfile keyword\"></a>dockerfile keyword</h1><ul>\n<li><p>FROM: base image</p>\n</li>\n<li><p>MAINTAINER</p>\n<pre><code>MAINTAINER ag &quot;allengaller@gmail.com&quot;\n</code></pre></li>\n<li><p>USER: set user</p>\n<pre><code>USER root\n</code></pre></li>\n<li><p>RUN: run system cmd</p>\n<pre><code>RUN apt-get update\nRUN [&quot;apt-get&quot;, &quot;update&quot;]\nRUN apt-get install -y nginx\nRUN touch test.txt &amp;&amp; echo &quot;abc&quot; &gt;&gt; abc.txt\n</code></pre></li>\n<li><p>EXPOSE: expose port</p>\n</li>\n<li><p>ADD</p>\n<p>  The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the container at the path <dest>.</p>\n<p>  pattern: ADD <src> <dest>; ADD [<src>, <dest>]<br>  add folder: ADD /webapp /opt/webapp<br>  add file: ADD abc.txt /opt/<br>  add network file: ADD <a href=\"https://www.baidu.com/img/bd_logo1.png\">https://www.baidu.com/img/bd_logo1.png</a> /opt/</p>\n</li>\n<li><p>ENV: set env variable</p>\n<pre><code>ENV WEBAPP_PORT = 9090\n</code></pre></li>\n<li><p>WORKDIR: set working directory</p>\n<p>  The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.The WORKDIR instruction can resolve environment variables previously set using ENV. You can only use environment variables explicitly set in the Dockerfile. For example:</p>\n<pre><code>ENV DIRPATH /path\nWORKDIR $DIRPATH/$DIRNAME\nRUN pwd\n</code></pre><p>  The output of the final pwd command in this Dockerfile would be /path/$DIRNAME.It can be used multiple times in the one Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:</p>\n<pre><code>WORKDIR /a\nWORKDIR b\nWORKDIR c\nRUN pwd\n</code></pre><p>  The output of the final pwd command in this Dockerfile would be /a/b/c.</p>\n<pre><code>WORKDIR /opt/\n</code></pre></li>\n<li><p>ENTRYPOINT: set boot command, append parameter to boot cmd</p>\n<p>  An ENTRYPOINT allows you to configure a container that will run as an executable.For example, the following will start nginx with its default content, listening on port 80:</p>\n<pre><code>docker run -i -t --rm -p 80:80 nginx\n\nENTRYPOINT [&quot;ls&quot;]\nENTRYPOINT [&quot;ls&quot;]\nCMD [&quot;-l&quot;, &quot;-a&quot;]\n</code></pre></li>\n<li><p>CMD: set boot parameter</p>\n<pre><code>CMD [&quot;ls&quot;, &quot;-a&quot;, &quot;-l&quot;]\nCMD ls -l -a\n</code></pre></li>\n<li><p>VOLUME: set volume</p>\n<pre><code>VOLUME [&quot;/data&quot;, &quot;/var/www&quot;]\n</code></pre></li>\n<li><p>ONBUILD: trigger for child image</p>\n<pre><code>ONBUILD ADD . /app/src\nONBUILD RUN echo &quot;on build excuted&quot; &gt;&gt; onbuild.txt\n</code></pre></li>\n<li><p>ARG</p>\n</li>\n<li><p>STOPSIGNAL</p>\n</li>\n</ul>\n<h1 id=\"best-practice-link\"><a href=\"#best-practice-link\" class=\"headerlink\" title=\"best practice link\"></a>best practice <a href=\"https://docs.docker.com/engine/articles/dockerfile_best-practices/\">link</a></h1><ul>\n<li><p>Containers should be ephemeral</p>\n<p>  The container produced by the image your Dockerfile defines should be as ephemeral as possible.By ephemeral, we mean that it can be stopped and destroyed and a new one built and put in place with an absolute minimum of set-up and configuration.</p>\n</li>\n<li><p>Use a .dockerignore file</p>\n<p>  In most cases, its best to put each Dockerfile in an empty directory. Then, add to that directory only the files needed for building the Dockerfile. To increase the builds performance, you can exclude files and directories by adding a .dockerignore file to that directory as well. This file supports exclusion patterns similar to .gitignore files. For information on creating one, see the .dockerignore file.</p>\n</li>\n<li><p>Avoid installing unnecessary packages</p>\n<p>  In order to reduce complexity, dependencies, file sizes, and build times, you should avoid installing extra or unnecessary packages just because they might be nice to have. For example, you dont need to include a text editor in a database image.</p>\n</li>\n<li><p>Run only one process per container</p>\n<p>  In almost all cases, you should only run a single process in a single container. Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. If that service depends on another service, make use of container linking.</p>\n</li>\n<li><p>Minimize the number of layers</p>\n<p>  You need to find the balance between readability (and thus long-term maintainability) of the Dockerfile and minimizing the number of layers it uses. Be strategic and cautious about the number of layers you use.</p>\n</li>\n<li><p>Sort multi-line arguments</p>\n<p>  Heres an example from the buildpack-deps image:</p>\n<p>  RUN apt-get update &amp;&amp; apt-get install -y \\</p>\n<pre><code>bzr \\\ncvs \\\ngit \\\nmercurial \\\nsubversion\n</code></pre></li>\n<li><p>Build cache</p>\n</li>\n</ul>\n<h1 id=\"dockerignore\"><a href=\"#dockerignore\" class=\"headerlink\" title=\".dockerignore\"></a>.dockerignore</h1><pre><code>*/temp*\n*/*/temp*\ntemp?\n</code></pre>"},{"title":"dockerhub","_content":"\n# dockerhub\n\n## about dockerhub [link](https://hub.docker.com)\n\n- types:\n\n        official image\n        user image\n\n## command\n\n- docker login\n\n        comfig: cat ~/.dockercfg\n\n- build: Automated Build/Trusted Build\n    \n- registry\n\n        docker pull registry\n        docker run -p 5000:5000 -d -i -t registry\n        docker commit 3ie9djk 127.0.0.1:5000/my_image:v1\n            [registry_host: registry_port\\image_name:image_tag]\n        docker push 127.0.0.1:5000/my_image:v1","source":"_posts/docker-dockerhub-detail.md","raw":"---\ntitle: dockerhub\ncategories:\n- docker\ntags:\n- detail\n---\n\n# dockerhub\n\n## about dockerhub [link](https://hub.docker.com)\n\n- types:\n\n        official image\n        user image\n\n## command\n\n- docker login\n\n        comfig: cat ~/.dockercfg\n\n- build: Automated Build/Trusted Build\n    \n- registry\n\n        docker pull registry\n        docker run -p 5000:5000 -d -i -t registry\n        docker commit 3ie9djk 127.0.0.1:5000/my_image:v1\n            [registry_host: registry_port\\image_name:image_tag]\n        docker push 127.0.0.1:5000/my_image:v1","slug":"docker-dockerhub-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T11:46:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm396002521svmkmo7uob","content":"<h1 id=\"dockerhub\"><a href=\"#dockerhub\" class=\"headerlink\" title=\"dockerhub\"></a>dockerhub</h1><h2 id=\"about-dockerhub-link\"><a href=\"#about-dockerhub-link\" class=\"headerlink\" title=\"about dockerhub link\"></a>about dockerhub <a href=\"https://hub.docker.com\" target=\"_blank\" rel=\"external\">link</a></h2><ul>\n<li><p>types:</p>\n<pre><code>official image\nuser image\n</code></pre></li>\n</ul>\n<h2 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h2><ul>\n<li><p>docker login</p>\n<pre><code>comfig: cat ~/.dockercfg\n</code></pre></li>\n<li><p>build: Automated Build/Trusted Build</p>\n</li>\n<li><p>registry</p>\n<pre><code>docker pull registry\ndocker run -p 5000:5000 -d -i -t registry\ndocker commit 3ie9djk 127.0.0.1:5000/my_image:v1\n    [registry_host: registry_port\\image_name:image_tag]\ndocker push 127.0.0.1:5000/my_image:v1\n</code></pre></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"dockerhub\"><a href=\"#dockerhub\" class=\"headerlink\" title=\"dockerhub\"></a>dockerhub</h1><h2 id=\"about-dockerhub-link\"><a href=\"#about-dockerhub-link\" class=\"headerlink\" title=\"about dockerhub link\"></a>about dockerhub <a href=\"https://hub.docker.com\">link</a></h2><ul>\n<li><p>types:</p>\n<pre><code>official image\nuser image\n</code></pre></li>\n</ul>\n<h2 id=\"command\"><a href=\"#command\" class=\"headerlink\" title=\"command\"></a>command</h2><ul>\n<li><p>docker login</p>\n<pre><code>comfig: cat ~/.dockercfg\n</code></pre></li>\n<li><p>build: Automated Build/Trusted Build</p>\n</li>\n<li><p>registry</p>\n<pre><code>docker pull registry\ndocker run -p 5000:5000 -d -i -t registry\ndocker commit 3ie9djk 127.0.0.1:5000/my_image:v1\n    [registry_host: registry_port\\image_name:image_tag]\ndocker push 127.0.0.1:5000/my_image:v1\n</code></pre></li>\n</ul>\n"},{"title":"docker engine","_content":"\n## about\n\n## docker engine command\n\n- tips\n\n    Delete all containers:\n        \n        docker rm $(docker ps -a -q)\n\n    Delete all images:\n        \n        docker rmi $(docker images -q)\n\n- env\n\n    - info\n    \n    - version\n\n- life-cycle\n\n    - create:  (ini: stop)\n\n            --restart: check for exit code then restart container; always or on-failure; on-failure:5 restart 5 times max\n\n            sudo docker run --restart=always --name docker_restart -d ubuntu /bin/sh -c \"while true;do echo hello world;sleep 1;done\"\n\n    - exec: exec cmd insid container\n\n            sudo docker exec -d daemon_dave touch /etc/new_config_file\n            sudo docker exec -t -i daemon_dave /bin/bash\n\n    - kill: send SIGKILL signal to container process\n    \n    - pause\n\n    - restart\n\n    - rm: cannot remove a running container; docker stop or kill first or docker rm -f bad_ubuntu\n        \n        -q: list only container ids;\n        delete all container at once:\n            \n            docker rm `docker ps -a -q`\n\n    - run: [reference](https://docs.docker.com/engine/reference/run/);(ini: run); \n\n        equals: docker create & docker start\n\n        2 types of container\n        - interactive\n            -i: STDIN\n            -t: open terminal\n            exit?: docker stop or kill;exit\n\n                sudo docker run -i -t --name=inspect_shell ubuntu /bin/bash\n                inspect_shell: container name\n                base image: ubuntu\n                command: /bin/bash\n                file system: image+writable layer\n                network: virtual network interface bridge to host & set a IP\n        \n        - daemon: -d\n            exit?: docker stop or kill\n            \n                sudo docker run --name daemon_while -d ubuntu /bin/sh -c \"while true; do echo hello world; sleep 1; done\"\n            \n                return token\n            \n                docker ps\n\n    - start: start existing container\n            \n            sudo docker start inspect_shell or cid\n\n    - stop: works for both interactive and daemon container;send SIGTERM signal to container process\n\n            sudo docker stop daemon_while\n            sudo docker stop s39c938dj34489d\n        \n    - unpause\n\n- registry\n\n    - login\n    \n    - logout\n    \n    - pull\n    \n    - push\n    \n    - search\n\n- image\n\n    - build\n    \n    - images\n    \n    - import:             \n\n            cat my_container.rar | sudo docker import - imported:container\n            repository: imported, tag: container\n            docker import url res:tag\n\n    - load\n    \n    - rmi\n    \n    - save\n    \n    - tag\n    \n    - commit\n\n- container\n\n    - attach: attach terminal to interactive container\n    \n    - export\n\n            sudo docker run -i -t --nam=inspect_import ubuntu /bin/bash\n            #... do something\n            sudo docker export inspect_import > my_container.tar\n\n    - inspect: check out the configuration\n\n            sudo docker inspect daemon_dave\n\n        -f or --format:\n\n            sudo docker inspect --format='{{ .State.Running }}' daemon_dave\n    \n    - port\n    \n    - ps: checkout existing container\n\n        -a: all\n            Exited(0): exit\n        -l: latest container\n        -n=x: latest x container\n\n    - rename\n    \n    - stats\n    \n    - top: check out UID PID PPID...\n        \n            sudo docker run -d --name=\"daemon_top\" ubuntu /bin/bash -c 'while true;do sleep 1;done'\n        \n        2 process:\n        \n            sudo docker top daemon_top\n\n    - wait\n    \n    - cp\n    \n    - diff\n\n- sys log\n\n    - events\n    \n    - history\n    \n    - logs\n\n        -f: realtime\n        --tail=x: last x line\n                \n            sudo docker logs -f --tail=5 -t daemon_logs\n\n- other\n\n    - docker daemon: [link](https://docs.docker.com/engine/reference/commandline/daemon/), A self-sufficient runtime for linux containers.\n            \n        The Docker daemon can listen for Docker Remote API requests via three different types of Socket: unix, tcp, and fd.\n        By default, a unix domain socket (or IPC socket) is created at /var/run/docker.sock, requiring either root permission, or docker group membership.","source":"_posts/docker-engine-detail.md","raw":"---\ntitle: docker engine\ncategories:\n- docker\ntags:\n- detail\n---\n\n## about\n\n## docker engine command\n\n- tips\n\n    Delete all containers:\n        \n        docker rm $(docker ps -a -q)\n\n    Delete all images:\n        \n        docker rmi $(docker images -q)\n\n- env\n\n    - info\n    \n    - version\n\n- life-cycle\n\n    - create:  (ini: stop)\n\n            --restart: check for exit code then restart container; always or on-failure; on-failure:5 restart 5 times max\n\n            sudo docker run --restart=always --name docker_restart -d ubuntu /bin/sh -c \"while true;do echo hello world;sleep 1;done\"\n\n    - exec: exec cmd insid container\n\n            sudo docker exec -d daemon_dave touch /etc/new_config_file\n            sudo docker exec -t -i daemon_dave /bin/bash\n\n    - kill: send SIGKILL signal to container process\n    \n    - pause\n\n    - restart\n\n    - rm: cannot remove a running container; docker stop or kill first or docker rm -f bad_ubuntu\n        \n        -q: list only container ids;\n        delete all container at once:\n            \n            docker rm `docker ps -a -q`\n\n    - run: [reference](https://docs.docker.com/engine/reference/run/);(ini: run); \n\n        equals: docker create & docker start\n\n        2 types of container\n        - interactive\n            -i: STDIN\n            -t: open terminal\n            exit?: docker stop or kill;exit\n\n                sudo docker run -i -t --name=inspect_shell ubuntu /bin/bash\n                inspect_shell: container name\n                base image: ubuntu\n                command: /bin/bash\n                file system: image+writable layer\n                network: virtual network interface bridge to host & set a IP\n        \n        - daemon: -d\n            exit?: docker stop or kill\n            \n                sudo docker run --name daemon_while -d ubuntu /bin/sh -c \"while true; do echo hello world; sleep 1; done\"\n            \n                return token\n            \n                docker ps\n\n    - start: start existing container\n            \n            sudo docker start inspect_shell or cid\n\n    - stop: works for both interactive and daemon container;send SIGTERM signal to container process\n\n            sudo docker stop daemon_while\n            sudo docker stop s39c938dj34489d\n        \n    - unpause\n\n- registry\n\n    - login\n    \n    - logout\n    \n    - pull\n    \n    - push\n    \n    - search\n\n- image\n\n    - build\n    \n    - images\n    \n    - import:             \n\n            cat my_container.rar | sudo docker import - imported:container\n            repository: imported, tag: container\n            docker import url res:tag\n\n    - load\n    \n    - rmi\n    \n    - save\n    \n    - tag\n    \n    - commit\n\n- container\n\n    - attach: attach terminal to interactive container\n    \n    - export\n\n            sudo docker run -i -t --nam=inspect_import ubuntu /bin/bash\n            #... do something\n            sudo docker export inspect_import > my_container.tar\n\n    - inspect: check out the configuration\n\n            sudo docker inspect daemon_dave\n\n        -f or --format:\n\n            sudo docker inspect --format='{{ .State.Running }}' daemon_dave\n    \n    - port\n    \n    - ps: checkout existing container\n\n        -a: all\n            Exited(0): exit\n        -l: latest container\n        -n=x: latest x container\n\n    - rename\n    \n    - stats\n    \n    - top: check out UID PID PPID...\n        \n            sudo docker run -d --name=\"daemon_top\" ubuntu /bin/bash -c 'while true;do sleep 1;done'\n        \n        2 process:\n        \n            sudo docker top daemon_top\n\n    - wait\n    \n    - cp\n    \n    - diff\n\n- sys log\n\n    - events\n    \n    - history\n    \n    - logs\n\n        -f: realtime\n        --tail=x: last x line\n                \n            sudo docker logs -f --tail=5 -t daemon_logs\n\n- other\n\n    - docker daemon: [link](https://docs.docker.com/engine/reference/commandline/daemon/), A self-sufficient runtime for linux containers.\n            \n        The Docker daemon can listen for Docker Remote API requests via three different types of Socket: unix, tcp, and fd.\n        By default, a unix domain socket (or IPC socket) is created at /var/run/docker.sock, requiring either root permission, or docker group membership.","slug":"docker-engine-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T12:20:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm39a002821svvdj89we5","content":"<h2 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h2><h2 id=\"docker-engine-command\"><a href=\"#docker-engine-command\" class=\"headerlink\" title=\"docker engine command\"></a>docker engine command</h2><ul>\n<li><p>tips</p>\n<p>  Delete all containers:</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre><p>  Delete all images:</p>\n<pre><code>docker rmi $(docker images -q)\n</code></pre></li>\n<li><p>env</p>\n<ul>\n<li><p>info</p>\n</li>\n<li><p>version</p>\n</li>\n</ul>\n</li>\n<li><p>life-cycle</p>\n<ul>\n<li><p>create:  (ini: stop)</p>\n<pre><code>--restart: check for exit code then restart container; always or on-failure; on-failure:5 restart 5 times max\n\nsudo docker run --restart=always --name docker_restart -d ubuntu /bin/sh -c &quot;while true;do echo hello world;sleep 1;done&quot;\n</code></pre></li>\n<li><p>exec: exec cmd insid container</p>\n<pre><code>sudo docker exec -d daemon_dave touch /etc/new_config_file\nsudo docker exec -t -i daemon_dave /bin/bash\n</code></pre></li>\n<li><p>kill: send SIGKILL signal to container process</p>\n</li>\n<li><p>pause</p>\n</li>\n<li><p>restart</p>\n</li>\n<li><p>rm: cannot remove a running container; docker stop or kill first or docker rm -f bad_ubuntu</p>\n<p>  -q: list only container ids;<br>  delete all container at once:</p>\n<pre><code>docker rm `docker ps -a -q`\n</code></pre></li>\n<li><p>run: <a href=\"https://docs.docker.com/engine/reference/run/\" target=\"_blank\" rel=\"external\">reference</a>;(ini: run); </p>\n<p>  equals: docker create &amp; docker start</p>\n<p>  2 types of container</p>\n<ul>\n<li><p>interactive<br>  -i: STDIN<br>  -t: open terminal<br>  exit?: docker stop or kill;exit</p>\n<pre><code>sudo docker run -i -t --name=inspect_shell ubuntu /bin/bash\ninspect_shell: container name\nbase image: ubuntu\ncommand: /bin/bash\nfile system: image+writable layer\nnetwork: virtual network interface bridge to host &amp; set a IP\n</code></pre></li>\n<li><p>daemon: -d<br>  exit?: docker stop or kill</p>\n<pre><code>sudo docker run --name daemon_while -d ubuntu /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;\n\nreturn token\n\ndocker ps\n</code></pre></li>\n</ul>\n</li>\n<li><p>start: start existing container</p>\n<pre><code>sudo docker start inspect_shell or cid\n</code></pre></li>\n<li><p>stop: works for both interactive and daemon container;send SIGTERM signal to container process</p>\n<pre><code>sudo docker stop daemon_while\nsudo docker stop s39c938dj34489d\n</code></pre></li>\n<li><p>unpause</p>\n</li>\n</ul>\n</li>\n<li><p>registry</p>\n<ul>\n<li><p>login</p>\n</li>\n<li><p>logout</p>\n</li>\n<li><p>pull</p>\n</li>\n<li><p>push</p>\n</li>\n<li><p>search</p>\n</li>\n</ul>\n</li>\n<li><p>image</p>\n<ul>\n<li><p>build</p>\n</li>\n<li><p>images</p>\n</li>\n<li><p>import:             </p>\n<pre><code>cat my_container.rar | sudo docker import - imported:container\nrepository: imported, tag: container\ndocker import url res:tag\n</code></pre></li>\n<li><p>load</p>\n</li>\n<li><p>rmi</p>\n</li>\n<li><p>save</p>\n</li>\n<li><p>tag</p>\n</li>\n<li><p>commit</p>\n</li>\n</ul>\n</li>\n<li><p>container</p>\n<ul>\n<li><p>attach: attach terminal to interactive container</p>\n</li>\n<li><p>export</p>\n<pre><code>sudo docker run -i -t --nam=inspect_import ubuntu /bin/bash\n#... do something\nsudo docker export inspect_import &gt; my_container.tar\n</code></pre></li>\n<li><p>inspect: check out the configuration</p>\n<pre><code>sudo docker inspect daemon_dave\n</code></pre><p>  -f or format:</p>\n<pre><code>sudo docker inspect --format=&apos;{{ .State.Running }}&apos; daemon_dave\n</code></pre></li>\n<li><p>port</p>\n</li>\n<li><p>ps: checkout existing container</p>\n<p>  -a: all</p>\n<pre><code>Exited(0): exit\n</code></pre><p>  -l: latest container<br>  -n=x: latest x container</p>\n</li>\n<li><p>rename</p>\n</li>\n<li><p>stats</p>\n</li>\n<li><p>top: check out UID PID PPID</p>\n<pre><code>sudo docker run -d --name=&quot;daemon_top&quot; ubuntu /bin/bash -c &apos;while true;do sleep 1;done&apos;\n</code></pre><p>  2 process:</p>\n<pre><code>sudo docker top daemon_top\n</code></pre></li>\n<li><p>wait</p>\n</li>\n<li><p>cp</p>\n</li>\n<li><p>diff</p>\n</li>\n</ul>\n</li>\n<li><p>sys log</p>\n<ul>\n<li><p>events</p>\n</li>\n<li><p>history</p>\n</li>\n<li><p>logs</p>\n<p>  -f: realtime<br>  tail=x: last x line</p>\n<pre><code>sudo docker logs -f --tail=5 -t daemon_logs\n</code></pre></li>\n</ul>\n</li>\n<li><p>other</p>\n<ul>\n<li><p>docker daemon: <a href=\"https://docs.docker.com/engine/reference/commandline/daemon/\" target=\"_blank\" rel=\"external\">link</a>, A self-sufficient runtime for linux containers.</p>\n<p>  The Docker daemon can listen for Docker Remote API requests via three different types of Socket: unix, tcp, and fd.<br>  By default, a unix domain socket (or IPC socket) is created at /var/run/docker.sock, requiring either root permission, or docker group membership.</p>\n</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h2 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h2><h2 id=\"docker-engine-command\"><a href=\"#docker-engine-command\" class=\"headerlink\" title=\"docker engine command\"></a>docker engine command</h2><ul>\n<li><p>tips</p>\n<p>  Delete all containers:</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre><p>  Delete all images:</p>\n<pre><code>docker rmi $(docker images -q)\n</code></pre></li>\n<li><p>env</p>\n<ul>\n<li><p>info</p>\n</li>\n<li><p>version</p>\n</li>\n</ul>\n</li>\n<li><p>life-cycle</p>\n<ul>\n<li><p>create:  (ini: stop)</p>\n<pre><code>--restart: check for exit code then restart container; always or on-failure; on-failure:5 restart 5 times max\n\nsudo docker run --restart=always --name docker_restart -d ubuntu /bin/sh -c &quot;while true;do echo hello world;sleep 1;done&quot;\n</code></pre></li>\n<li><p>exec: exec cmd insid container</p>\n<pre><code>sudo docker exec -d daemon_dave touch /etc/new_config_file\nsudo docker exec -t -i daemon_dave /bin/bash\n</code></pre></li>\n<li><p>kill: send SIGKILL signal to container process</p>\n</li>\n<li><p>pause</p>\n</li>\n<li><p>restart</p>\n</li>\n<li><p>rm: cannot remove a running container; docker stop or kill first or docker rm -f bad_ubuntu</p>\n<p>  -q: list only container ids;<br>  delete all container at once:</p>\n<pre><code>docker rm `docker ps -a -q`\n</code></pre></li>\n<li><p>run: <a href=\"https://docs.docker.com/engine/reference/run/\">reference</a>;(ini: run); </p>\n<p>  equals: docker create &amp; docker start</p>\n<p>  2 types of container</p>\n<ul>\n<li><p>interactive<br>  -i: STDIN<br>  -t: open terminal<br>  exit?: docker stop or kill;exit</p>\n<pre><code>sudo docker run -i -t --name=inspect_shell ubuntu /bin/bash\ninspect_shell: container name\nbase image: ubuntu\ncommand: /bin/bash\nfile system: image+writable layer\nnetwork: virtual network interface bridge to host &amp; set a IP\n</code></pre></li>\n<li><p>daemon: -d<br>  exit?: docker stop or kill</p>\n<pre><code>sudo docker run --name daemon_while -d ubuntu /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;\n\nreturn token\n\ndocker ps\n</code></pre></li>\n</ul>\n</li>\n<li><p>start: start existing container</p>\n<pre><code>sudo docker start inspect_shell or cid\n</code></pre></li>\n<li><p>stop: works for both interactive and daemon container;send SIGTERM signal to container process</p>\n<pre><code>sudo docker stop daemon_while\nsudo docker stop s39c938dj34489d\n</code></pre></li>\n<li><p>unpause</p>\n</li>\n</ul>\n</li>\n<li><p>registry</p>\n<ul>\n<li><p>login</p>\n</li>\n<li><p>logout</p>\n</li>\n<li><p>pull</p>\n</li>\n<li><p>push</p>\n</li>\n<li><p>search</p>\n</li>\n</ul>\n</li>\n<li><p>image</p>\n<ul>\n<li><p>build</p>\n</li>\n<li><p>images</p>\n</li>\n<li><p>import:             </p>\n<pre><code>cat my_container.rar | sudo docker import - imported:container\nrepository: imported, tag: container\ndocker import url res:tag\n</code></pre></li>\n<li><p>load</p>\n</li>\n<li><p>rmi</p>\n</li>\n<li><p>save</p>\n</li>\n<li><p>tag</p>\n</li>\n<li><p>commit</p>\n</li>\n</ul>\n</li>\n<li><p>container</p>\n<ul>\n<li><p>attach: attach terminal to interactive container</p>\n</li>\n<li><p>export</p>\n<pre><code>sudo docker run -i -t --nam=inspect_import ubuntu /bin/bash\n#... do something\nsudo docker export inspect_import &gt; my_container.tar\n</code></pre></li>\n<li><p>inspect: check out the configuration</p>\n<pre><code>sudo docker inspect daemon_dave\n</code></pre><p>  -f or format:</p>\n<pre><code>sudo docker inspect --format=&apos;{{ .State.Running }}&apos; daemon_dave\n</code></pre></li>\n<li><p>port</p>\n</li>\n<li><p>ps: checkout existing container</p>\n<p>  -a: all</p>\n<pre><code>Exited(0): exit\n</code></pre><p>  -l: latest container<br>  -n=x: latest x container</p>\n</li>\n<li><p>rename</p>\n</li>\n<li><p>stats</p>\n</li>\n<li><p>top: check out UID PID PPID</p>\n<pre><code>sudo docker run -d --name=&quot;daemon_top&quot; ubuntu /bin/bash -c &apos;while true;do sleep 1;done&apos;\n</code></pre><p>  2 process:</p>\n<pre><code>sudo docker top daemon_top\n</code></pre></li>\n<li><p>wait</p>\n</li>\n<li><p>cp</p>\n</li>\n<li><p>diff</p>\n</li>\n</ul>\n</li>\n<li><p>sys log</p>\n<ul>\n<li><p>events</p>\n</li>\n<li><p>history</p>\n</li>\n<li><p>logs</p>\n<p>  -f: realtime<br>  tail=x: last x line</p>\n<pre><code>sudo docker logs -f --tail=5 -t daemon_logs\n</code></pre></li>\n</ul>\n</li>\n<li><p>other</p>\n<ul>\n<li><p>docker daemon: <a href=\"https://docs.docker.com/engine/reference/commandline/daemon/\">link</a>, A self-sufficient runtime for linux containers.</p>\n<p>  The Docker daemon can listen for Docker Remote API requests via three different types of Socket: unix, tcp, and fd.<br>  By default, a unix domain socket (or IPC socket) is created at /var/run/docker.sock, requiring either root permission, or docker group membership.</p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"docker filesystem","_content":"\n# about\n\n\n# AuFS\n\n- about\n    \n    http://aufs.sourceforge.net/\n    \n    layered file system\n    \n    AuFS is a layered file system, so you can have a read only part, and a write part, and merge those together. So you could have the common parts of the operating system as read only, which are shared amongst all of your containers, and then give each container its own mount for writing.So let's say you have a container image that is 1GB in size. If you wanted to use a Full VM, you would need to have 1GB times x number of VMs you want. With LXC and AuFS you can share the bulk of the 1GB and if you have 1000 containers you still might only have a little over 1GB of space for the containers OS, assuming they are all running the same OS image.\n\n# ceph\n\n- about\n\n     Linux PB \n    Ceph is a distributed object store and file system designed to provide excellent performance, reliability and scalability.\n\n- feature\n\n    - O(1)TB\n    - 100K\n    - Kafka ServerPartition\n    - \n    - Scale out\n\n- resource\n\n    link http://ceph.com/\n    doc http://docs.openfans.org/ceph\n\n- core\n\n- components\n    \n    cluster monitors\n    clients\n    metadata server cluster\n    object storage cluster\n\n# overlayfs\n\n- link https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt","source":"_posts/docker-filesystem-core.md","raw":"---\ntitle: docker filesystem\ncategories:\n- docker\ntags:\n- core\n- filesystem\n---\n\n# about\n\n\n# AuFS\n\n- about\n    \n    http://aufs.sourceforge.net/\n    \n    layered file system\n    \n    AuFS is a layered file system, so you can have a read only part, and a write part, and merge those together. So you could have the common parts of the operating system as read only, which are shared amongst all of your containers, and then give each container its own mount for writing.So let's say you have a container image that is 1GB in size. If you wanted to use a Full VM, you would need to have 1GB times x number of VMs you want. With LXC and AuFS you can share the bulk of the 1GB and if you have 1000 containers you still might only have a little over 1GB of space for the containers OS, assuming they are all running the same OS image.\n\n# ceph\n\n- about\n\n     Linux PB \n    Ceph is a distributed object store and file system designed to provide excellent performance, reliability and scalability.\n\n- feature\n\n    - O(1)TB\n    - 100K\n    - Kafka ServerPartition\n    - \n    - Scale out\n\n- resource\n\n    link http://ceph.com/\n    doc http://docs.openfans.org/ceph\n\n- core\n\n- components\n    \n    cluster monitors\n    clients\n    metadata server cluster\n    object storage cluster\n\n# overlayfs\n\n- link https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt","slug":"docker-filesystem-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T07:30:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm39c002b21svtsnp2crr","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"AuFS\"><a href=\"#AuFS\" class=\"headerlink\" title=\"AuFS\"></a>AuFS</h1><ul>\n<li><p>about</p>\n<p>  <a href=\"http://aufs.sourceforge.net/\" target=\"_blank\" rel=\"external\">http://aufs.sourceforge.net/</a></p>\n<p>  layered file system</p>\n<p>  AuFS is a layered file system, so you can have a read only part, and a write part, and merge those together. So you could have the common parts of the operating system as read only, which are shared amongst all of your containers, and then give each container its own mount for writing.So lets say you have a container image that is 1GB in size. If you wanted to use a Full VM, you would need to have 1GB times x number of VMs you want. With LXC and AuFS you can share the bulk of the 1GB and if you have 1000 containers you still might only have a little over 1GB of space for the containers OS, assuming they are all running the same OS image.</p>\n</li>\n</ul>\n<h1 id=\"ceph\"><a href=\"#ceph\" class=\"headerlink\" title=\"ceph\"></a>ceph</h1><ul>\n<li><p>about</p>\n<p>   Linux PB <br>  Ceph is a distributed object store and file system designed to provide excellent performance, reliability and scalability.</p>\n</li>\n<li><p>feature</p>\n<ul>\n<li>O(1)TB</li>\n<li>100K</li>\n<li>Kafka ServerPartition</li>\n<li></li>\n<li>Scale out</li>\n</ul>\n</li>\n<li><p>resource</p>\n<p>  link <a href=\"http://ceph.com/\" target=\"_blank\" rel=\"external\">http://ceph.com/</a><br>  doc <a href=\"http://docs.openfans.org/ceph\" target=\"_blank\" rel=\"external\">http://docs.openfans.org/ceph</a></p>\n</li>\n<li><p>core</p>\n</li>\n<li><p>components</p>\n<p>  cluster monitors<br>  clients<br>  metadata server cluster<br>  object storage cluster</p>\n</li>\n</ul>\n<h1 id=\"overlayfs\"><a href=\"#overlayfs\" class=\"headerlink\" title=\"overlayfs\"></a>overlayfs</h1><ul>\n<li>link <a href=\"https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt\" target=\"_blank\" rel=\"external\">https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt</a></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"AuFS\"><a href=\"#AuFS\" class=\"headerlink\" title=\"AuFS\"></a>AuFS</h1><ul>\n<li><p>about</p>\n<p>  <a href=\"http://aufs.sourceforge.net/\">http://aufs.sourceforge.net/</a></p>\n<p>  layered file system</p>\n<p>  AuFS is a layered file system, so you can have a read only part, and a write part, and merge those together. So you could have the common parts of the operating system as read only, which are shared amongst all of your containers, and then give each container its own mount for writing.So lets say you have a container image that is 1GB in size. If you wanted to use a Full VM, you would need to have 1GB times x number of VMs you want. With LXC and AuFS you can share the bulk of the 1GB and if you have 1000 containers you still might only have a little over 1GB of space for the containers OS, assuming they are all running the same OS image.</p>\n</li>\n</ul>\n<h1 id=\"ceph\"><a href=\"#ceph\" class=\"headerlink\" title=\"ceph\"></a>ceph</h1><ul>\n<li><p>about</p>\n<p>   Linux PB <br>  Ceph is a distributed object store and file system designed to provide excellent performance, reliability and scalability.</p>\n</li>\n<li><p>feature</p>\n<ul>\n<li>O(1)TB</li>\n<li>100K</li>\n<li>Kafka ServerPartition</li>\n<li></li>\n<li>Scale out</li>\n</ul>\n</li>\n<li><p>resource</p>\n<p>  link <a href=\"http://ceph.com/\">http://ceph.com/</a><br>  doc <a href=\"http://docs.openfans.org/ceph\">http://docs.openfans.org/ceph</a></p>\n</li>\n<li><p>core</p>\n</li>\n<li><p>components</p>\n<p>  cluster monitors<br>  clients<br>  metadata server cluster<br>  object storage cluster</p>\n</li>\n</ul>\n<h1 id=\"overlayfs\"><a href=\"#overlayfs\" class=\"headerlink\" title=\"overlayfs\"></a>overlayfs</h1><ul>\n<li>link <a href=\"https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt\">https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt</a></li>\n</ul>\n"},{"title":"docker image","_content":"\n# about docker image\n\n- standard: [Docker Image Specification](https://github.com/docker/docker/blob/master/image/spec/v1.md)\n\n- layer\n\n        r & w layer-container\n        add nginx-image2\n        add nginx-image1\n        ubuntu-base image\n        kernel-bootfs\n\n- duplication while writing \n\n# docker image command\n        \n- docker pull\n\n- docker run\n\n- docker images: check out\n    \n        docker images ububtu\n\n- docker inspect\n\n        docker inspect ubuntu\n\n- docker search: AUTOMATED-automatic build\n\n- docker rmi: delete image\n\n        docker rmi c03k349dfjn2\n    \n    -f if some container depends on this image:\n\n        docker rmi -f ubuntu\n    \n    delete all:\n        \n        docker rm $(docker ps -a -q)\n\n- docker commit: one way to create local image, the other way is dockerfile\n    commit changes to user image\n    \n        sudo docker run -t -i ubuntu\n        apt-get install sqlite3\n        echo 'test docker commit' >> hellodocker\n        exit\n        sudo docker commit -m=\"message\" --author=\"ag\" CONTAINERID ag/sqlite3:v1\n        sudo docker run -t -i ag/sqlite3:v1\n        cat hellodocker\n        sqlite3 -version\n\n- docker build: build image with dockerfile\n    \n    -rm=false: do not delete the tmp image while building\n\n    -t: set namespace, repo name, tag\n\n        sudo docker build -t ag/test:v1\n\n- docker tag\n\n        sudo docker tag ag/test:v1 ag/test:v2\n        (v1 and v2 will have the same image id)\n    \n    build with github:\n    \n        sudo docker build -t ag/test:v1 git://github.com/ag/dockerfile.git\n\n- docker save\n\n- docker load\n\n- docker diff\n    \n        docker diff container","source":"_posts/docker-image-detail.md","raw":"---\ntitle: docker image\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about docker image\n\n- standard: [Docker Image Specification](https://github.com/docker/docker/blob/master/image/spec/v1.md)\n\n- layer\n\n        r & w layer-container\n        add nginx-image2\n        add nginx-image1\n        ubuntu-base image\n        kernel-bootfs\n\n- duplication while writing \n\n# docker image command\n        \n- docker pull\n\n- docker run\n\n- docker images: check out\n    \n        docker images ububtu\n\n- docker inspect\n\n        docker inspect ubuntu\n\n- docker search: AUTOMATED-automatic build\n\n- docker rmi: delete image\n\n        docker rmi c03k349dfjn2\n    \n    -f if some container depends on this image:\n\n        docker rmi -f ubuntu\n    \n    delete all:\n        \n        docker rm $(docker ps -a -q)\n\n- docker commit: one way to create local image, the other way is dockerfile\n    commit changes to user image\n    \n        sudo docker run -t -i ubuntu\n        apt-get install sqlite3\n        echo 'test docker commit' >> hellodocker\n        exit\n        sudo docker commit -m=\"message\" --author=\"ag\" CONTAINERID ag/sqlite3:v1\n        sudo docker run -t -i ag/sqlite3:v1\n        cat hellodocker\n        sqlite3 -version\n\n- docker build: build image with dockerfile\n    \n    -rm=false: do not delete the tmp image while building\n\n    -t: set namespace, repo name, tag\n\n        sudo docker build -t ag/test:v1\n\n- docker tag\n\n        sudo docker tag ag/test:v1 ag/test:v2\n        (v1 and v2 will have the same image id)\n    \n    build with github:\n    \n        sudo docker build -t ag/test:v1 git://github.com/ag/dockerfile.git\n\n- docker save\n\n- docker load\n\n- docker diff\n    \n        docker diff container","slug":"docker-image-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T11:50:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm39e002f21svqd89nzvh","content":"<h1 id=\"about-docker-image\"><a href=\"#about-docker-image\" class=\"headerlink\" title=\"about docker image\"></a>about docker image</h1><ul>\n<li><p>standard: <a href=\"https://github.com/docker/docker/blob/master/image/spec/v1.md\" target=\"_blank\" rel=\"external\">Docker Image Specification</a></p>\n</li>\n<li><p>layer</p>\n<pre><code>r &amp; w layer-container\nadd nginx-image2\nadd nginx-image1\nubuntu-base image\nkernel-bootfs\n</code></pre></li>\n<li><p>duplication while writing </p>\n</li>\n</ul>\n<h1 id=\"docker-image-command\"><a href=\"#docker-image-command\" class=\"headerlink\" title=\"docker image command\"></a>docker image command</h1><ul>\n<li><p>docker pull</p>\n</li>\n<li><p>docker run</p>\n</li>\n<li><p>docker images: check out</p>\n<pre><code>docker images ububtu\n</code></pre></li>\n<li><p>docker inspect</p>\n<pre><code>docker inspect ubuntu\n</code></pre></li>\n<li><p>docker search: AUTOMATED-automatic build</p>\n</li>\n<li><p>docker rmi: delete image</p>\n<pre><code>docker rmi c03k349dfjn2\n</code></pre><p>  -f if some container depends on this image:</p>\n<pre><code>docker rmi -f ubuntu\n</code></pre><p>  delete all:</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre></li>\n<li><p>docker commit: one way to create local image, the other way is dockerfile<br>  commit changes to user image</p>\n<pre><code>sudo docker run -t -i ubuntu\napt-get install sqlite3\necho &apos;test docker commit&apos; &gt;&gt; hellodocker\nexit\nsudo docker commit -m=&quot;message&quot; --author=&quot;ag&quot; CONTAINERID ag/sqlite3:v1\nsudo docker run -t -i ag/sqlite3:v1\ncat hellodocker\nsqlite3 -version\n</code></pre></li>\n<li><p>docker build: build image with dockerfile</p>\n<p>  -rm=false: do not delete the tmp image while building</p>\n<p>  -t: set namespace, repo name, tag</p>\n<pre><code>sudo docker build -t ag/test:v1\n</code></pre></li>\n<li><p>docker tag</p>\n<pre><code>sudo docker tag ag/test:v1 ag/test:v2\n(v1 and v2 will have the same image id)\n</code></pre><p>  build with github:</p>\n<pre><code>sudo docker build -t ag/test:v1 git://github.com/ag/dockerfile.git\n</code></pre></li>\n<li><p>docker save</p>\n</li>\n<li><p>docker load</p>\n</li>\n<li><p>docker diff</p>\n<pre><code>docker diff container\n</code></pre></li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about-docker-image\"><a href=\"#about-docker-image\" class=\"headerlink\" title=\"about docker image\"></a>about docker image</h1><ul>\n<li><p>standard: <a href=\"https://github.com/docker/docker/blob/master/image/spec/v1.md\">Docker Image Specification</a></p>\n</li>\n<li><p>layer</p>\n<pre><code>r &amp; w layer-container\nadd nginx-image2\nadd nginx-image1\nubuntu-base image\nkernel-bootfs\n</code></pre></li>\n<li><p>duplication while writing </p>\n</li>\n</ul>\n<h1 id=\"docker-image-command\"><a href=\"#docker-image-command\" class=\"headerlink\" title=\"docker image command\"></a>docker image command</h1><ul>\n<li><p>docker pull</p>\n</li>\n<li><p>docker run</p>\n</li>\n<li><p>docker images: check out</p>\n<pre><code>docker images ububtu\n</code></pre></li>\n<li><p>docker inspect</p>\n<pre><code>docker inspect ubuntu\n</code></pre></li>\n<li><p>docker search: AUTOMATED-automatic build</p>\n</li>\n<li><p>docker rmi: delete image</p>\n<pre><code>docker rmi c03k349dfjn2\n</code></pre><p>  -f if some container depends on this image:</p>\n<pre><code>docker rmi -f ubuntu\n</code></pre><p>  delete all:</p>\n<pre><code>docker rm $(docker ps -a -q)\n</code></pre></li>\n<li><p>docker commit: one way to create local image, the other way is dockerfile<br>  commit changes to user image</p>\n<pre><code>sudo docker run -t -i ubuntu\napt-get install sqlite3\necho &apos;test docker commit&apos; &gt;&gt; hellodocker\nexit\nsudo docker commit -m=&quot;message&quot; --author=&quot;ag&quot; CONTAINERID ag/sqlite3:v1\nsudo docker run -t -i ag/sqlite3:v1\ncat hellodocker\nsqlite3 -version\n</code></pre></li>\n<li><p>docker build: build image with dockerfile</p>\n<p>  -rm=false: do not delete the tmp image while building</p>\n<p>  -t: set namespace, repo name, tag</p>\n<pre><code>sudo docker build -t ag/test:v1\n</code></pre></li>\n<li><p>docker tag</p>\n<pre><code>sudo docker tag ag/test:v1 ag/test:v2\n(v1 and v2 will have the same image id)\n</code></pre><p>  build with github:</p>\n<pre><code>sudo docker build -t ag/test:v1 git://github.com/ag/dockerfile.git\n</code></pre></li>\n<li><p>docker save</p>\n</li>\n<li><p>docker load</p>\n</li>\n<li><p>docker diff</p>\n<pre><code>docker diff container\n</code></pre></li>\n</ul>\n"},{"title":"k8s core","_content":"\n#  core","source":"_posts/docker-k8s-core.md","raw":"---\ntitle: k8s core\ncategories:\n- docker\ntags:\n- core\n---\n\n#  core","slug":"docker-k8s-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:32:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm39i002i21sv9msto5pk","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"docker machine","_content":"\n# about\n\n- link: https://docs.docker.com/machine/overview/\n\n# faq\n\n- Whats the difference between Docker Engine and Docker Machine?\n\nWhen people say Docker they typically mean Docker Engine, the client-server application made up of the Docker daemon, a REST API that specifies interfaces for interacting with the daemon, and a command line interface (CLI) client that talks to the daemon (through the REST API wrapper). Docker Engine accepts docker commands from the CLI, such as docker run <image>, docker ps to list running containers, docker images to list images, and so on.","source":"_posts/docker-machine-detail.md","raw":"---\ntitle: docker machine\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about\n\n- link: https://docs.docker.com/machine/overview/\n\n# faq\n\n- Whats the difference between Docker Engine and Docker Machine?\n\nWhen people say Docker they typically mean Docker Engine, the client-server application made up of the Docker daemon, a REST API that specifies interfaces for interacting with the daemon, and a command line interface (CLI) client that talks to the daemon (through the REST API wrapper). Docker Engine accepts docker commands from the CLI, such as docker run <image>, docker ps to list running containers, docker images to list images, and so on.","slug":"docker-machine-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-18T05:50:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm39m002n21svzvub4bz1","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>link: <a href=\"https://docs.docker.com/machine/overview/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/machine/overview/</a></li>\n</ul>\n<h1 id=\"faq\"><a href=\"#faq\" class=\"headerlink\" title=\"faq\"></a>faq</h1><ul>\n<li>Whats the difference between Docker Engine and Docker Machine?</li>\n</ul>\n<p>When people say Docker they typically mean Docker Engine, the client-server application made up of the Docker daemon, a REST API that specifies interfaces for interacting with the daemon, and a command line interface (CLI) client that talks to the daemon (through the REST API wrapper). Docker Engine accepts docker commands from the CLI, such as docker run <image>, docker ps to list running containers, docker images to list images, and so on.</image></p>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>link: <a href=\"https://docs.docker.com/machine/overview/\">https://docs.docker.com/machine/overview/</a></li>\n</ul>\n<h1 id=\"faq\"><a href=\"#faq\" class=\"headerlink\" title=\"faq\"></a>faq</h1><ul>\n<li>Whats the difference between Docker Engine and Docker Machine?</li>\n</ul>\n<p>When people say Docker they typically mean Docker Engine, the client-server application made up of the Docker daemon, a REST API that specifies interfaces for interacting with the daemon, and a command line interface (CLI) client that talks to the daemon (through the REST API wrapper). Docker Engine accepts docker commands from the CLI, such as docker run <image>, docker ps to list running containers, docker images to list images, and so on.</p>\n"},{"title":"mesos core","_content":"\n#  core","source":"_posts/docker-mesos-core.md","raw":"---\ntitle: mesos core\ncategories:\n- docker\ntags:\n- core\n---\n\n#  core","slug":"docker-mesos-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:32:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm39p002q21svs69ki7jr","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"docker security","_content":"\n# about\n\n# cgroups\n\n# capability\n\n# notary\nhttps://github.com/docker/notary","source":"_posts/docker-security-core.md","raw":"---\ntitle: docker security\ncategories:\n- docker\ntags:\n- core\n- security\n---\n\n# about\n\n# cgroups\n\n# capability\n\n# notary\nhttps://github.com/docker/notary","slug":"docker-security-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T05:26:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm39s002u21svylq4icy5","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"cgroups\"><a href=\"#cgroups\" class=\"headerlink\" title=\"cgroups\"></a>cgroups</h1><h1 id=\"capability\"><a href=\"#capability\" class=\"headerlink\" title=\"capability\"></a>capability</h1><h1 id=\"notary\"><a href=\"#notary\" class=\"headerlink\" title=\"notary\"></a>notary</h1><p><a href=\"https://github.com/docker/notary\" target=\"_blank\" rel=\"external\">https://github.com/docker/notary</a></p>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"cgroups\"><a href=\"#cgroups\" class=\"headerlink\" title=\"cgroups\"></a>cgroups</h1><h1 id=\"capability\"><a href=\"#capability\" class=\"headerlink\" title=\"capability\"></a>capability</h1><h1 id=\"notary\"><a href=\"#notary\" class=\"headerlink\" title=\"notary\"></a>notary</h1><p><a href=\"https://github.com/docker/notary\">https://github.com/docker/notary</a></p>\n"},{"title":"docker network","_content":"\n# about\n\n- docker daemon ini process(docker -d)\n\n    [/var/lib/docker|116d5cd4] +job init_networkdriver()\n    [/var/lib/docker|116d5cd4.init_networkdriver()] creating new bridge for docker0\n    [/var/lib/docker|116d5cd4.init_networkdriver()] getting iface addr\n    [/var/lib/docker|116d5cd4] -job init_networkdriver() = OK (0)\n\n- default mode\n    bridge\n        docker0\n\n- expose port\n\n    -P: randomly expose a port between 49000-49900\n            sudo docker run -d -P traning/webapp python app.py\n    -p:\n            ip:hostPort:containerPost | ip::containerPort | hostPort:containerPort\n\n- check out network setting\n\n        sudo docker inspect --format '{{.NetworkSettings}}' CID\n\n- container link\n    \n    about: docker0 bridge; iptables\n\n    --link name:alias\n\n            sudo docker -d --name dbdata training/postgres\n            sudo docker run -d -P --name web --link dbdata:db training/webapp python app.py\n            sudo docker inspect web\n        \n        Links: /dbdata:/web/db\n\n        how web container use dbdata:\n            \n            - env variable\n                sudo docker run --rm --name web2 --link dbdata:webdb training/webapp env\n                <name>_PORT_<port>_<protocol>_ADDR/PORT/PROTO\n            \n            - /etc/hosts\n\n    - ambassador\n        about: \n        connect redis client and server via 2 ambassador\n                sudo docker run -d --name redis ag/redis\n                sudo docker run -d --name redis ag/redis\n\n# docker network design\n\nhttps://blog.docker.com/2016/03/docker-networking-design-philosophy/\n\n# cnm design\n\nhttps://github.com/docker/libnetwork/blob/master/docs/design.md\n\n# docker network command\n\n- docker network ls\n\n- docker network create\n\n- docker network connect\n\n- docker network disconnect\n\n- docker network inspect\n\n- docker network rm\n\n# docker network api\n\n- network driver api\n\n- IPAM api\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/docker-network-core.md","raw":"---\ntitle: docker network\ncategories:\n- docker\ntags:\n- core\n- network\n---\n\n# about\n\n- docker daemon ini process(docker -d)\n\n    [/var/lib/docker|116d5cd4] +job init_networkdriver()\n    [/var/lib/docker|116d5cd4.init_networkdriver()] creating new bridge for docker0\n    [/var/lib/docker|116d5cd4.init_networkdriver()] getting iface addr\n    [/var/lib/docker|116d5cd4] -job init_networkdriver() = OK (0)\n\n- default mode\n    bridge\n        docker0\n\n- expose port\n\n    -P: randomly expose a port between 49000-49900\n            sudo docker run -d -P traning/webapp python app.py\n    -p:\n            ip:hostPort:containerPost | ip::containerPort | hostPort:containerPort\n\n- check out network setting\n\n        sudo docker inspect --format '{{.NetworkSettings}}' CID\n\n- container link\n    \n    about: docker0 bridge; iptables\n\n    --link name:alias\n\n            sudo docker -d --name dbdata training/postgres\n            sudo docker run -d -P --name web --link dbdata:db training/webapp python app.py\n            sudo docker inspect web\n        \n        Links: /dbdata:/web/db\n\n        how web container use dbdata:\n            \n            - env variable\n                sudo docker run --rm --name web2 --link dbdata:webdb training/webapp env\n                <name>_PORT_<port>_<protocol>_ADDR/PORT/PROTO\n            \n            - /etc/hosts\n\n    - ambassador\n        about: \n        connect redis client and server via 2 ambassador\n                sudo docker run -d --name redis ag/redis\n                sudo docker run -d --name redis ag/redis\n\n# docker network design\n\nhttps://blog.docker.com/2016/03/docker-networking-design-philosophy/\n\n# cnm design\n\nhttps://github.com/docker/libnetwork/blob/master/docs/design.md\n\n# docker network command\n\n- docker network ls\n\n- docker network create\n\n- docker network connect\n\n- docker network disconnect\n\n- docker network inspect\n\n- docker network rm\n\n# docker network api\n\n- network driver api\n\n- IPAM api\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"docker-network-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T05:25:33.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm39x002x21svqqrk3m16","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li><p>docker daemon ini process(docker -d)</p>\n<p>  [/var/lib/docker|116d5cd4] +job init_networkdriver()<br>  [/var/lib/docker|116d5cd4.init_networkdriver()] creating new bridge for docker0<br>  [/var/lib/docker|116d5cd4.init_networkdriver()] getting iface addr<br>  [/var/lib/docker|116d5cd4] -job init_networkdriver() = OK (0)</p>\n</li>\n<li><p>default mode<br>  bridge</p>\n<pre><code>docker0\n</code></pre></li>\n<li><p>expose port</p>\n<p>  -P: randomly expose a port between 49000-49900</p>\n<pre><code>sudo docker run -d -P traning/webapp python app.py\n</code></pre><p>  -p:</p>\n<pre><code>ip:hostPort:containerPost | ip::containerPort | hostPort:containerPort\n</code></pre></li>\n<li><p>check out network setting</p>\n<pre><code>sudo docker inspect --format &apos;{{.NetworkSettings}}&apos; CID\n</code></pre></li>\n<li><p>container link</p>\n<p>  about: docker0 bridge; iptables</p>\n<p>  link name:alias</p>\n<pre><code>    sudo docker -d --name dbdata training/postgres\n    sudo docker run -d -P --name web --link dbdata:db training/webapp python app.py\n    sudo docker inspect web\n\nLinks: /dbdata:/web/db\n\nhow web container use dbdata:\n\n    - env variable\n        sudo docker run --rm --name web2 --link dbdata:webdb training/webapp env\n        &lt;name&gt;_PORT_&lt;port&gt;_&lt;protocol&gt;_ADDR/PORT/PROTO\n\n    - /etc/hosts\n</code></pre><ul>\n<li>ambassador<br>  about: <br>  connect redis client and server via 2 ambassador<pre><code>sudo docker run -d --name redis ag/redis\nsudo docker run -d --name redis ag/redis\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"docker-network-design\"><a href=\"#docker-network-design\" class=\"headerlink\" title=\"docker network design\"></a>docker network design</h1><p><a href=\"https://blog.docker.com/2016/03/docker-networking-design-philosophy/\" target=\"_blank\" rel=\"external\">https://blog.docker.com/2016/03/docker-networking-design-philosophy/</a></p>\n<h1 id=\"cnm-design\"><a href=\"#cnm-design\" class=\"headerlink\" title=\"cnm design\"></a>cnm design</h1><p><a href=\"https://github.com/docker/libnetwork/blob/master/docs/design.md\" target=\"_blank\" rel=\"external\">https://github.com/docker/libnetwork/blob/master/docs/design.md</a></p>\n<h1 id=\"docker-network-command\"><a href=\"#docker-network-command\" class=\"headerlink\" title=\"docker network command\"></a>docker network command</h1><ul>\n<li><p>docker network ls</p>\n</li>\n<li><p>docker network create</p>\n</li>\n<li><p>docker network connect</p>\n</li>\n<li><p>docker network disconnect</p>\n</li>\n<li><p>docker network inspect</p>\n</li>\n<li><p>docker network rm</p>\n</li>\n</ul>\n<h1 id=\"docker-network-api\"><a href=\"#docker-network-api\" class=\"headerlink\" title=\"docker network api\"></a>docker network api</h1><ul>\n<li><p>network driver api</p>\n</li>\n<li><p>IPAM api</p>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li><p>docker daemon ini process(docker -d)</p>\n<p>  [/var/lib/docker|116d5cd4] +job init_networkdriver()<br>  [/var/lib/docker|116d5cd4.init_networkdriver()] creating new bridge for docker0<br>  [/var/lib/docker|116d5cd4.init_networkdriver()] getting iface addr<br>  [/var/lib/docker|116d5cd4] -job init_networkdriver() = OK (0)</p>\n</li>\n<li><p>default mode<br>  bridge</p>\n<pre><code>docker0\n</code></pre></li>\n<li><p>expose port</p>\n<p>  -P: randomly expose a port between 49000-49900</p>\n<pre><code>sudo docker run -d -P traning/webapp python app.py\n</code></pre><p>  -p:</p>\n<pre><code>ip:hostPort:containerPost | ip::containerPort | hostPort:containerPort\n</code></pre></li>\n<li><p>check out network setting</p>\n<pre><code>sudo docker inspect --format &apos;{{.NetworkSettings}}&apos; CID\n</code></pre></li>\n<li><p>container link</p>\n<p>  about: docker0 bridge; iptables</p>\n<p>  link name:alias</p>\n<pre><code>    sudo docker -d --name dbdata training/postgres\n    sudo docker run -d -P --name web --link dbdata:db training/webapp python app.py\n    sudo docker inspect web\n\nLinks: /dbdata:/web/db\n\nhow web container use dbdata:\n\n    - env variable\n        sudo docker run --rm --name web2 --link dbdata:webdb training/webapp env\n        &lt;name&gt;_PORT_&lt;port&gt;_&lt;protocol&gt;_ADDR/PORT/PROTO\n\n    - /etc/hosts\n</code></pre><ul>\n<li>ambassador<br>  about: <br>  connect redis client and server via 2 ambassador<pre><code>sudo docker run -d --name redis ag/redis\nsudo docker run -d --name redis ag/redis\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"docker-network-design\"><a href=\"#docker-network-design\" class=\"headerlink\" title=\"docker network design\"></a>docker network design</h1><p><a href=\"https://blog.docker.com/2016/03/docker-networking-design-philosophy/\">https://blog.docker.com/2016/03/docker-networking-design-philosophy/</a></p>\n<h1 id=\"cnm-design\"><a href=\"#cnm-design\" class=\"headerlink\" title=\"cnm design\"></a>cnm design</h1><p><a href=\"https://github.com/docker/libnetwork/blob/master/docs/design.md\">https://github.com/docker/libnetwork/blob/master/docs/design.md</a></p>\n<h1 id=\"docker-network-command\"><a href=\"#docker-network-command\" class=\"headerlink\" title=\"docker network command\"></a>docker network command</h1><ul>\n<li><p>docker network ls</p>\n</li>\n<li><p>docker network create</p>\n</li>\n<li><p>docker network connect</p>\n</li>\n<li><p>docker network disconnect</p>\n</li>\n<li><p>docker network inspect</p>\n</li>\n<li><p>docker network rm</p>\n</li>\n</ul>\n<h1 id=\"docker-network-api\"><a href=\"#docker-network-api\" class=\"headerlink\" title=\"docker network api\"></a>docker network api</h1><ul>\n<li><p>network driver api</p>\n</li>\n<li><p>IPAM api</p>\n</li>\n</ul>\n"},{"title":"docker storage","_content":"\n# about\n\n- data volumes \n   \n    - create\n        \n        using dockerfile:\n            \n                VOLUME /var/lib/postgresql\n        \n        docker run -v:\n\n                docker run -d -P -v /webapp training/webapp python app.py\n                docker inspect my_data\n                docker inspect --format {{.Volums}} my_data\n    \n    - mount file\n        \n            $ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash\n    \n    - mount folder\n        \n            $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py\n    \n    - mount local directory\n        \n            sudo docker run -d -P --name webapp -v `pwd`:/webapp:ro training/webapp python app.py\n\n- data volume containers \n    \n    - tips:\n\n            $ sudo docker run -it -v /dbdata --name dbdata training/postgres\n            sudo docker run -d --volumes-from=dbdata --name db1 training/postgres\n            sudo docker run -d --name db2 --volumes-from=dbdata training/postgres\n            sudo docker run -d --name db2 --volumes-from=db1 training/postgres\n            docker rm -v db3\n\n    - migration\n        \n        backup:\n\n                $ sudo docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata\n                should use sudo \n            \n        restore:\n        \n                $ sudo docker run -v /dbdata --name dbdata2 ubuntu /bin/bash\n\n# link\n[Manage data in containers](https://docs.docker.com/engine/userguide/containers/dockervolumes/)\n\n# docker storage command\n\n- docker volume create\n\n- docker volume inspect\n\n- docker volume ls\n\n- docker volume rm","source":"_posts/docker-storage-core.md","raw":"---\ntitle: docker storage\ncategories:\n- docker\ntags:\n- core\n- storage\n---\n\n# about\n\n- data volumes \n   \n    - create\n        \n        using dockerfile:\n            \n                VOLUME /var/lib/postgresql\n        \n        docker run -v:\n\n                docker run -d -P -v /webapp training/webapp python app.py\n                docker inspect my_data\n                docker inspect --format {{.Volums}} my_data\n    \n    - mount file\n        \n            $ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash\n    \n    - mount folder\n        \n            $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py\n    \n    - mount local directory\n        \n            sudo docker run -d -P --name webapp -v `pwd`:/webapp:ro training/webapp python app.py\n\n- data volume containers \n    \n    - tips:\n\n            $ sudo docker run -it -v /dbdata --name dbdata training/postgres\n            sudo docker run -d --volumes-from=dbdata --name db1 training/postgres\n            sudo docker run -d --name db2 --volumes-from=dbdata training/postgres\n            sudo docker run -d --name db2 --volumes-from=db1 training/postgres\n            docker rm -v db3\n\n    - migration\n        \n        backup:\n\n                $ sudo docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata\n                should use sudo \n            \n        restore:\n        \n                $ sudo docker run -v /dbdata --name dbdata2 ubuntu /bin/bash\n\n# link\n[Manage data in containers](https://docs.docker.com/engine/userguide/containers/dockervolumes/)\n\n# docker storage command\n\n- docker volume create\n\n- docker volume inspect\n\n- docker volume ls\n\n- docker volume rm","slug":"docker-storage-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T06:26:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3a2003221svf7toen7b","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li><p>data volumes </p>\n<ul>\n<li><p>create</p>\n<p>  using dockerfile:</p>\n<pre><code>VOLUME /var/lib/postgresql\n</code></pre><p>  docker run -v:</p>\n<pre><code>docker run -d -P -v /webapp training/webapp python app.py\ndocker inspect my_data\ndocker inspect --format {{.Volums}} my_data\n</code></pre></li>\n<li><p>mount file</p>\n<pre><code>$ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash\n</code></pre></li>\n<li><p>mount folder</p>\n<pre><code>$ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py\n</code></pre></li>\n<li><p>mount local directory</p>\n<pre><code>sudo docker run -d -P --name webapp -v `pwd`:/webapp:ro training/webapp python app.py\n</code></pre></li>\n</ul>\n</li>\n<li><p>data volume containers </p>\n<ul>\n<li><p>tips:</p>\n<pre><code>$ sudo docker run -it -v /dbdata --name dbdata training/postgres\nsudo docker run -d --volumes-from=dbdata --name db1 training/postgres\nsudo docker run -d --name db2 --volumes-from=dbdata training/postgres\nsudo docker run -d --name db2 --volumes-from=db1 training/postgres\ndocker rm -v db3\n</code></pre></li>\n<li><p>migration</p>\n<p>  backup:</p>\n<pre><code>$ sudo docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata\nshould use sudo \n</code></pre><p>  restore:</p>\n<pre><code>$ sudo docker run -v /dbdata --name dbdata2 ubuntu /bin/bash\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><p><a href=\"https://docs.docker.com/engine/userguide/containers/dockervolumes/\" target=\"_blank\" rel=\"external\">Manage data in containers</a></p>\n<h1 id=\"docker-storage-command\"><a href=\"#docker-storage-command\" class=\"headerlink\" title=\"docker storage command\"></a>docker storage command</h1><ul>\n<li><p>docker volume create</p>\n</li>\n<li><p>docker volume inspect</p>\n</li>\n<li><p>docker volume ls</p>\n</li>\n<li><p>docker volume rm</p>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li><p>data volumes </p>\n<ul>\n<li><p>create</p>\n<p>  using dockerfile:</p>\n<pre><code>VOLUME /var/lib/postgresql\n</code></pre><p>  docker run -v:</p>\n<pre><code>docker run -d -P -v /webapp training/webapp python app.py\ndocker inspect my_data\ndocker inspect --format {{.Volums}} my_data\n</code></pre></li>\n<li><p>mount file</p>\n<pre><code>$ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash\n</code></pre></li>\n<li><p>mount folder</p>\n<pre><code>$ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py\n</code></pre></li>\n<li><p>mount local directory</p>\n<pre><code>sudo docker run -d -P --name webapp -v `pwd`:/webapp:ro training/webapp python app.py\n</code></pre></li>\n</ul>\n</li>\n<li><p>data volume containers </p>\n<ul>\n<li><p>tips:</p>\n<pre><code>$ sudo docker run -it -v /dbdata --name dbdata training/postgres\nsudo docker run -d --volumes-from=dbdata --name db1 training/postgres\nsudo docker run -d --name db2 --volumes-from=dbdata training/postgres\nsudo docker run -d --name db2 --volumes-from=db1 training/postgres\ndocker rm -v db3\n</code></pre></li>\n<li><p>migration</p>\n<p>  backup:</p>\n<pre><code>$ sudo docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata\nshould use sudo \n</code></pre><p>  restore:</p>\n<pre><code>$ sudo docker run -v /dbdata --name dbdata2 ubuntu /bin/bash\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><p><a href=\"https://docs.docker.com/engine/userguide/containers/dockervolumes/\">Manage data in containers</a></p>\n<h1 id=\"docker-storage-command\"><a href=\"#docker-storage-command\" class=\"headerlink\" title=\"docker storage command\"></a>docker storage command</h1><ul>\n<li><p>docker volume create</p>\n</li>\n<li><p>docker volume inspect</p>\n</li>\n<li><p>docker volume ls</p>\n</li>\n<li><p>docker volume rm</p>\n</li>\n</ul>\n"},{"title":"docker swarm portal","_content":"\n# about \n\n- reference: http://mt.sohu.com/20160818/n464799101.shtml\n\nSwarmNextSwarm Docker SwarmDockerSwarmKubernetesDocker1.12SwarmNextSwarmSwarmSwarmNextComposeSwarmNextSwarmSwarmNextSwarmSwarmkitSwarmkit\n\n# swarm \n\n- link: https://docs.docker.com/swarm/overview/\n\n# swarm next (swarm mode)\n\n- link: https://docs.docker.com/engine/swarm/\n- tut: https://docs.docker.com/engine/swarm/swarm-tutorial/\n- cli: https://docs.docker.com/engine/swarm/#swarm-mode-cli-commands\n\n# swarmkit\n","source":"_posts/docker-swarm-portal.md","raw":"---\ntitle: docker swarm portal\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about \n\n- reference: http://mt.sohu.com/20160818/n464799101.shtml\n\nSwarmNextSwarm Docker SwarmDockerSwarmKubernetesDocker1.12SwarmNextSwarmSwarmSwarmNextComposeSwarmNextSwarmSwarmNextSwarmSwarmkitSwarmkit\n\n# swarm \n\n- link: https://docs.docker.com/swarm/overview/\n\n# swarm next (swarm mode)\n\n- link: https://docs.docker.com/engine/swarm/\n- tut: https://docs.docker.com/engine/swarm/swarm-tutorial/\n- cli: https://docs.docker.com/engine/swarm/#swarm-mode-cli-commands\n\n# swarmkit\n","slug":"docker-swarm-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T07:55:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3ae003521svyblhs7lq","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>reference: <a href=\"http://mt.sohu.com/20160818/n464799101.shtml\" target=\"_blank\" rel=\"external\">http://mt.sohu.com/20160818/n464799101.shtml</a></li>\n</ul>\n<p>SwarmNextSwarm Docker SwarmDockerSwarmKubernetesDocker1.12SwarmNextSwarmSwarmSwarmNextComposeSwarmNextSwarmSwarmNextSwarmSwarmkitSwarmkit</p>\n<h1 id=\"swarm\"><a href=\"#swarm\" class=\"headerlink\" title=\"swarm\"></a>swarm</h1><ul>\n<li>link: <a href=\"https://docs.docker.com/swarm/overview/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/swarm/overview/</a></li>\n</ul>\n<h1 id=\"swarm-next-swarm-mode\"><a href=\"#swarm-next-swarm-mode\" class=\"headerlink\" title=\"swarm next (swarm mode)\"></a>swarm next (swarm mode)</h1><ul>\n<li>link: <a href=\"https://docs.docker.com/engine/swarm/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/engine/swarm/</a></li>\n<li>tut: <a href=\"https://docs.docker.com/engine/swarm/swarm-tutorial/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/engine/swarm/swarm-tutorial/</a></li>\n<li>cli: <a href=\"https://docs.docker.com/engine/swarm/#swarm-mode-cli-commands\" target=\"_blank\" rel=\"external\">https://docs.docker.com/engine/swarm/#swarm-mode-cli-commands</a></li>\n</ul>\n<h1 id=\"swarmkit\"><a href=\"#swarmkit\" class=\"headerlink\" title=\"swarmkit\"></a>swarmkit</h1>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>reference: <a href=\"http://mt.sohu.com/20160818/n464799101.shtml\">http://mt.sohu.com/20160818/n464799101.shtml</a></li>\n</ul>\n<p>SwarmNextSwarm Docker SwarmDockerSwarmKubernetesDocker1.12SwarmNextSwarmSwarmSwarmNextComposeSwarmNextSwarmSwarmNextSwarmSwarmkitSwarmkit</p>\n<h1 id=\"swarm\"><a href=\"#swarm\" class=\"headerlink\" title=\"swarm\"></a>swarm</h1><ul>\n<li>link: <a href=\"https://docs.docker.com/swarm/overview/\">https://docs.docker.com/swarm/overview/</a></li>\n</ul>\n<h1 id=\"swarm-next-swarm-mode\"><a href=\"#swarm-next-swarm-mode\" class=\"headerlink\" title=\"swarm next (swarm mode)\"></a>swarm next (swarm mode)</h1><ul>\n<li>link: <a href=\"https://docs.docker.com/engine/swarm/\">https://docs.docker.com/engine/swarm/</a></li>\n<li>tut: <a href=\"https://docs.docker.com/engine/swarm/swarm-tutorial/\">https://docs.docker.com/engine/swarm/swarm-tutorial/</a></li>\n<li>cli: <a href=\"https://docs.docker.com/engine/swarm/#swarm-mode-cli-commands\">https://docs.docker.com/engine/swarm/#swarm-mode-cli-commands</a></li>\n</ul>\n<h1 id=\"swarmkit\"><a href=\"#swarmkit\" class=\"headerlink\" title=\"swarmkit\"></a>swarmkit</h1>"},{"title":"mesos core","_content":"\n#  core","source":"_posts/docker-store-detail.md","raw":"---\ntitle: mesos core\ncategories:\n- docker\ntags:\n- core\n---\n\n#  core","slug":"docker-store-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:32:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3ai003921sv5f0f4edv","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"docker swarm","_content":"\n# about \n\n# docker swarm command\n\n- docker-machine ls\n\n- docker-machine create -d virtualbox local\n\n- $(docker-machine env local) \n\n- docker run swarm create\n\n        $  docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://63e7a1adb607ce4db056a29b1f5d30cf swarm-master \n\n        $(docker-machine env --swarm swarm-master)\n\n- docker-machine ls\n","source":"_posts/docker-swarm-detail.md","raw":"---\ntitle: docker swarm\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about \n\n# docker swarm command\n\n- docker-machine ls\n\n- docker-machine create -d virtualbox local\n\n- $(docker-machine env local) \n\n- docker run swarm create\n\n        $  docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://63e7a1adb607ce4db056a29b1f5d30cf swarm-master \n\n        $(docker-machine env --swarm swarm-master)\n\n- docker-machine ls\n","slug":"docker-swarm-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T07:30:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3al003d21svs6i4yavl","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"docker-swarm-command\"><a href=\"#docker-swarm-command\" class=\"headerlink\" title=\"docker swarm command\"></a>docker swarm command</h1><ul>\n<li><p>docker-machine ls</p>\n</li>\n<li><p>docker-machine create -d virtualbox local</p>\n</li>\n<li><p>$(docker-machine env local) </p>\n</li>\n<li><p>docker run swarm create</p>\n<pre><code>$  docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://63e7a1adb607ce4db056a29b1f5d30cf swarm-master \n\n$(docker-machine env --swarm swarm-master)\n</code></pre></li>\n<li><p>docker-machine ls</p>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"docker-swarm-command\"><a href=\"#docker-swarm-command\" class=\"headerlink\" title=\"docker swarm command\"></a>docker swarm command</h1><ul>\n<li><p>docker-machine ls</p>\n</li>\n<li><p>docker-machine create -d virtualbox local</p>\n</li>\n<li><p>$(docker-machine env local) </p>\n</li>\n<li><p>docker run swarm create</p>\n<pre><code>$  docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery token://63e7a1adb607ce4db056a29b1f5d30cf swarm-master \n\n$(docker-machine env --swarm swarm-master)\n</code></pre></li>\n<li><p>docker-machine ls</p>\n</li>\n</ul>\n"},{"title":"openstack core","_content":"\n# about\n\n- link: https://github.com/docker/swarmkit\n\n# ","source":"_posts/docker-swarmkit-detail.md","raw":"---\ntitle: openstack core\ncategories:\n- iaas\ntags:\n- core\n- openstack\n---\n\n# about\n\n- link: https://github.com/docker/swarmkit\n\n# ","slug":"docker-swarmkit-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T08:04:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3an003h21sv7b0gw30l","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>link: <a href=\"https://github.com/docker/swarmkit\" target=\"_blank\" rel=\"external\">https://github.com/docker/swarmkit</a></li>\n</ul>\n<p># </p>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li>link: <a href=\"https://github.com/docker/swarmkit\">https://github.com/docker/swarmkit</a></li>\n</ul>\n<p># </p>\n"},{"title":"docker yaml file","_content":"\n# about\n\n# link\n\nhttp://www.yaml.org/\nhttps://en.wikipedia.org/wiki/YAML","source":"_posts/docker-yaml-detail.md","raw":"---\ntitle: docker yaml file\ncategories:\n- docker\ntags:\n- detail\n---\n\n# about\n\n# link\n\nhttp://www.yaml.org/\nhttps://en.wikipedia.org/wiki/YAML","slug":"docker-yaml-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T05:31:36.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3ao003l21svrwyk2i8l","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><p><a href=\"http://www.yaml.org/\" target=\"_blank\" rel=\"external\">http://www.yaml.org/</a><br><a href=\"https://en.wikipedia.org/wiki/YAML\" target=\"_blank\" rel=\"external\">https://en.wikipedia.org/wiki/YAML</a></p>\n","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><p><a href=\"http://www.yaml.org/\">http://www.yaml.org/</a><br><a href=\"https://en.wikipedia.org/wiki/YAML\">https://en.wikipedia.org/wiki/YAML</a></p>\n"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ncategories:\n- tmp\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2017-01-11T09:26:51.000Z","updated":"2017-01-11T16:32:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3as003p21sv6fbp39yp","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n","excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\">Deployment</a></p>\n"},{"title":"docker swarm mode","_content":"\n# link\n\n- tut: https://docs.docker.com/engine/swarm/swarm-tutorial/\n\n\n# about\n\nDocker Engine 1.12 includes swarm mode for natively managing a cluster of Docker Engines called a swarm. Use the Docker CLI to create a swarm, deploy application services to a swarm, and manage swarm behavior.\n\n# feature\n\n    - Cluster management integrated with Docker Engine: \n\n    Use the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. You dont need additional orchestration software to create or manage a swarm.\n\n    - Decentralized design: \n\n    Instead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. You can deploy both kinds of nodes, managers and workers, using the Docker Engine. This means you can build an entire swarm from a single disk image.\n\n    - Declarative service model: \n\n    Docker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.\n\n    - Scaling: \n\n    For each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.\n\n    - Desired state reconciliation: \n\n    The swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state your expressed desired state. For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager will create two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.\n\n    - Multi-host networking: \n\n    You can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.\n\n    - Service discovery: \n\n    Swarm manager nodes assign each service in the swarm a unique DNS name and load balances running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.\n\n    - Load balancing: \n\n    You can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.\n\n    - Secure by default: \n\n    Each node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.\n\n    - Rolling updates: \n\n    At rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll-back a task to a previous version of the service.\n\n\n# key concepts\n\n- link: https://docs.docker.com/engine/swarm/key-concepts/ (Docker Engine 1.12.)\n\n- What is a swarm?\n\n    The cluster management and orchestration features embedded in the Docker Engine are built using SwarmKit. Docker engines participating in a cluster are running in swarm mode. You enable swarm mode for an engine by either initializing a swarm or joining an existing swarm.\n\n    A swarm is a cluster of Docker engines, or nodes, where you deploy services. The Docker Engine CLI and API include commands to manage swarm nodes (e.g., add or remove nodes), and deploy and orchestrate services across the swarm.\n\n    When you run Docker without using swarm mode, you execute container commands. When you run the Docker in swarm mode, you orchestrate services. You can run swarm services and standalone containers on the same Docker instances.\n\n- What is a node?\n\n    A node is an instance of the Docker engine participating in the swarm. You can also think of this as a Docker node. You can run one or more nodes on a single physical computer or cloud server, but production swarm deployments typically include Docker nodes distributed across multiple physical and cloud machines.\n\n    To deploy your application to a swarm, you submit a service definition to a manager node. The manager node dispatches units of work called tasks to worker nodes.\n\n    Manager nodes also perform the orchestration and cluster management functions required to maintain the desired state of the swarm. Manager nodes elect a single leader to conduct orchestration tasks.\n\n    Worker nodes receive and execute tasks dispatched from manager nodes. By default manager nodes also run services as worker nodes, but you can configure them to run manager tasks exclusively and be manager-only nodes. An agent runs on each worker node and reports on the tasks assigned to it. The worker node notifies the manager node of the current state of its assigned tasks so that the manager can maintain the desired state of each worker.\n\n- Services and tasks\n\n    A service is the definition of the tasks to execute on the worker nodes. It is the central structure of the swarm system and the primary root of user interaction with the swarm.\n\n    When you create a service, you specify which container image to use and which commands to execute inside running containers.\n\n    In the replicated services model, the swarm manager distributes a specific number of replica tasks among the nodes based upon the scale you set in the desired state.\n\n    For global services, the swarm runs one task for the service on every available node in the cluster.\n\n    A task carries a Docker container and the commands to run inside the container. It is the atomic scheduling unit of swarm. Manager nodes assign tasks to worker nodes according to the number of replicas set in the service scale. Once a task is assigned to a node, it cannot move to another node. It can only run on the assigned node or fail.\n\n- Load balancing\n\n    The swarm manager uses ingress load balancing to expose the services you want to make available externally to the swarm. The swarm manager can automatically assign the service a PublishedPort or you can configure a PublishedPort for the service. You can specify any unused port. If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.\n\n    External components, such as cloud load balancers, can access the service on the PublishedPort of any node in the cluster whether or not the node is currently running the task for the service. All nodes in the swarm route ingress connections to a running task instance.\n\n    Swarm mode has an internal DNS component that automatically assigns each service in the swarm a DNS entry. The swarm manager uses internal load balancing to distribute requests among services within the cluster based upon the DNS name of the service.\n\n# docker swarm mode command\n\n- swarm init\n\n- swarm join\n\n- service create\n\n- service inspect\n\n- service ls\n\n- service rm\n\n- service scale\n\n- service ps\n\n- service update","source":"_posts/docker-swarmnext-detail.md","raw":"---\ntitle: docker swarm mode\ncategories:\n- docker\ntags:\n- core\n- swarm\n---\n\n# link\n\n- tut: https://docs.docker.com/engine/swarm/swarm-tutorial/\n\n\n# about\n\nDocker Engine 1.12 includes swarm mode for natively managing a cluster of Docker Engines called a swarm. Use the Docker CLI to create a swarm, deploy application services to a swarm, and manage swarm behavior.\n\n# feature\n\n    - Cluster management integrated with Docker Engine: \n\n    Use the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. You dont need additional orchestration software to create or manage a swarm.\n\n    - Decentralized design: \n\n    Instead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. You can deploy both kinds of nodes, managers and workers, using the Docker Engine. This means you can build an entire swarm from a single disk image.\n\n    - Declarative service model: \n\n    Docker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.\n\n    - Scaling: \n\n    For each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.\n\n    - Desired state reconciliation: \n\n    The swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state your expressed desired state. For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager will create two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.\n\n    - Multi-host networking: \n\n    You can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.\n\n    - Service discovery: \n\n    Swarm manager nodes assign each service in the swarm a unique DNS name and load balances running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.\n\n    - Load balancing: \n\n    You can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.\n\n    - Secure by default: \n\n    Each node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.\n\n    - Rolling updates: \n\n    At rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll-back a task to a previous version of the service.\n\n\n# key concepts\n\n- link: https://docs.docker.com/engine/swarm/key-concepts/ (Docker Engine 1.12.)\n\n- What is a swarm?\n\n    The cluster management and orchestration features embedded in the Docker Engine are built using SwarmKit. Docker engines participating in a cluster are running in swarm mode. You enable swarm mode for an engine by either initializing a swarm or joining an existing swarm.\n\n    A swarm is a cluster of Docker engines, or nodes, where you deploy services. The Docker Engine CLI and API include commands to manage swarm nodes (e.g., add or remove nodes), and deploy and orchestrate services across the swarm.\n\n    When you run Docker without using swarm mode, you execute container commands. When you run the Docker in swarm mode, you orchestrate services. You can run swarm services and standalone containers on the same Docker instances.\n\n- What is a node?\n\n    A node is an instance of the Docker engine participating in the swarm. You can also think of this as a Docker node. You can run one or more nodes on a single physical computer or cloud server, but production swarm deployments typically include Docker nodes distributed across multiple physical and cloud machines.\n\n    To deploy your application to a swarm, you submit a service definition to a manager node. The manager node dispatches units of work called tasks to worker nodes.\n\n    Manager nodes also perform the orchestration and cluster management functions required to maintain the desired state of the swarm. Manager nodes elect a single leader to conduct orchestration tasks.\n\n    Worker nodes receive and execute tasks dispatched from manager nodes. By default manager nodes also run services as worker nodes, but you can configure them to run manager tasks exclusively and be manager-only nodes. An agent runs on each worker node and reports on the tasks assigned to it. The worker node notifies the manager node of the current state of its assigned tasks so that the manager can maintain the desired state of each worker.\n\n- Services and tasks\n\n    A service is the definition of the tasks to execute on the worker nodes. It is the central structure of the swarm system and the primary root of user interaction with the swarm.\n\n    When you create a service, you specify which container image to use and which commands to execute inside running containers.\n\n    In the replicated services model, the swarm manager distributes a specific number of replica tasks among the nodes based upon the scale you set in the desired state.\n\n    For global services, the swarm runs one task for the service on every available node in the cluster.\n\n    A task carries a Docker container and the commands to run inside the container. It is the atomic scheduling unit of swarm. Manager nodes assign tasks to worker nodes according to the number of replicas set in the service scale. Once a task is assigned to a node, it cannot move to another node. It can only run on the assigned node or fail.\n\n- Load balancing\n\n    The swarm manager uses ingress load balancing to expose the services you want to make available externally to the swarm. The swarm manager can automatically assign the service a PublishedPort or you can configure a PublishedPort for the service. You can specify any unused port. If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.\n\n    External components, such as cloud load balancers, can access the service on the PublishedPort of any node in the cluster whether or not the node is currently running the task for the service. All nodes in the swarm route ingress connections to a running task instance.\n\n    Swarm mode has an internal DNS component that automatically assigns each service in the swarm a DNS entry. The swarm manager uses internal load balancing to distribute requests among services within the cluster based upon the DNS name of the service.\n\n# docker swarm mode command\n\n- swarm init\n\n- swarm join\n\n- service create\n\n- service inspect\n\n- service ls\n\n- service rm\n\n- service scale\n\n- service ps\n\n- service update","slug":"docker-swarmnext-detail","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T13:29:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3aw003s21svc9u1t1uj","content":"<h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><ul>\n<li>tut: <a href=\"https://docs.docker.com/engine/swarm/swarm-tutorial/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/engine/swarm/swarm-tutorial/</a></li>\n</ul>\n<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><p>Docker Engine 1.12 includes swarm mode for natively managing a cluster of Docker Engines called a swarm. Use the Docker CLI to create a swarm, deploy application services to a swarm, and manage swarm behavior.</p>\n<h1 id=\"feature\"><a href=\"#feature\" class=\"headerlink\" title=\"feature\"></a>feature</h1><pre><code>- Cluster management integrated with Docker Engine: \n\nUse the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. You dont need additional orchestration software to create or manage a swarm.\n\n- Decentralized design: \n\nInstead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. You can deploy both kinds of nodes, managers and workers, using the Docker Engine. This means you can build an entire swarm from a single disk image.\n\n- Declarative service model: \n\nDocker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.\n\n- Scaling: \n\nFor each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.\n\n- Desired state reconciliation: \n\nThe swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state your expressed desired state. For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager will create two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.\n\n- Multi-host networking: \n\nYou can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.\n\n- Service discovery: \n\nSwarm manager nodes assign each service in the swarm a unique DNS name and load balances running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.\n\n- Load balancing: \n\nYou can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.\n\n- Secure by default: \n\nEach node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.\n\n- Rolling updates: \n\nAt rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll-back a task to a previous version of the service.\n</code></pre><h1 id=\"key-concepts\"><a href=\"#key-concepts\" class=\"headerlink\" title=\"key concepts\"></a>key concepts</h1><ul>\n<li><p>link: <a href=\"https://docs.docker.com/engine/swarm/key-concepts/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/engine/swarm/key-concepts/</a> (Docker Engine 1.12.)</p>\n</li>\n<li><p>What is a swarm?</p>\n<p>  The cluster management and orchestration features embedded in the Docker Engine are built using SwarmKit. Docker engines participating in a cluster are running in swarm mode. You enable swarm mode for an engine by either initializing a swarm or joining an existing swarm.</p>\n<p>  A swarm is a cluster of Docker engines, or nodes, where you deploy services. The Docker Engine CLI and API include commands to manage swarm nodes (e.g., add or remove nodes), and deploy and orchestrate services across the swarm.</p>\n<p>  When you run Docker without using swarm mode, you execute container commands. When you run the Docker in swarm mode, you orchestrate services. You can run swarm services and standalone containers on the same Docker instances.</p>\n</li>\n<li><p>What is a node?</p>\n<p>  A node is an instance of the Docker engine participating in the swarm. You can also think of this as a Docker node. You can run one or more nodes on a single physical computer or cloud server, but production swarm deployments typically include Docker nodes distributed across multiple physical and cloud machines.</p>\n<p>  To deploy your application to a swarm, you submit a service definition to a manager node. The manager node dispatches units of work called tasks to worker nodes.</p>\n<p>  Manager nodes also perform the orchestration and cluster management functions required to maintain the desired state of the swarm. Manager nodes elect a single leader to conduct orchestration tasks.</p>\n<p>  Worker nodes receive and execute tasks dispatched from manager nodes. By default manager nodes also run services as worker nodes, but you can configure them to run manager tasks exclusively and be manager-only nodes. An agent runs on each worker node and reports on the tasks assigned to it. The worker node notifies the manager node of the current state of its assigned tasks so that the manager can maintain the desired state of each worker.</p>\n</li>\n<li><p>Services and tasks</p>\n<p>  A service is the definition of the tasks to execute on the worker nodes. It is the central structure of the swarm system and the primary root of user interaction with the swarm.</p>\n<p>  When you create a service, you specify which container image to use and which commands to execute inside running containers.</p>\n<p>  In the replicated services model, the swarm manager distributes a specific number of replica tasks among the nodes based upon the scale you set in the desired state.</p>\n<p>  For global services, the swarm runs one task for the service on every available node in the cluster.</p>\n<p>  A task carries a Docker container and the commands to run inside the container. It is the atomic scheduling unit of swarm. Manager nodes assign tasks to worker nodes according to the number of replicas set in the service scale. Once a task is assigned to a node, it cannot move to another node. It can only run on the assigned node or fail.</p>\n</li>\n<li><p>Load balancing</p>\n<p>  The swarm manager uses ingress load balancing to expose the services you want to make available externally to the swarm. The swarm manager can automatically assign the service a PublishedPort or you can configure a PublishedPort for the service. You can specify any unused port. If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.</p>\n<p>  External components, such as cloud load balancers, can access the service on the PublishedPort of any node in the cluster whether or not the node is currently running the task for the service. All nodes in the swarm route ingress connections to a running task instance.</p>\n<p>  Swarm mode has an internal DNS component that automatically assigns each service in the swarm a DNS entry. The swarm manager uses internal load balancing to distribute requests among services within the cluster based upon the DNS name of the service.</p>\n</li>\n</ul>\n<h1 id=\"docker-swarm-mode-command\"><a href=\"#docker-swarm-mode-command\" class=\"headerlink\" title=\"docker swarm mode command\"></a>docker swarm mode command</h1><ul>\n<li><p>swarm init</p>\n</li>\n<li><p>swarm join</p>\n</li>\n<li><p>service create</p>\n</li>\n<li><p>service inspect</p>\n</li>\n<li><p>service ls</p>\n</li>\n<li><p>service rm</p>\n</li>\n<li><p>service scale</p>\n</li>\n<li><p>service ps</p>\n</li>\n<li><p>service update</p>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><ul>\n<li>tut: <a href=\"https://docs.docker.com/engine/swarm/swarm-tutorial/\">https://docs.docker.com/engine/swarm/swarm-tutorial/</a></li>\n</ul>\n<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><p>Docker Engine 1.12 includes swarm mode for natively managing a cluster of Docker Engines called a swarm. Use the Docker CLI to create a swarm, deploy application services to a swarm, and manage swarm behavior.</p>\n<h1 id=\"feature\"><a href=\"#feature\" class=\"headerlink\" title=\"feature\"></a>feature</h1><pre><code>- Cluster management integrated with Docker Engine: \n\nUse the Docker Engine CLI to create a swarm of Docker Engines where you can deploy application services. You dont need additional orchestration software to create or manage a swarm.\n\n- Decentralized design: \n\nInstead of handling differentiation between node roles at deployment time, the Docker Engine handles any specialization at runtime. You can deploy both kinds of nodes, managers and workers, using the Docker Engine. This means you can build an entire swarm from a single disk image.\n\n- Declarative service model: \n\nDocker Engine uses a declarative approach to let you define the desired state of the various services in your application stack. For example, you might describe an application comprised of a web front end service with message queueing services and a database backend.\n\n- Scaling: \n\nFor each service, you can declare the number of tasks you want to run. When you scale up or down, the swarm manager automatically adapts by adding or removing tasks to maintain the desired state.\n\n- Desired state reconciliation: \n\nThe swarm manager node constantly monitors the cluster state and reconciles any differences between the actual state your expressed desired state. For example, if you set up a service to run 10 replicas of a container, and a worker machine hosting two of those replicas crashes, the manager will create two new replicas to replace the replicas that crashed. The swarm manager assigns the new replicas to workers that are running and available.\n\n- Multi-host networking: \n\nYou can specify an overlay network for your services. The swarm manager automatically assigns addresses to the containers on the overlay network when it initializes or updates the application.\n\n- Service discovery: \n\nSwarm manager nodes assign each service in the swarm a unique DNS name and load balances running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.\n\n- Load balancing: \n\nYou can expose the ports for services to an external load balancer. Internally, the swarm lets you specify how to distribute service containers between nodes.\n\n- Secure by default: \n\nEach node in the swarm enforces TLS mutual authentication and encryption to secure communications between itself and all other nodes. You have the option to use self-signed root certificates or certificates from a custom root CA.\n\n- Rolling updates: \n\nAt rollout time you can apply service updates to nodes incrementally. The swarm manager lets you control the delay between service deployment to different sets of nodes. If anything goes wrong, you can roll-back a task to a previous version of the service.\n</code></pre><h1 id=\"key-concepts\"><a href=\"#key-concepts\" class=\"headerlink\" title=\"key concepts\"></a>key concepts</h1><ul>\n<li><p>link: <a href=\"https://docs.docker.com/engine/swarm/key-concepts/\">https://docs.docker.com/engine/swarm/key-concepts/</a> (Docker Engine 1.12.)</p>\n</li>\n<li><p>What is a swarm?</p>\n<p>  The cluster management and orchestration features embedded in the Docker Engine are built using SwarmKit. Docker engines participating in a cluster are running in swarm mode. You enable swarm mode for an engine by either initializing a swarm or joining an existing swarm.</p>\n<p>  A swarm is a cluster of Docker engines, or nodes, where you deploy services. The Docker Engine CLI and API include commands to manage swarm nodes (e.g., add or remove nodes), and deploy and orchestrate services across the swarm.</p>\n<p>  When you run Docker without using swarm mode, you execute container commands. When you run the Docker in swarm mode, you orchestrate services. You can run swarm services and standalone containers on the same Docker instances.</p>\n</li>\n<li><p>What is a node?</p>\n<p>  A node is an instance of the Docker engine participating in the swarm. You can also think of this as a Docker node. You can run one or more nodes on a single physical computer or cloud server, but production swarm deployments typically include Docker nodes distributed across multiple physical and cloud machines.</p>\n<p>  To deploy your application to a swarm, you submit a service definition to a manager node. The manager node dispatches units of work called tasks to worker nodes.</p>\n<p>  Manager nodes also perform the orchestration and cluster management functions required to maintain the desired state of the swarm. Manager nodes elect a single leader to conduct orchestration tasks.</p>\n<p>  Worker nodes receive and execute tasks dispatched from manager nodes. By default manager nodes also run services as worker nodes, but you can configure them to run manager tasks exclusively and be manager-only nodes. An agent runs on each worker node and reports on the tasks assigned to it. The worker node notifies the manager node of the current state of its assigned tasks so that the manager can maintain the desired state of each worker.</p>\n</li>\n<li><p>Services and tasks</p>\n<p>  A service is the definition of the tasks to execute on the worker nodes. It is the central structure of the swarm system and the primary root of user interaction with the swarm.</p>\n<p>  When you create a service, you specify which container image to use and which commands to execute inside running containers.</p>\n<p>  In the replicated services model, the swarm manager distributes a specific number of replica tasks among the nodes based upon the scale you set in the desired state.</p>\n<p>  For global services, the swarm runs one task for the service on every available node in the cluster.</p>\n<p>  A task carries a Docker container and the commands to run inside the container. It is the atomic scheduling unit of swarm. Manager nodes assign tasks to worker nodes according to the number of replicas set in the service scale. Once a task is assigned to a node, it cannot move to another node. It can only run on the assigned node or fail.</p>\n</li>\n<li><p>Load balancing</p>\n<p>  The swarm manager uses ingress load balancing to expose the services you want to make available externally to the swarm. The swarm manager can automatically assign the service a PublishedPort or you can configure a PublishedPort for the service. You can specify any unused port. If you do not specify a port, the swarm manager assigns the service a port in the 30000-32767 range.</p>\n<p>  External components, such as cloud load balancers, can access the service on the PublishedPort of any node in the cluster whether or not the node is currently running the task for the service. All nodes in the swarm route ingress connections to a running task instance.</p>\n<p>  Swarm mode has an internal DNS component that automatically assigns each service in the swarm a DNS entry. The swarm manager uses internal load balancing to distribute requests among services within the cluster based upon the DNS name of the service.</p>\n</li>\n</ul>\n<h1 id=\"docker-swarm-mode-command\"><a href=\"#docker-swarm-mode-command\" class=\"headerlink\" title=\"docker swarm mode command\"></a>docker swarm mode command</h1><ul>\n<li><p>swarm init</p>\n</li>\n<li><p>swarm join</p>\n</li>\n<li><p>service create</p>\n</li>\n<li><p>service inspect</p>\n</li>\n<li><p>service ls</p>\n</li>\n<li><p>service rm</p>\n</li>\n<li><p>service scale</p>\n</li>\n<li><p>service ps</p>\n</li>\n<li><p>service update</p>\n</li>\n</ul>\n"},{"title":"openstack core","_content":"\n# core","source":"_posts/iot-portal.md","raw":"---\ntitle: openstack core\ncategories:\n- iaas\ntags:\n- core\n- openstack\n---\n\n# core","slug":"iot-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3ay003w21svpn73kvxk","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"cloud architect portal","_content":"\n# about cloud architect\n\n# resource\n\n","source":"_posts/jd-architect-portal.md","raw":"---\ntitle: cloud architect portal\ncategories:\n- cloud\ntags:\n- portal\n- architect\n---\n\n# about cloud architect\n\n# resource\n\n","slug":"jd-architect-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T11:48:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3b2004021svioptmeei","content":"<h1 id=\"about-cloud-architect\"><a href=\"#about-cloud-architect\" class=\"headerlink\" title=\"about cloud architect\"></a>about cloud architect</h1><h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1>","excerpt":"","more":"<h1 id=\"about-cloud-architect\"><a href=\"#about-cloud-architect\" class=\"headerlink\" title=\"about cloud architect\"></a>about cloud architect</h1><h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1>"},{"title":"python portal","_content":"\n# 123","source":"_posts/jd-fullstack-portal.md","raw":"---\ntitle: python portal\ncategories:\n- python\ntags:\n- portal\n---\n\n# 123","slug":"jd-fullstack-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:35:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3b4004421svqhoqjae5","content":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>","excerpt":"","more":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>"},{"title":"cloud architect portal","_content":"\n# about cloud architect\n\n# resource\n\n","source":"_posts/jd--portal.md","raw":"---\ntitle: cloud architect portal\ncategories:\n- cloud\ntags:\n- portal\n- architect\n---\n\n# about cloud architect\n\n# resource\n\n","slug":"jd--portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-13T11:48:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3b7004721sv1225ic1c","content":"<h1 id=\"about-cloud-architect\"><a href=\"#about-cloud-architect\" class=\"headerlink\" title=\"about cloud architect\"></a>about cloud architect</h1><h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1>","excerpt":"","more":"<h1 id=\"about-cloud-architect\"><a href=\"#about-cloud-architect\" class=\"headerlink\" title=\"about cloud architect\"></a>about cloud architect</h1><h1 id=\"resource\"><a href=\"#resource\" class=\"headerlink\" title=\"resource\"></a>resource</h1>"},{"title":"cx portal","_content":"\n","source":"_posts/lang--portal.md","raw":"---\ntitle: cx portal\ncategories:\n- cx\ntags:\n- portal\n---\n\n","slug":"lang--portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:31:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3ba004c21svocwumvw5","content":"","excerpt":"","more":""},{"title":"cx portal","_content":"\n","source":"_posts/lang-cx-portal.md","raw":"---\ntitle: cx portal\ncategories:\n- cx\ntags:\n- portal\n---\n\n","slug":"lang-cx-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:31:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3bc004f21svgewuytn4","content":"","excerpt":"","more":""},{"title":"java portal","_content":"\n#  portal","source":"_posts/lang-java-portal.md","raw":"---\ntitle: java portal\ncategories:\n- java\ntags:\n- portal\n---\n\n#  portal","slug":"lang-java-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3be004k21svfutfhg13","content":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>","excerpt":"","more":"<h1 id=\"portal\"><a href=\"#portal\" class=\"headerlink\" title=\"portal\"></a>portal</h1>"},{"title":"nodejs core","_content":"\n\n        ","source":"_posts/lang-js-nodejs-core.md","raw":"---\ntitle: nodejs core\ncategories:\n- nodejs\ntags:\n- core\n---\n\n\n        ","slug":"lang-js-nodejs-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3bg004n21sv7l1ddxrz","content":"","excerpt":"","more":""},{"title":"js portal","_content":"\n\n        ","source":"_posts/lang-js-portal.md","raw":"---\ntitle: js portal\ncategories:\n- js\ntags:\n- portal\n---\n\n\n        ","slug":"lang-js-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:33:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3bj004r21svidlm72tf","content":"","excerpt":"","more":""},{"title":"django core","_content":"\n# about\n\n    Full stack web frameworks.The most popular web framework in Python.\n\n    Django makes it easier to build better Web apps more quickly and with less code.\n    \n    Django is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. Its free and open source.\n\n    Ridiculously fast: Django was designed to help developers take applications from concept to completion as quickly as possible.\n\n    Reassuringly secure: Django takes security seriously and helps developers avoid many common security mistakes.\n\n    Exceedingly scalable: Some of the busiest sites on the Web leverage Djangos ability to quickly and flexibly scale.\n\n# link\n\n    - official: https://www.djangoproject.com/\n    - tut: https://docs.djangoproject.com/en/1.10/intro/tutorial01/\n    - awesome: https://github.com/rosarior/awesome-django\n    - community: http://django-china.cn/\n\n# install\n\n    - [install on mac (bare metal)]()\n    - [install on mac (docker)]()\n\n# read\n\n    - djangobook: http://docs.30c.org/djangobook2/; http://djangobook.py3k.cn/2.0/\n\n# mooc\n    \n    - http://www.imooc.com/learn/790\n\n    \n\n","source":"_posts/lang-python-django-core.md","raw":"---\ntitle: django core\ncategories:\n- python\ntags:\n- core\n- django\n---\n\n# about\n\n    Full stack web frameworks.The most popular web framework in Python.\n\n    Django makes it easier to build better Web apps more quickly and with less code.\n    \n    Django is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. Its free and open source.\n\n    Ridiculously fast: Django was designed to help developers take applications from concept to completion as quickly as possible.\n\n    Reassuringly secure: Django takes security seriously and helps developers avoid many common security mistakes.\n\n    Exceedingly scalable: Some of the busiest sites on the Web leverage Djangos ability to quickly and flexibly scale.\n\n# link\n\n    - official: https://www.djangoproject.com/\n    - tut: https://docs.djangoproject.com/en/1.10/intro/tutorial01/\n    - awesome: https://github.com/rosarior/awesome-django\n    - community: http://django-china.cn/\n\n# install\n\n    - [install on mac (bare metal)]()\n    - [install on mac (docker)]()\n\n# read\n\n    - djangobook: http://docs.30c.org/djangobook2/; http://djangobook.py3k.cn/2.0/\n\n# mooc\n    \n    - http://www.imooc.com/learn/790\n\n    \n\n","slug":"lang-python-django-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-12T09:47:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3bo004u21sve7kv8amn","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><pre><code>Full stack web frameworks.The most popular web framework in Python.\n\nDjango makes it easier to build better Web apps more quickly and with less code.\n\nDjango is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. Its free and open source.\n\nRidiculously fast: Django was designed to help developers take applications from concept to completion as quickly as possible.\n\nReassuringly secure: Django takes security seriously and helps developers avoid many common security mistakes.\n\nExceedingly scalable: Some of the busiest sites on the Web leverage Djangos ability to quickly and flexibly scale.\n</code></pre><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>- official: https://www.djangoproject.com/\n- tut: https://docs.djangoproject.com/en/1.10/intro/tutorial01/\n- awesome: https://github.com/rosarior/awesome-django\n- community: http://django-china.cn/\n</code></pre><h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><pre><code>- [install on mac (bare metal)]()\n- [install on mac (docker)]()\n</code></pre><h1 id=\"read\"><a href=\"#read\" class=\"headerlink\" title=\"read\"></a>read</h1><pre><code>- djangobook: http://docs.30c.org/djangobook2/; http://djangobook.py3k.cn/2.0/\n</code></pre><h1 id=\"mooc\"><a href=\"#mooc\" class=\"headerlink\" title=\"mooc\"></a>mooc</h1><pre><code>- http://www.imooc.com/learn/790\n</code></pre>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><pre><code>Full stack web frameworks.The most popular web framework in Python.\n\nDjango makes it easier to build better Web apps more quickly and with less code.\n\nDjango is a high-level Python Web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of Web development, so you can focus on writing your app without needing to reinvent the wheel. Its free and open source.\n\nRidiculously fast: Django was designed to help developers take applications from concept to completion as quickly as possible.\n\nReassuringly secure: Django takes security seriously and helps developers avoid many common security mistakes.\n\nExceedingly scalable: Some of the busiest sites on the Web leverage Djangos ability to quickly and flexibly scale.\n</code></pre><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>- official: https://www.djangoproject.com/\n- tut: https://docs.djangoproject.com/en/1.10/intro/tutorial01/\n- awesome: https://github.com/rosarior/awesome-django\n- community: http://django-china.cn/\n</code></pre><h1 id=\"install\"><a href=\"#install\" class=\"headerlink\" title=\"install\"></a>install</h1><pre><code>- [install on mac (bare metal)]()\n- [install on mac (docker)]()\n</code></pre><h1 id=\"read\"><a href=\"#read\" class=\"headerlink\" title=\"read\"></a>read</h1><pre><code>- djangobook: http://docs.30c.org/djangobook2/; http://djangobook.py3k.cn/2.0/\n</code></pre><h1 id=\"mooc\"><a href=\"#mooc\" class=\"headerlink\" title=\"mooc\"></a>mooc</h1><pre><code>- http://www.imooc.com/learn/790\n</code></pre>"},{"title":"install django on mac","update":"2017-01-12T09:43:23.000Z","_content":"\n# install on mac (bare metal)\n\n# install on mac (docker)\n- download & install docker for mac;\n    - link: https://docs.docker.com/compose/django/;\n    - Define the project components;\n        1. create folder;\n        2. create Dockerfile;\n            ```\n             FROM python:2.7\n             ENV PYTHONUNBUFFERED 1\n             RUN mkdir /code\n             WORKDIR /code\n             ADD requirements.txt /code/\n             RUN pip install -r requirements.txt\n             ADD . /code/\n            ```\n        3. create requirements.txt;\n            ```\n             Django\n             psycopg2\n            ```\n        4. create docker-compose.yml\n            ```\n             version: '2'\n             services:\n               db:\n                 image: postgres\n               web:\n                 build: .\n                 command: python manage.py runserver 0.0.0.0:8000\n                 volumes:\n                   - .:/code\n                 ports:\n                   - \"8000:8000\"\n                 depends_on:\n                   - db\n            ```\n    - Create a Django project;\n        1. goto root dir;\n        2. docker-compose run web django-admin.py startproject composeexample .\n        3. ls -l; sudo chown -R $USER:$USER .;\n    - Connect the database;\n        1. edit composeexample/settings.py;\n        ```\n        DATABASES = {\n             'default': {\n                 'ENGINE': 'django.db.backends.postgresql',\n                 'NAME': 'postgres',\n                 'USER': 'postgres',\n                 'HOST': 'db',\n                 'PORT': 5432,\n             }\n         }\n        ```\n        2. $ docker-compose up","source":"_posts/lang-python-django-install.md","raw":"---\ntitle: install django on mac\nupdate: 2017-01-12 17:43:23\ncategories:\n- python\ntags: \n- install\n- python\n- django\n- docker\n---\n\n# install on mac (bare metal)\n\n# install on mac (docker)\n- download & install docker for mac;\n    - link: https://docs.docker.com/compose/django/;\n    - Define the project components;\n        1. create folder;\n        2. create Dockerfile;\n            ```\n             FROM python:2.7\n             ENV PYTHONUNBUFFERED 1\n             RUN mkdir /code\n             WORKDIR /code\n             ADD requirements.txt /code/\n             RUN pip install -r requirements.txt\n             ADD . /code/\n            ```\n        3. create requirements.txt;\n            ```\n             Django\n             psycopg2\n            ```\n        4. create docker-compose.yml\n            ```\n             version: '2'\n             services:\n               db:\n                 image: postgres\n               web:\n                 build: .\n                 command: python manage.py runserver 0.0.0.0:8000\n                 volumes:\n                   - .:/code\n                 ports:\n                   - \"8000:8000\"\n                 depends_on:\n                   - db\n            ```\n    - Create a Django project;\n        1. goto root dir;\n        2. docker-compose run web django-admin.py startproject composeexample .\n        3. ls -l; sudo chown -R $USER:$USER .;\n    - Connect the database;\n        1. edit composeexample/settings.py;\n        ```\n        DATABASES = {\n             'default': {\n                 'ENGINE': 'django.db.backends.postgresql',\n                 'NAME': 'postgres',\n                 'USER': 'postgres',\n                 'HOST': 'db',\n                 'PORT': 5432,\n             }\n         }\n        ```\n        2. $ docker-compose up","slug":"lang-python-django-install","published":1,"date":"2017-01-12T09:43:23.000Z","updated":"2017-01-12T09:49:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3bs004x21svpb3i7i4k","content":"<h1 id=\"install-on-mac-bare-metal\"><a href=\"#install-on-mac-bare-metal\" class=\"headerlink\" title=\"install on mac (bare metal)\"></a>install on mac (bare metal)</h1><h1 id=\"install-on-mac-docker\"><a href=\"#install-on-mac-docker\" class=\"headerlink\" title=\"install on mac (docker)\"></a>install on mac (docker)</h1><ul>\n<li><p>download &amp; install docker for mac;</p>\n<ul>\n<li>link: <a href=\"https://docs.docker.com/compose/django/\" target=\"_blank\" rel=\"external\">https://docs.docker.com/compose/django/</a>;</li>\n<li><p>Define the project components;</p>\n<ol>\n<li>create folder;</li>\n<li><p>create Dockerfile;</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">FROM python:2.7</div><div class=\"line\">ENV PYTHONUNBUFFERED 1</div><div class=\"line\">RUN mkdir /code</div><div class=\"line\">WORKDIR /code</div><div class=\"line\">ADD requirements.txt /code/</div><div class=\"line\">RUN pip install -r requirements.txt</div><div class=\"line\">ADD . /code/</div></pre></td></tr></table></figure>\n</li>\n<li><p>create requirements.txt;</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Django</div><div class=\"line\">psycopg2</div></pre></td></tr></table></figure>\n</li>\n<li><p>create docker-compose.yml</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">version: &apos;2&apos;</div><div class=\"line\">services:</div><div class=\"line\">  db:</div><div class=\"line\">    image: postgres</div><div class=\"line\">  web:</div><div class=\"line\">    build: .</div><div class=\"line\">    command: python manage.py runserver 0.0.0.0:8000</div><div class=\"line\">    volumes:</div><div class=\"line\">      - .:/code</div><div class=\"line\">    ports:</div><div class=\"line\">      - &quot;8000:8000&quot;</div><div class=\"line\">    depends_on:</div><div class=\"line\">      - db</div></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>Create a Django project;</p>\n<ol>\n<li>goto root dir;</li>\n<li>docker-compose run web django-admin.py startproject composeexample .</li>\n<li>ls -l; sudo chown -R $USER:$USER .;</li>\n</ol>\n</li>\n<li><p>Connect the database;</p>\n<ol>\n<li><p>edit composeexample/settings.py;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">DATABASES = &#123;</div><div class=\"line\">     &apos;default&apos;: &#123;</div><div class=\"line\">         &apos;ENGINE&apos;: &apos;django.db.backends.postgresql&apos;,</div><div class=\"line\">         &apos;NAME&apos;: &apos;postgres&apos;,</div><div class=\"line\">         &apos;USER&apos;: &apos;postgres&apos;,</div><div class=\"line\">         &apos;HOST&apos;: &apos;db&apos;,</div><div class=\"line\">         &apos;PORT&apos;: 5432,</div><div class=\"line\">     &#125;</div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>$ docker-compose up</p>\n</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"install-on-mac-bare-metal\"><a href=\"#install-on-mac-bare-metal\" class=\"headerlink\" title=\"install on mac (bare metal)\"></a>install on mac (bare metal)</h1><h1 id=\"install-on-mac-docker\"><a href=\"#install-on-mac-docker\" class=\"headerlink\" title=\"install on mac (docker)\"></a>install on mac (docker)</h1><ul>\n<li><p>download &amp; install docker for mac;</p>\n<ul>\n<li>link: <a href=\"https://docs.docker.com/compose/django/\">https://docs.docker.com/compose/django/</a>;</li>\n<li><p>Define the project components;</p>\n<ol>\n<li>create folder;</li>\n<li><p>create Dockerfile;</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">FROM python:2.7</div><div class=\"line\">ENV PYTHONUNBUFFERED 1</div><div class=\"line\">RUN mkdir /code</div><div class=\"line\">WORKDIR /code</div><div class=\"line\">ADD requirements.txt /code/</div><div class=\"line\">RUN pip install -r requirements.txt</div><div class=\"line\">ADD . /code/</div></pre></td></tr></table></figure>\n</li>\n<li><p>create requirements.txt;</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Django</div><div class=\"line\">psycopg2</div></pre></td></tr></table></figure>\n</li>\n<li><p>create docker-compose.yml</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">version: &apos;2&apos;</div><div class=\"line\">services:</div><div class=\"line\">  db:</div><div class=\"line\">    image: postgres</div><div class=\"line\">  web:</div><div class=\"line\">    build: .</div><div class=\"line\">    command: python manage.py runserver 0.0.0.0:8000</div><div class=\"line\">    volumes:</div><div class=\"line\">      - .:/code</div><div class=\"line\">    ports:</div><div class=\"line\">      - &quot;8000:8000&quot;</div><div class=\"line\">    depends_on:</div><div class=\"line\">      - db</div></pre></td></tr></table></figure>\n</li>\n</ol>\n</li>\n<li><p>Create a Django project;</p>\n<ol>\n<li>goto root dir;</li>\n<li>docker-compose run web django-admin.py startproject composeexample .</li>\n<li>ls -l; sudo chown -R $USER:$USER .;</li>\n</ol>\n</li>\n<li><p>Connect the database;</p>\n<ol>\n<li><p>edit composeexample/settings.py;</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">DATABASES = &#123;</div><div class=\"line\">     &apos;default&apos;: &#123;</div><div class=\"line\">         &apos;ENGINE&apos;: &apos;django.db.backends.postgresql&apos;,</div><div class=\"line\">         &apos;NAME&apos;: &apos;postgres&apos;,</div><div class=\"line\">         &apos;USER&apos;: &apos;postgres&apos;,</div><div class=\"line\">         &apos;HOST&apos;: &apos;db&apos;,</div><div class=\"line\">         &apos;PORT&apos;: 5432,</div><div class=\"line\">     &#125;</div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>$ docker-compose up</p>\n</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"python portal","_content":"\n# about\n\n# link\n\n    - official: \n    - pep: http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/python_style_rules/Python\n    - awesome\n    https://github.com/vinta/awesome-python\n    https://github.com/Junnplus/awesome-python-books\n","source":"_posts/lang-python-portal.md","raw":"---\ntitle: python portal\ncategories:\n- python\ntags:\n- portal\n---\n\n# about\n\n# link\n\n    - official: \n    - pep: http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/python_style_rules/Python\n    - awesome\n    https://github.com/vinta/awesome-python\n    https://github.com/Junnplus/awesome-python-books\n","slug":"lang-python-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-12T09:42:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3bw005221sv9xsoxqtn","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>- official: \n- pep: http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/python_style_rules/Python\n- awesome\nhttps://github.com/vinta/awesome-python\nhttps://github.com/Junnplus/awesome-python-books\n</code></pre>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>- official: \n- pep: http://zh-google-styleguide.readthedocs.org/en/latest/google-python-styleguide/python_style_rules/Python\n- awesome\nhttps://github.com/vinta/awesome-python\nhttps://github.com/Junnplus/awesome-python-books\n</code></pre>"},{"title":"microservice portal","_content":"\n# about\n\n- current\n\n    - \n\n            \n            \n    \n    - \n\n            monolith\n            java warrailsnode\n            \n            \n            \n\n- \n\n    - \n\n            \n            \n                \n            \n                \n            \n                \n            \n                \n                \n            \n                \n                \n                \n\n    - \n\n            \n            \n            \n            \n            \n\n# link\n\n    main: http://microservices.io/patterns/microservices.html\n    http://microservices.io/\n\n# project\n\n    iron.io: Microservices For The Enterprise\n    http://www.iron.io/ \n\n# clusterup\n\n    about\n        life cycle management GUI for docker microservices\n        Real-time monitoring of Docker containers and applications\n        Manage and monitor your app pre-production. We provide app analytics\n    link\n        https://clusterup.io/\n        ","source":"_posts/microservice-portal.md","raw":"---\ntitle: microservice portal\ncategories:\n- microservice\ntags:\n- portal\n---\n\n# about\n\n- current\n\n    - \n\n            \n            \n    \n    - \n\n            monolith\n            java warrailsnode\n            \n            \n            \n\n- \n\n    - \n\n            \n            \n                \n            \n                \n            \n                \n            \n                \n                \n            \n                \n                \n                \n\n    - \n\n            \n            \n            \n            \n            \n\n# link\n\n    main: http://microservices.io/patterns/microservices.html\n    http://microservices.io/\n\n# project\n\n    iron.io: Microservices For The Enterprise\n    http://www.iron.io/ \n\n# clusterup\n\n    about\n        life cycle management GUI for docker microservices\n        Real-time monitoring of Docker containers and applications\n        Manage and monitor your app pre-production. We provide app analytics\n    link\n        https://clusterup.io/\n        ","slug":"microservice-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T05:29:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3bz005521sv6q6whiyk","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li><p>current</p>\n<ul>\n<li><p></p>\n<pre><code>\n\n</code></pre></li>\n<li><p></p>\n<pre><code>monolith\njava warrailsnode\n\n\n\n</code></pre></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<pre><code>\n\n    \n\n    \n\n    \n\n    \n    \n\n    \n    \n    \n</code></pre></li>\n<li><p></p>\n<pre><code>\n\n\n\n\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>main: http://microservices.io/patterns/microservices.html\nhttp://microservices.io/\n</code></pre><h1 id=\"project\"><a href=\"#project\" class=\"headerlink\" title=\"project\"></a>project</h1><pre><code>iron.io: Microservices For The Enterprise\nhttp://www.iron.io/ \n</code></pre><h1 id=\"clusterup\"><a href=\"#clusterup\" class=\"headerlink\" title=\"clusterup\"></a>clusterup</h1><pre><code>about\n    life cycle management GUI for docker microservices\n    Real-time monitoring of Docker containers and applications\n    Manage and monitor your app pre-production. We provide app analytics\nlink\n    https://clusterup.io/\n</code></pre>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><ul>\n<li><p>current</p>\n<ul>\n<li><p></p>\n<pre><code>\n\n</code></pre></li>\n<li><p></p>\n<pre><code>monolith\njava warrailsnode\n\n\n\n</code></pre></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<pre><code>\n\n    \n\n    \n\n    \n\n    \n    \n\n    \n    \n    \n</code></pre></li>\n<li><p></p>\n<pre><code>\n\n\n\n\n</code></pre></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"link\"><a href=\"#link\" class=\"headerlink\" title=\"link\"></a>link</h1><pre><code>main: http://microservices.io/patterns/microservices.html\nhttp://microservices.io/\n</code></pre><h1 id=\"project\"><a href=\"#project\" class=\"headerlink\" title=\"project\"></a>project</h1><pre><code>iron.io: Microservices For The Enterprise\nhttp://www.iron.io/ \n</code></pre><h1 id=\"clusterup\"><a href=\"#clusterup\" class=\"headerlink\" title=\"clusterup\"></a>clusterup</h1><pre><code>about\n    life cycle management GUI for docker microservices\n    Real-time monitoring of Docker containers and applications\n    Manage and monitor your app pre-production. We provide app analytics\nlink\n    https://clusterup.io/\n</code></pre>"},{"title":"ruby on rails core","_content":"\n# 123","source":"_posts/lang-ruby-rails-core.md","raw":"---\ntitle: ruby on rails core\ncategories:\n- ruby\ntags:\n- core\n- rails\n---\n\n# 123","slug":"lang-ruby-rails-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:36:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3c2005921sv50p1s021","content":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>","excerpt":"","more":"<h1 id=\"123\"><a href=\"#123\" class=\"headerlink\" title=\"123\"></a>123</h1>"},{"title":"http core","_content":"\n#  core","source":"_posts/network-http-core.md","raw":"---\ntitle: http core\ncategories:\n- network\ntags:\n- core\n- http\n---\n\n#  core","slug":"network-http-core","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:34:31.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3c4005d21sv93q4gepl","content":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>","excerpt":"","more":"<h1 id=\"core\"><a href=\"#core\" class=\"headerlink\" title=\"core\"></a>core</h1>"},{"title":"network portal","_content":"\n# about\n\n\n# websocket\n","source":"_posts/network-portal.md","raw":"---\ntitle: network portal\ncategories:\n- network\ntags:\n- portal\n---\n\n# about\n\n\n# websocket\n","slug":"network-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-15T13:29:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3c7005h21svamd3gs1p","content":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"websocket\"><a href=\"#websocket\" class=\"headerlink\" title=\"websocket\"></a>websocket</h1>","excerpt":"","more":"<h1 id=\"about\"><a href=\"#about\" class=\"headerlink\" title=\"about\"></a>about</h1><h1 id=\"websocket\"><a href=\"#websocket\" class=\"headerlink\" title=\"websocket\"></a>websocket</h1>"},{"title":"linux portal","_content":"\n#  ","source":"_posts/system-linux-portal.md","raw":"---\ntitle: linux portal\ncategories:\n- linux\ntags:\n- portal\n---\n\n#  ","slug":"system-linux-portal","published":1,"date":"2017-01-11T14:06:12.000Z","updated":"2017-01-11T16:34:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciypwm3cb005l21svlf0gc6a4","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h1>","excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h1>"}],"PostAsset":[],"PostCategory":[{"post_id":"ciypwm370000621sv5wqww7o5","category_id":"ciypwm36s000321sv2ayq74mg","_id":"ciypwm37f000c21sv2in622km"},{"post_id":"ciypwm36l000121sv4vi8ieps","category_id":"ciypwm36s000321sv2ayq74mg","_id":"ciypwm37k000h21sv2rz3wkhl"},{"post_id":"ciypwm373000721sve8sra0p8","category_id":"ciypwm36s000321sv2ayq74mg","_id":"ciypwm37n000k21svh1v35cu8"},{"post_id":"ciypwm36p000221svq1phbbk0","category_id":"ciypwm36s000321sv2ayq74mg","_id":"ciypwm37r000p21svxoyermy2"},{"post_id":"ciypwm36y000521svf4gipt4m","category_id":"ciypwm36s000321sv2ayq74mg","_id":"ciypwm37v000t21svxfxwbwdz"},{"post_id":"ciypwm37s000r21svd81wuly4","category_id":"ciypwm37q000n21sv6dlm59y0","_id":"ciypwm380000z21svrp0qp30g"},{"post_id":"ciypwm37b000b21svs9suqb35","category_id":"ciypwm37q000n21sv6dlm59y0","_id":"ciypwm386001421svy7qnw6ow"},{"post_id":"ciypwm37g000e21sv4w08jqwz","category_id":"ciypwm37x000v21svrncf6pj1","_id":"ciypwm38e001921svvzpfj3wu"},{"post_id":"ciypwm37k000j21svx26uzv21","category_id":"ciypwm37q000n21sv6dlm59y0","_id":"ciypwm38k001g21sv7ribpger"},{"post_id":"ciypwm38b001821svqerj6t12","category_id":"ciypwm37q000n21sv6dlm59y0","_id":"ciypwm38o001l21svbbd3dx99"},{"post_id":"ciypwm37n000m21svlowv6kfh","category_id":"ciypwm37x000v21svrncf6pj1","_id":"ciypwm38q001o21svkwebhqmb"},{"post_id":"ciypwm37v000u21svtfny6hag","category_id":"ciypwm38k001h21svxlgxac0o","_id":"ciypwm390001v21sv5xbutbf0"},{"post_id":"ciypwm37z000y21sv7ku7mwqz","category_id":"ciypwm38k001h21svxlgxac0o","_id":"ciypwm396002221sv9m6lwult"},{"post_id":"ciypwm381001121svtap4yfqx","category_id":"ciypwm38k001h21svxlgxac0o","_id":"ciypwm39c002921svdo50m0mz"},{"post_id":"ciypwm39a002821svvdj89we5","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm39h002g21svd8575f2r"},{"post_id":"ciypwm387001621sv0tyyvktn","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm39l002l21sv3qvwb52d"},{"post_id":"ciypwm39c002b21svtsnp2crr","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm39o002o21sv43kxy575"},{"post_id":"ciypwm39e002f21svqd89nzvh","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm39s002s21svgisawsid"},{"post_id":"ciypwm38f001d21svebn6o2x0","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm39x002v21sv6um6u400"},{"post_id":"ciypwm39i002i21sv9msto5pk","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3a2003021svvbegg3ew"},{"post_id":"ciypwm39m002n21svzvub4bz1","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3ad003321svfkzibr6y"},{"post_id":"ciypwm38h001f21sv8w2usj1k","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3ah003721svgctupmel"},{"post_id":"ciypwm39p002q21svs69ki7jr","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3ak003b21svezheb98a"},{"post_id":"ciypwm39s002u21svylq4icy5","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3am003f21svyfb1bso1"},{"post_id":"ciypwm38l001k21svmq9vzpvt","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3ao003j21svykzf8kik"},{"post_id":"ciypwm39x002x21svqqrk3m16","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3aq003n21sv57qqwtj4"},{"post_id":"ciypwm3a2003221svf7toen7b","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3av003q21sv4655peal"},{"post_id":"ciypwm38t001s21svt0sqa4iq","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3ax003u21svml52h4kq"},{"post_id":"ciypwm3ae003521svyblhs7lq","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3b1003y21svizhfs2et"},{"post_id":"ciypwm3ai003921sv5f0f4edv","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3b4004221svxr2czuu1"},{"post_id":"ciypwm38y001u21svs7mji43n","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3b6004521svmhcjtgvs"},{"post_id":"ciypwm3al003d21svs6i4yavl","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3b9004a21sv6b26t5hr"},{"post_id":"ciypwm3an003h21sv7b0gw30l","category_id":"ciypwm37x000v21svrncf6pj1","_id":"ciypwm3bc004d21sv2fk442tj"},{"post_id":"ciypwm391001y21svngtxbmr2","category_id":"ciypwm3am003e21svty5ib55t","_id":"ciypwm3be004h21sv0onu7yv3"},{"post_id":"ciypwm3ao003l21svrwyk2i8l","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3bf004l21sv9592jem1"},{"post_id":"ciypwm394002121svo7zb0zb3","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3bi004o21svkpp36ghb"},{"post_id":"ciypwm3aw003s21svc9u1t1uj","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3bo004s21sv0cjth70b"},{"post_id":"ciypwm3ay003w21svpn73kvxk","category_id":"ciypwm37x000v21svrncf6pj1","_id":"ciypwm3br004v21svmuq2po06"},{"post_id":"ciypwm396002521svmkmo7uob","category_id":"ciypwm396002421svh3qvjzup","_id":"ciypwm3bv005021svqe9z702f"},{"post_id":"ciypwm3b4004421svqhoqjae5","category_id":"ciypwm36s000321sv2ayq74mg","_id":"ciypwm3by005321svq3h76wzi"},{"post_id":"ciypwm3as003p21sv6fbp39yp","category_id":"ciypwm3b3004121svtkx85z4d","_id":"ciypwm3c1005721sv6rxllkw4"},{"post_id":"ciypwm3b2004021svioptmeei","category_id":"ciypwm3b9004921svnu7nqm17","_id":"ciypwm3c4005b21sv833gpiuv"},{"post_id":"ciypwm3be004k21svfutfhg13","category_id":"ciypwm38k001h21svxlgxac0o","_id":"ciypwm3c7005f21sv8sqlhn2u"},{"post_id":"ciypwm3b7004721sv1225ic1c","category_id":"ciypwm3b9004921svnu7nqm17","_id":"ciypwm3cb005j21svgn3httg0"},{"post_id":"ciypwm3bo004u21sve7kv8amn","category_id":"ciypwm36s000321sv2ayq74mg","_id":"ciypwm3cd005n21svt30z6gya"},{"post_id":"ciypwm3ba004c21svocwumvw5","category_id":"ciypwm3bj004q21sve4wap485","_id":"ciypwm3cd005q21svuo138kpp"},{"post_id":"ciypwm3bs004x21svpb3i7i4k","category_id":"ciypwm36s000321sv2ayq74mg","_id":"ciypwm3ce005s21sv4ndhbq84"},{"post_id":"ciypwm3bw005221sv9xsoxqtn","category_id":"ciypwm36s000321sv2ayq74mg","_id":"ciypwm3ce005w21svs54wwwg7"},{"post_id":"ciypwm3bc004f21svgewuytn4","category_id":"ciypwm3bj004q21sve4wap485","_id":"ciypwm3cg005y21sv6xgpjf9v"},{"post_id":"ciypwm3bg004n21sv7l1ddxrz","category_id":"ciypwm3c0005621svwg9s5r8n","_id":"ciypwm3ch006221sv5e2oylst"},{"post_id":"ciypwm3bj004r21svidlm72tf","category_id":"ciypwm3c6005e21sv23z2ug6y","_id":"ciypwm3ch006421svxmtw5qim"},{"post_id":"ciypwm3bz005521sv6q6whiyk","category_id":"ciypwm3cd005m21sva7pdlkq9","_id":"ciypwm3ci006721svt5y7rxqp"},{"post_id":"ciypwm3c2005921sv50p1s021","category_id":"ciypwm3ce005u21sv403nox6t","_id":"ciypwm3ci006a21svs32vbnui"},{"post_id":"ciypwm3c4005d21sv93q4gepl","category_id":"ciypwm3cg006021svbgr4bjye","_id":"ciypwm3cj006d21svikgkoqz0"},{"post_id":"ciypwm3c7005h21svamd3gs1p","category_id":"ciypwm3cg006021svbgr4bjye","_id":"ciypwm3cj006g21sv20sxx8yw"},{"post_id":"ciypwm3cb005l21svlf0gc6a4","category_id":"ciypwm3ci006c21svajl2sgwk","_id":"ciypwm3cj006j21sv3m3o43yb"}],"PostTag":[{"post_id":"ciypwm370000621sv5wqww7o5","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm37a000a21svfax58516"},{"post_id":"ciypwm36l000121sv4vi8ieps","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm37f000d21sv7fk525fo"},{"post_id":"ciypwm373000721sve8sra0p8","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm37k000i21svnad3ijp2"},{"post_id":"ciypwm36p000221svq1phbbk0","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm37n000l21svsaspgr17"},{"post_id":"ciypwm37g000e21sv4w08jqwz","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm37r000q21svw41qxuqt"},{"post_id":"ciypwm36y000521svf4gipt4m","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm37u000s21svdyy1ze7s"},{"post_id":"ciypwm37s000r21svd81wuly4","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm37y000x21svbru4huzo"},{"post_id":"ciypwm37v000u21svtfny6hag","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm380001021svtybgpqsz"},{"post_id":"ciypwm37z000y21sv7ku7mwqz","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm386001521svutmja09k"},{"post_id":"ciypwm37b000b21svs9suqb35","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm38a001721svbmdelerh"},{"post_id":"ciypwm37b000b21svs9suqb35","tag_id":"ciypwm37y000w21sv7akqrkp4","_id":"ciypwm38f001c21svvt4h2mm7"},{"post_id":"ciypwm381001121svtap4yfqx","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm38h001e21svn5ld5b06"},{"post_id":"ciypwm387001621sv0tyyvktn","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm38k001i21svqkuzu8tv"},{"post_id":"ciypwm38b001821svqerj6t12","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm38o001m21svg8cviaig"},{"post_id":"ciypwm38f001d21svebn6o2x0","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm38s001p21svh9m4ut1m"},{"post_id":"ciypwm37k000j21svx26uzv21","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm38x001t21svfn04cqko"},{"post_id":"ciypwm37k000j21svx26uzv21","tag_id":"ciypwm38f001b21svlvklr72p","_id":"ciypwm390001w21svzftkbwhz"},{"post_id":"ciypwm38t001s21svt0sqa4iq","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm394002021svo8n48ckh"},{"post_id":"ciypwm37n000m21svlowv6kfh","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm396002321sva7axz9ya"},{"post_id":"ciypwm37n000m21svlowv6kfh","tag_id":"ciypwm38s001r21svydvoae1d","_id":"ciypwm39a002721sv1pflqbvt"},{"post_id":"ciypwm391001y21svngtxbmr2","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm39c002a21svaw84tgku"},{"post_id":"ciypwm394002121svo7zb0zb3","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm39e002e21svowo1d3vo"},{"post_id":"ciypwm38h001f21sv8w2usj1k","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm39i002h21svuf36v2oh"},{"post_id":"ciypwm396002521svmkmo7uob","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm39l002m21svnll9m813"},{"post_id":"ciypwm39a002821svvdj89we5","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm39o002p21svotoxav00"},{"post_id":"ciypwm38l001k21svmq9vzpvt","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm39s002t21sv69d0gzxb"},{"post_id":"ciypwm39e002f21svqd89nzvh","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm39x002w21svj85eaeh5"},{"post_id":"ciypwm38y001u21svs7mji43n","tag_id":"ciypwm39e002d21sv64407bht","_id":"ciypwm3a2003121svv17iivnk"},{"post_id":"ciypwm39i002i21sv9msto5pk","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3ae003421svlmlryek5"},{"post_id":"ciypwm39m002n21svzvub4bz1","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm3ah003821svmtv2qne3"},{"post_id":"ciypwm39c002b21svtsnp2crr","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3ak003c21svikhitx11"},{"post_id":"ciypwm39c002b21svtsnp2crr","tag_id":"ciypwm39l002k21svytq32fhf","_id":"ciypwm3am003g21sv3pyhg7yw"},{"post_id":"ciypwm39p002q21svs69ki7jr","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3ao003k21sv2n3jtmop"},{"post_id":"ciypwm3ae003521svyblhs7lq","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm3ar003o21sve5zw7sjz"},{"post_id":"ciypwm39s002u21svylq4icy5","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3av003r21svguznlq80"},{"post_id":"ciypwm39s002u21svylq4icy5","tag_id":"ciypwm3a1002z21svtd90b889","_id":"ciypwm3ax003v21svqkqk8ot1"},{"post_id":"ciypwm3ai003921sv5f0f4edv","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3b1003z21svx4pe0b8t"},{"post_id":"ciypwm3al003d21svs6i4yavl","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm3b4004321sv6e3a8xso"},{"post_id":"ciypwm39x002x21svqqrk3m16","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3b6004621sv1joiocxx"},{"post_id":"ciypwm39x002x21svqqrk3m16","tag_id":"ciypwm3ak003a21svg0ygjid2","_id":"ciypwm3b9004b21svgaibm1bp"},{"post_id":"ciypwm3an003h21sv7b0gw30l","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3bc004e21svh9h6tpw1"},{"post_id":"ciypwm3an003h21sv7b0gw30l","tag_id":"ciypwm38s001r21svydvoae1d","_id":"ciypwm3be004i21svu5c090n6"},{"post_id":"ciypwm3ao003l21svrwyk2i8l","tag_id":"ciypwm392001z21svrcw0otfu","_id":"ciypwm3bg004m21sv3asght9w"},{"post_id":"ciypwm3a2003221svf7toen7b","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3bi004p21svf6eui4kf"},{"post_id":"ciypwm3a2003221svf7toen7b","tag_id":"ciypwm3ao003i21svh8r94vgn","_id":"ciypwm3bo004t21sveo6cxfit"},{"post_id":"ciypwm3ay003w21svpn73kvxk","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3br004w21svoy8j8l2c"},{"post_id":"ciypwm3ay003w21svpn73kvxk","tag_id":"ciypwm38s001r21svydvoae1d","_id":"ciypwm3bv005121svtvhgykh1"},{"post_id":"ciypwm3b4004421svqhoqjae5","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3by005421svwqniij1v"},{"post_id":"ciypwm3aw003s21svc9u1t1uj","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3c1005821svzddb5nmn"},{"post_id":"ciypwm3aw003s21svc9u1t1uj","tag_id":"ciypwm3b1003x21svxhs5szvn","_id":"ciypwm3c4005c21sv1swcumb5"},{"post_id":"ciypwm3ba004c21svocwumvw5","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3c7005g21sv5397cxqt"},{"post_id":"ciypwm3b2004021svioptmeei","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3cb005k21svp39qfahn"},{"post_id":"ciypwm3b2004021svioptmeei","tag_id":"ciypwm3b8004821sva121xkab","_id":"ciypwm3cd005o21svt9yhmohq"},{"post_id":"ciypwm3bc004f21svgewuytn4","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3cd005r21sv2id72j8f"},{"post_id":"ciypwm3be004k21svfutfhg13","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3ce005t21sv1bcnptke"},{"post_id":"ciypwm3b7004721sv1225ic1c","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3ce005x21svaaixto5z"},{"post_id":"ciypwm3b7004721sv1225ic1c","tag_id":"ciypwm3b8004821sva121xkab","_id":"ciypwm3cg005z21sv5izyd5fu"},{"post_id":"ciypwm3bg004n21sv7l1ddxrz","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3ch006321svis6jaywg"},{"post_id":"ciypwm3bj004r21svidlm72tf","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3ch006521svaju372ai"},{"post_id":"ciypwm3bw005221sv9xsoxqtn","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3ci006821sv2jnf3mrg"},{"post_id":"ciypwm3bz005521sv6q6whiyk","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3ci006b21svxcw5s4lc"},{"post_id":"ciypwm3bo004u21sve7kv8amn","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3cj006e21sv7st5k6qa"},{"post_id":"ciypwm3bo004u21sve7kv8amn","tag_id":"ciypwm3bv004z21sveko5655v","_id":"ciypwm3cj006f21svanymt0fg"},{"post_id":"ciypwm3c7005h21svamd3gs1p","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3cj006h21sv8g5sjcth"},{"post_id":"ciypwm3cb005l21svlf0gc6a4","tag_id":"ciypwm36x000421svx7frtbsl","_id":"ciypwm3cj006i21sv1tsxgij9"},{"post_id":"ciypwm3bs004x21svpb3i7i4k","tag_id":"ciypwm3c3005a21sv2ovu098c","_id":"ciypwm3cj006k21sv64jn4hkr"},{"post_id":"ciypwm3bs004x21svpb3i7i4k","tag_id":"ciypwm3ca005i21svhxwhovao","_id":"ciypwm3cj006l21svqskl39j0"},{"post_id":"ciypwm3bs004x21svpb3i7i4k","tag_id":"ciypwm3bv004z21sveko5655v","_id":"ciypwm3cj006m21sv7vrhnwhx"},{"post_id":"ciypwm3bs004x21svpb3i7i4k","tag_id":"ciypwm3ce005v21svhpc2mlny","_id":"ciypwm3cj006n21sv6iyou2rp"},{"post_id":"ciypwm3c2005921sv50p1s021","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3cj006o21svh2tjl2ht"},{"post_id":"ciypwm3c2005921sv50p1s021","tag_id":"ciypwm3ch006121svvkfcwhkd","_id":"ciypwm3cj006p21sv7bmlqcn8"},{"post_id":"ciypwm3c4005d21sv93q4gepl","tag_id":"ciypwm37r000o21svjcqqxc6i","_id":"ciypwm3ck006q21svda2o4obb"},{"post_id":"ciypwm3c4005d21sv93q4gepl","tag_id":"ciypwm3ci006921sv33rfphoh","_id":"ciypwm3ck006r21svm3332mu0"}],"Tag":[{"name":"portal","_id":"ciypwm36x000421svx7frtbsl"},{"name":"core","_id":"ciypwm37r000o21svjcqqxc6i"},{"name":"cloudfoundry","_id":"ciypwm37y000w21sv7akqrkp4"},{"name":"openshift","_id":"ciypwm38f001b21svlvklr72p"},{"name":"openstack","_id":"ciypwm38s001r21svydvoae1d"},{"name":"detail","_id":"ciypwm392001z21svrcw0otfu"},{"name":"cookbook","_id":"ciypwm39e002d21sv64407bht"},{"name":"filesystem","_id":"ciypwm39l002k21svytq32fhf"},{"name":"security","_id":"ciypwm3a1002z21svtd90b889"},{"name":"network","_id":"ciypwm3ak003a21svg0ygjid2"},{"name":"storage","_id":"ciypwm3ao003i21svh8r94vgn"},{"name":"swarm","_id":"ciypwm3b1003x21svxhs5szvn"},{"name":"architect","_id":"ciypwm3b8004821sva121xkab"},{"name":"django","_id":"ciypwm3bv004z21sveko5655v"},{"name":"install","_id":"ciypwm3c3005a21sv2ovu098c"},{"name":"python","_id":"ciypwm3ca005i21svhxwhovao"},{"name":"docker","_id":"ciypwm3ce005v21svhpc2mlny"},{"name":"rails","_id":"ciypwm3ch006121svvkfcwhkd"},{"name":"http","_id":"ciypwm3ci006921sv33rfphoh"}]}}